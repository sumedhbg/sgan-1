{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_stack_gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhmVBp07pIV_",
        "outputId": "ac501e7a-bcf2-48fe-ab69-d8be6aa22397"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "import PIL\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from keras import Input, Model\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Dense, LeakyReLU, BatchNormalization,ZeroPadding2D, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n",
        "    concatenate, Flatten, Lambda, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ9xcSXzpWHu"
      },
      "source": [
        "def load_class_ids(class_info_file_path):\n",
        "    \"\"\"\n",
        "    Load class ids from class_info.pickle file\n",
        "    \"\"\"\n",
        "    with open(class_info_file_path, 'rb') as f:\n",
        "        class_ids = pickle.load(f, encoding='latin1')\n",
        "        return class_ids\n",
        "      \n",
        "def load_embeddings(embeddings_file_path):\n",
        "    \"\"\"\n",
        "    Load embeddings\n",
        "    \"\"\"\n",
        "    with open(embeddings_file_path, 'rb') as f:\n",
        "        embeddings = pickle.load(f, encoding='latin1')\n",
        "        embeddings = np.array(embeddings)\n",
        "        print('embeddings: ', embeddings.shape)\n",
        "    return embeddings\n",
        " \n",
        "def load_filenames(filenames_file_path):\n",
        "    \"\"\"\n",
        "    Load filenames.pickle file and return a list of all file names\n",
        "    \"\"\"\n",
        "    with open(filenames_file_path, 'rb') as f:\n",
        "        filenames = pickle.load(f, encoding='latin1')\n",
        "    return filenames\n",
        " \n",
        "def load_bounding_boxes(dataset_dir):\n",
        "    \"\"\"\n",
        "    Load bounding boxes and return a dictionary of file names and corresponding bounding boxes\n",
        "    \"\"\"\n",
        "    # Paths\n",
        "    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n",
        "    file_paths_path = os.path.join(dataset_dir, 'images.txt')\n",
        "\n",
        "    # Read bounding_boxes.txt and images.txt file\n",
        "    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n",
        "                                    delim_whitespace=True, header=None).astype(int)\n",
        "    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n",
        "\n",
        "    # Create a list of file names\n",
        "    file_names = df_file_names[1].tolist()\n",
        "\n",
        "    # Create a dictionary of file_names and bounding boxes\n",
        "    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n",
        "\n",
        "    # Assign a bounding box to the corresponding image\n",
        "    for i in range(0, len(file_names)):\n",
        "        # Get the bounding box\n",
        "        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n",
        "        key = file_names[i][:-4]\n",
        "        filename_boundingbox_dict[key] = bounding_box\n",
        "\n",
        "    return filename_boundingbox_dict\n",
        "\n",
        "def get_img(img_path, bbox, image_size):\n",
        "    \"\"\"\n",
        "    Load and resize image\n",
        "    \"\"\"\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    width, height = img.size\n",
        "    if bbox is not None:\n",
        "        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
        "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
        "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
        "        y1 = np.maximum(0, center_y - R)\n",
        "        y2 = np.minimum(height, center_y + R)\n",
        "        x1 = np.maximum(0, center_x - R)\n",
        "        x2 = np.minimum(width, center_x + R)\n",
        "        img = img.crop([x1, y1, x2, y2])\n",
        "    img = img.resize(image_size, PIL.Image.BILINEAR)\n",
        "    return img\n",
        " \n",
        "def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n",
        "    \"\"\"\n",
        "    Load dataset\n",
        "    \"\"\"\n",
        "    filenames = load_filenames(filenames_file_path) #names of the files containing the images\n",
        "    class_ids = load_class_ids(class_info_file_path) #not sure what this corresponds to\n",
        "    bounding_boxes = load_bounding_boxes(cub_dataset_dir) #these have something to do with the image size and config of attributes of image\n",
        "    all_embeddings = load_embeddings(embeddings_file_path) #this obv loads the text embeddings\n",
        "\n",
        "    X, y, embeddings = [], [], []\n",
        "\n",
        "    print(\"Embeddings shape:\", all_embeddings.shape)\n",
        "\n",
        "    for index, filename in enumerate(filenames):\n",
        "        bounding_box = bounding_boxes[filename]\n",
        "\n",
        "        try:\n",
        "            # Load images\n",
        "            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n",
        "            img = get_img(img_name, bounding_box, image_size)\n",
        "\n",
        "            all_embeddings1 = all_embeddings[index, :, :]\n",
        "\n",
        "            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n",
        "            embedding = all_embeddings1[embedding_ix, :]\n",
        "\n",
        "            X.append(np.array(img)) #clearly we here append the image to the x list\n",
        "            y.append(class_ids[index]) #here we clearly append the \n",
        "            embeddings.append(embedding) #\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    embeddings = np.array(embeddings)\n",
        "    return X, y, embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTbMiqBIqKuk"
      },
      "source": [
        "def generate_c(x):\n",
        "    mean = x[:, :128]\n",
        "    log_sigma = x[:, 128:]\n",
        "    stddev = K.exp(log_sigma)\n",
        "    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\n",
        "    c = stddev * epsilon + mean\n",
        "    return c\n",
        "  \n",
        "def build_ca_model():\n",
        "    \"\"\"\n",
        "    Get conditioning augmentation model.\n",
        "    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(1024,)) #this is the text embedding\n",
        "    x = Dense(256)(input_layer)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    model = Model(inputs=[input_layer], outputs=[x])\n",
        "    return model\n",
        "  \n",
        "def build_embedding_compressor_model():\n",
        "    \"\"\"\n",
        "    Build embedding compressor model\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(1024,))\n",
        "    x = Dense(128)(input_layer)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[x])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pmy-cUhqSVV"
      },
      "source": [
        "def build_stage1_generator():\n",
        "    \"\"\"\n",
        "    Builds a generator model used in Stage-I\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(1024,)) #the Input layer tells that we will be recieving this as an input during prediction\n",
        "    x = Dense(256)(input_layer)\n",
        "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    c = Lambda(generate_c)(mean_logsigma) #gives out a tensor with dimenstion (batch_size, 128)\n",
        "\n",
        "    input_layer2 = Input(shape=(100,))  #the Input layer tells that we will be recieving this as an input during prediction\n",
        "\n",
        "    gen_input = Concatenate(axis=1)([c, input_layer2]) #this gives rise to concatenated vector containing both randomness and the essence of the text description\n",
        "\n",
        "    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x) #changes the size to (8 , 8 , 1024)\n",
        "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = Activation(activation='tanh')(x)\n",
        "\n",
        "    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma]) #this means that when we use this model to perdict we must give [input_layer, input_layer2] as inputs and in turn we get [x, mean_logsigma] as output\n",
        "    return stage1_gen\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ybl4wo7qXgv"
      },
      "source": [
        "def build_stage1_discriminator():\n",
        "    \"\"\"\n",
        "    Create a model which takes two inputs\n",
        "    1. One from above network\n",
        "    2. One from the embedding layer\n",
        "    3. Concatenate along the axis dimension and feed it to the last module which produces final logits\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(64, 64, 3))\n",
        "\n",
        "    x = Conv2D(64, (4, 4),padding='same', strides=2,input_shape=(64, 64, 3), use_bias=False)(input_layer)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    input_layer2 = Input(shape=(4, 4, 128))\n",
        "\n",
        "    merged_input = concatenate([x, input_layer2]) #the dimension of the merged_imput is (4, 4, 640=(512+128))\n",
        "\n",
        "    x2 = Conv2D(64 * 8, kernel_size=1,\n",
        "                padding=\"same\", strides=1)(merged_input)\n",
        "    x2 = BatchNormalization()(x2)\n",
        "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
        "    x2 = Flatten()(x2)\n",
        "    x2 = Dense(1)(x2)\n",
        "    x2 = Activation('sigmoid')(x2)\n",
        "\n",
        "    stage1_dis = Model(inputs=[input_layer, input_layer2], outputs=[x2])\n",
        "    return stage1_dis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5zVFPonqa61"
      },
      "source": [
        "def build_adversarial_model(gen_model, dis_model):\n",
        "    input_layer = Input(shape=(1024,))\n",
        "    input_layer2 = Input(shape=(100,))\n",
        "    input_layer3 = Input(shape=(4, 4, 128)) #the text_embedding converted from (1024, ) to (4, 4, 128, ) only for compatibality that is required while we are dealing with stage1_dis\n",
        "\n",
        "    x, mean_logsigma = gen_model([input_layer, input_layer2]) #here also clearly we are seeing that we are passing these two layers as input to gen_model to get two outputs x and mean_logsigma \n",
        "\n",
        "    dis_model.trainable = False\n",
        "    valid = dis_model([x, input_layer3])\n",
        "\n",
        "    model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[valid, mean_logsigma]) #as already previously explained this means that when we want to predict using this model we must provide input_layer, input_layer2, input_layer3 as input and we get [valid, mean_logsigma] as ouputs\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwWT3MWoqd-4"
      },
      "source": [
        "def KL_loss(y_true, y_pred):\n",
        "    mean = y_pred[:, :128]\n",
        "    logsigma = y_pred[:, :128]\n",
        "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n",
        "    loss = K.mean(loss)\n",
        "    return loss\n",
        "    \n",
        "\n",
        "def custom_generator_loss(y_true, y_pred):\n",
        "    # Calculate binary cross entropy loss\n",
        "    return K.binary_crossentropy(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpom2WTlqgPC"
      },
      "source": [
        "def save_rgb_img(img, path):\n",
        "    \"\"\"\n",
        "    Save an rgb image\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Image\")\n",
        "\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    \n",
        "# def write_log(callback, name, loss, batch_no):\n",
        "#     \"\"\"\n",
        "#     Write training summary to TensorBoard\n",
        "#     \"\"\"\n",
        "#     summary = tf.Summary()\n",
        "#     summary_value = summary.value.add()\n",
        "#     summary_value.simple_value = loss\n",
        "#     summary_value.tag = name\n",
        "#     callback.writer.add_summary(summary, batch_no)\n",
        "#     callback.writer.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    data_dir = \"/content/drive/MyDrive/birds\"\n",
        "    train_dir = data_dir + \"/train\"\n",
        "    test_dir = data_dir + \"/test\"\n",
        "    image_size = 64\n",
        "    batch_size = 64\n",
        "    z_dim = 100\n",
        "    stage1_generator_lr = 0.0002\n",
        "    stage1_discriminator_lr = 0.0002\n",
        "    stage1_lr_decay_step = 600\n",
        "    epochs = 100\n",
        "    condition_dim = 128\n",
        "\n",
        "    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\" #this is the path for text embeddings(dim=1024) which are alredy created using word2vec.\n",
        "    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"  #this is the path for text embeddings(dim=1024) which are alredy created using word2vec.\n",
        "\n",
        "    filenames_file_path_train = train_dir + \"/filenames.pickle\" #this is the path for text embeddings(dim=1024) which are alredy created using word2vec.\n",
        "    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n",
        "\n",
        "    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n",
        "    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n",
        "\n",
        "    cub_dataset_dir = data_dir + \"/CUB_200_2011\"\n",
        "    \n",
        "    # Define optimizers\n",
        "    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "   \n",
        "\n",
        "    \"\"\"\n",
        "    Build and compile networks\n",
        "    \"\"\"\n",
        "    ca_model = build_ca_model() #the ca_model just compresses the text embedding from (1024, ) to (256, )\n",
        "    ca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\") #when we say compile we basically only define the parameters which decide the performance of the model and we also define the optimizer, we do nothing else\n",
        "\n",
        "    stage1_dis = build_stage1_discriminator()\n",
        "    stage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
        "\n",
        "    stage1_gen = build_stage1_generator()\n",
        "    stage1_gen.compile(loss=\"mse\", optimizer=gen_optimizer)\n",
        "\n",
        "    embedding_compressor_model = build_embedding_compressor_model()\n",
        "    embedding_compressor_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "    adversarial_model = build_adversarial_model(gen_model=stage1_gen, dis_model=stage1_dis) #the main GAN Stage1 \n",
        "    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],\n",
        "                              optimizer=gen_optimizer, metrics=None)\n",
        "\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
        "    tensorboard.set_model(stage1_gen)\n",
        "    tensorboard.set_model(stage1_dis)\n",
        "    tensorboard.set_model(ca_model)\n",
        "    tensorboard.set_model(embedding_compressor_model)\n",
        "\n",
        "    # Generate an array containing real and fake values\n",
        "    # Apply label smoothing as well\n",
        "    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9 #we are multiplying by 0.9 to intoduce label smoothing which is a regularization technique for classification problems to prevent the model from predicting the labels too confidently during training and generalizing poorly\n",
        "    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbwby7G4qQ6t",
        "outputId": "0e9e5c08-82eb-43ee-c935-d601691f88aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfvUFdliqjrX",
        "outputId": "6222dab3-0904-4963-87ff-3ba08ff05c15"
      },
      "source": [
        "    data_dir = \"/content/drive/MyDrive/birds\"\n",
        "    train_dir = data_dir + \"/train\"\n",
        "    test_dir = data_dir + \"/test\"\n",
        "    image_size = 64\n",
        "    batch_size = 64\n",
        "    z_dim = 100\n",
        "    stage1_generator_lr = 0.0002\n",
        "    stage1_discriminator_lr = 0.0002\n",
        "    stage1_lr_decay_step = 600\n",
        "    epochs = 100\n",
        "    condition_dim = 128\n",
        "\n",
        "    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\" #this is the path for text embeddings(dim=1024) which are alredy created using word2vec.\n",
        "    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"  #this is the path for text embeddings(dim=1024) which are alredy created using word2vec.\n",
        "\n",
        "    filenames_file_path_train = train_dir + \"/filenames.pickle\" #this is the path for text embeddings(dim=1024) which are alredy created using word2vec.\n",
        "    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n",
        "\n",
        "    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n",
        "    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n",
        "\n",
        "    cub_dataset_dir = data_dir + \"/CUB_200_2011\"\n",
        "    \n",
        "    # Define optimizers\n",
        "    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "    \"\"\"\"\n",
        "    Load datasets\n",
        "    \"\"\"\n",
        "    X_train, y_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,    #this line does the huge job of finally doing all the activities and loading the x_train and others\n",
        "                                                      class_info_file_path=class_info_file_path_train,\n",
        "                                                      cub_dataset_dir=cub_dataset_dir,\n",
        "                                                      embeddings_file_path=embeddings_file_path_train,\n",
        "                                                      image_size=(64, 64))\n",
        "\n",
        "    X_test, y_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n",
        "                                                   class_info_file_path=class_info_file_path_test,\n",
        "                                                   cub_dataset_dir=cub_dataset_dir,\n",
        "                                                   embeddings_file_path=embeddings_file_path_test,\n",
        "                                                   image_size=(64, 64))\n",
        "\n",
        "    \"\"\"\n",
        "    Build and compile networks\n",
        "    \"\"\"\n",
        "    ca_model = build_ca_model() #the ca_model just compresses the text embedding from (1024, ) to (256, )\n",
        "    ca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\") #when we say compile we basically only define the parameters which decide the performance of the model and we also define the optimizer, we do nothing else\n",
        "\n",
        "    stage1_dis = build_stage1_discriminator()\n",
        "    stage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
        "\n",
        "    stage1_gen = build_stage1_generator()\n",
        "    stage1_gen.compile(loss=\"mse\", optimizer=gen_optimizer)\n",
        "\n",
        "    embedding_compressor_model = build_embedding_compressor_model()\n",
        "    embedding_compressor_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "    adversarial_model = build_adversarial_model(gen_model=stage1_gen, dis_model=stage1_dis) #the main GAN Stage1 \n",
        "    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],\n",
        "                              optimizer=gen_optimizer, metrics=None)\n",
        "\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
        "    tensorboard.set_model(stage1_gen)\n",
        "    tensorboard.set_model(stage1_dis)\n",
        "    tensorboard.set_model(ca_model)\n",
        "    tensorboard.set_model(embedding_compressor_model)\n",
        "\n",
        "    # Generate an array containing real and fake values\n",
        "    # Apply label smoothing as well\n",
        "    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9 #we are multiplying by 0.9 to intoduce label smoothing which is a regularization technique for classification problems to prevent the model from predicting the labels too confidently during training and generalizing poorly\n",
        "    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"========================================\")\n",
        "        print(\"Epoch is:\", epoch)\n",
        "        print(\"Number of batches\", int(X_train.shape[0] / batch_size))\n",
        "\n",
        "        gen_losses = []\n",
        "        dis_losses = []\n",
        "\n",
        "        # Load data and train model\n",
        "        number_of_batches = int(X_train.shape[0] / batch_size)\n",
        "        for index in range(number_of_batches):\n",
        "            print(\"Batch:{}\".format(index+1))\n",
        "            \n",
        "            \"\"\"\n",
        "            Train the discriminator network\n",
        "            \"\"\"\n",
        "            # Sample a batch of data\n",
        "            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim)) #random vector needed by the stage1_gen\n",
        "            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
        "            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n",
        "            image_batch = (image_batch - 127.5) / 127.5\n",
        "\n",
        "            # Generate fake images\n",
        "            fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3) #here we are generating the fake images using the predict method and we are passing the required two inputs which are the embedding_batch and z_noise\n",
        "\n",
        "            # Generate compressed embeddings\n",
        "            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n",
        "            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n",
        "            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1)) #the end result of compressed_embeddind is we take in a text embedding with dimension (1024) and convert this into a tensor of dim (4, 4, 128) and the motive is to make it compatible for concatanation with the image of(4, 4, 512) in the stage1_dis\n",
        "\n",
        "            dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],  # a normal training procedure where we give two params, one is x_train and the other y_train. Clearly here x_train is real images adn the y_train is an array of np.ones which is label smoothned by multiplying with 0.9\n",
        "                                                      np.reshape(real_labels, (batch_size, 1)))\n",
        "            dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],    #here we get the discriminator output for the fake labels as we are now training the discriminator on the fake images\n",
        "                                                      np.reshape(fake_labels, (batch_size, 1)))\n",
        "            dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],\n",
        "                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n",
        "\n",
        "            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n",
        "\n",
        "            print(\"d_loss_real:{}\".format(dis_loss_real))\n",
        "            print(\"d_loss_fake:{}\".format(dis_loss_fake))\n",
        "            print(\"d_loss_wrong:{}\".format(dis_loss_wrong))\n",
        "            print(\"d_loss:{}\".format(d_loss))\n",
        "\n",
        "            \"\"\"\n",
        "            Train the generator network \n",
        "            \"\"\"\n",
        "            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9]) #here the output(g_loss) is nothing but the stage_1 discriminators output\n",
        "            print(\"g_loss:{}\".format(g_loss))\n",
        "\n",
        "            dis_losses.append(d_loss)\n",
        "            gen_losses.append(g_loss)\n",
        "        \"\"\"\n",
        "        Save losses to Tensorboard after each epoch\n",
        "        \"\"\"\n",
        "        #write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n",
        "        #write_log(tensorboard, 'generator_loss', np.mean(gen_losses[0]), epoch)\n",
        "        \n",
        "        # Generate and save images after every 2nd epoch\n",
        "        if epoch % 2 == 0:\n",
        "            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
        "            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "            embedding_batch = embeddings_test[0:batch_size]\n",
        "            fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\n",
        "            stage1_gen.save_weights(\"/content/drive/MyDrive/StackGAN_weights/stage1_gen_weight.h5\")\n",
        "            stage1_dis.save_weights(\"/content/drive/MyDrive/StackGAN_weights/stage1_dis_weight.h5\") \n",
        "            # Save images\n",
        "            for i, img in enumerate(fake_images[:10]):\n",
        "                save_rgb_img(img, \"/content/drive/My Drive/results_stackgan/gen_{}_{}.png\".format(epoch, i))\n",
        "\n",
        "\n",
        "    # Save models\n",
        "    \n",
        "       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings:  (8855, 10, 1024)\n",
            "Embeddings shape: (8855, 10, 1024)\n",
            "embeddings:  (2933, 10, 1024)\n",
            "Embeddings shape: (2933, 10, 1024)\n",
            "========================================\n",
            "Epoch is: 0\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.8240528702735901\n",
            "d_loss_fake:3.8111064434051514\n",
            "d_loss_wrong:5.308828353881836\n",
            "d_loss:2.692010134458542\n",
            "g_loss:[0.7293922305107117, 0.6960375308990479, 0.016677353531122208]\n",
            "Batch:2\n",
            "d_loss_real:1.671766996383667\n",
            "d_loss_fake:0.29849714040756226\n",
            "d_loss_wrong:1.520751953125\n",
            "d_loss:1.290695771574974\n",
            "g_loss:[0.7431575655937195, 0.7142202258110046, 0.01446867361664772]\n",
            "Batch:3\n",
            "d_loss_real:2.4226465225219727\n",
            "d_loss_fake:0.030885428190231323\n",
            "d_loss_wrong:1.7119323015213013\n",
            "d_loss:1.6470276936888695\n",
            "g_loss:[0.7342869639396667, 0.6992925405502319, 0.017497222870588303]\n",
            "Batch:4\n",
            "d_loss_real:2.488600254058838\n",
            "d_loss_fake:0.4267066717147827\n",
            "d_loss_wrong:1.8926234245300293\n",
            "d_loss:1.824132651090622\n",
            "g_loss:[0.7599400281906128, 0.7345042824745178, 0.012717858888208866]\n",
            "Batch:5\n",
            "d_loss_real:2.0346920490264893\n",
            "d_loss_fake:0.053959593176841736\n",
            "d_loss_wrong:2.2366137504577637\n",
            "d_loss:1.589989360421896\n",
            "g_loss:[0.7927147150039673, 0.7742009162902832, 0.009256898425519466]\n",
            "Batch:6\n",
            "d_loss_real:2.1067895889282227\n",
            "d_loss_fake:0.011830044910311699\n",
            "d_loss_wrong:1.8646225929260254\n",
            "d_loss:1.5225079539231956\n",
            "g_loss:[0.7930612564086914, 0.7709863185882568, 0.011037472635507584]\n",
            "Batch:7\n",
            "d_loss_real:2.3219661712646484\n",
            "d_loss_fake:0.013352916575968266\n",
            "d_loss_wrong:1.0855947732925415\n",
            "d_loss:1.4357200080994517\n",
            "g_loss:[0.7328367233276367, 0.7179922461509705, 0.007422241382300854]\n",
            "Batch:8\n",
            "d_loss_real:2.4299774169921875\n",
            "d_loss_fake:0.027161912992596626\n",
            "d_loss_wrong:0.647068977355957\n",
            "d_loss:1.3835464310832322\n",
            "g_loss:[0.7143733501434326, 0.6785466074943542, 0.01791338436305523]\n",
            "Batch:9\n",
            "d_loss_real:1.7885229587554932\n",
            "d_loss_fake:0.04292246326804161\n",
            "d_loss_wrong:1.1867188215255737\n",
            "d_loss:1.2016718005761504\n",
            "g_loss:[0.7328040599822998, 0.694312334060669, 0.019245851784944534]\n",
            "Batch:10\n",
            "d_loss_real:1.246109962463379\n",
            "d_loss_fake:0.07391548156738281\n",
            "d_loss_wrong:1.0689303874969482\n",
            "d_loss:0.9087664484977722\n",
            "g_loss:[0.739633321762085, 0.7165117263793945, 0.011560797691345215]\n",
            "Batch:11\n",
            "d_loss_real:1.3577497005462646\n",
            "d_loss_fake:0.10301517695188522\n",
            "d_loss_wrong:0.9062936902046204\n",
            "d_loss:0.9312020670622587\n",
            "g_loss:[0.7323372960090637, 0.7131259441375732, 0.009605685248970985]\n",
            "Batch:12\n",
            "d_loss_real:1.5486072301864624\n",
            "d_loss_fake:0.016356242820620537\n",
            "d_loss_wrong:0.9059789776802063\n",
            "d_loss:1.004887420218438\n",
            "g_loss:[0.7141340970993042, 0.701133131980896, 0.006500484421849251]\n",
            "Batch:13\n",
            "d_loss_real:1.344506025314331\n",
            "d_loss_fake:0.19932007789611816\n",
            "d_loss_wrong:0.8535000085830688\n",
            "d_loss:0.9354580342769623\n",
            "g_loss:[0.6947823762893677, 0.6836850643157959, 0.005548666696995497]\n",
            "Batch:14\n",
            "d_loss_real:1.4813905954360962\n",
            "d_loss_fake:0.005699687637388706\n",
            "d_loss_wrong:0.9970903396606445\n",
            "d_loss:0.9913928045425564\n",
            "g_loss:[0.7125746011734009, 0.7024538516998291, 0.005060379393398762]\n",
            "Batch:15\n",
            "d_loss_real:1.3879823684692383\n",
            "d_loss_fake:0.011883527040481567\n",
            "d_loss_wrong:1.3391982316970825\n",
            "d_loss:1.0317616239190102\n",
            "g_loss:[0.7146872282028198, 0.6973132491111755, 0.008686989545822144]\n",
            "Batch:16\n",
            "d_loss_real:1.0935723781585693\n",
            "d_loss_fake:0.013223160989582539\n",
            "d_loss_wrong:1.102662205696106\n",
            "d_loss:0.8257575307507068\n",
            "g_loss:[0.6805959939956665, 0.6678333282470703, 0.006381342187523842]\n",
            "Batch:17\n",
            "d_loss_real:1.29354727268219\n",
            "d_loss_fake:0.06490752100944519\n",
            "d_loss_wrong:1.2850509881973267\n",
            "d_loss:0.9842632636427879\n",
            "g_loss:[0.6775005459785461, 0.6690662503242493, 0.0042171538807451725]\n",
            "Batch:18\n",
            "d_loss_real:1.4420201778411865\n",
            "d_loss_fake:0.019223716109991074\n",
            "d_loss_wrong:0.7171654105186462\n",
            "d_loss:0.9051073705777526\n",
            "g_loss:[0.6659142374992371, 0.659176230430603, 0.0033690142445266247]\n",
            "Batch:19\n",
            "d_loss_real:1.3138527870178223\n",
            "d_loss_fake:0.010556206107139587\n",
            "d_loss_wrong:0.924068808555603\n",
            "d_loss:0.8905826471745968\n",
            "g_loss:[0.6505668759346008, 0.6404201984405518, 0.0050733331590890884]\n",
            "Batch:20\n",
            "d_loss_real:1.2762736082077026\n",
            "d_loss_fake:0.03200002387166023\n",
            "d_loss_wrong:0.9854737520217896\n",
            "d_loss:0.8925052480772138\n",
            "g_loss:[0.6411013007164001, 0.6347929835319519, 0.003154152538627386]\n",
            "Batch:21\n",
            "d_loss_real:1.3674323558807373\n",
            "d_loss_fake:0.013449670746922493\n",
            "d_loss_wrong:0.6953814029693604\n",
            "d_loss:0.8609239463694394\n",
            "g_loss:[0.6252955198287964, 0.6170821189880371, 0.004106711596250534]\n",
            "Batch:22\n",
            "d_loss_real:1.0003230571746826\n",
            "d_loss_fake:0.05294163152575493\n",
            "d_loss_wrong:1.028029203414917\n",
            "d_loss:0.7704042373225093\n",
            "g_loss:[0.6225236654281616, 0.6145432591438293, 0.003990214318037033]\n",
            "Batch:23\n",
            "d_loss_real:0.9927927851676941\n",
            "d_loss_fake:0.047642193734645844\n",
            "d_loss_wrong:0.8261943459510803\n",
            "d_loss:0.7148555275052786\n",
            "g_loss:[0.6865116953849792, 0.6801556348800659, 0.0031780353747308254]\n",
            "Batch:24\n",
            "d_loss_real:1.1597051620483398\n",
            "d_loss_fake:0.030002325773239136\n",
            "d_loss_wrong:0.792385458946228\n",
            "d_loss:0.7854495272040367\n",
            "g_loss:[0.6654535531997681, 0.6575298309326172, 0.003961873706430197]\n",
            "Batch:25\n",
            "d_loss_real:1.0592402219772339\n",
            "d_loss_fake:0.02054883912205696\n",
            "d_loss_wrong:0.9702041745185852\n",
            "d_loss:0.7773083643987775\n",
            "g_loss:[0.6794909834861755, 0.6713290214538574, 0.004080972634255886]\n",
            "Batch:26\n",
            "d_loss_real:1.160815715789795\n",
            "d_loss_fake:0.004696146119385958\n",
            "d_loss_wrong:0.8397050499916077\n",
            "d_loss:0.7915081569226459\n",
            "g_loss:[0.6611213684082031, 0.6529310941696167, 0.0040951501578092575]\n",
            "Batch:27\n",
            "d_loss_real:1.2354280948638916\n",
            "d_loss_fake:0.006660837680101395\n",
            "d_loss_wrong:1.1321170330047607\n",
            "d_loss:0.9024085151031613\n",
            "g_loss:[0.632685661315918, 0.6237813234329224, 0.004452175460755825]\n",
            "Batch:28\n",
            "d_loss_real:1.1628705263137817\n",
            "d_loss_fake:0.0042985109612345695\n",
            "d_loss_wrong:0.7224955558776855\n",
            "d_loss:0.7631337798666209\n",
            "g_loss:[0.6430680751800537, 0.6298964619636536, 0.006585806608200073]\n",
            "Batch:29\n",
            "d_loss_real:1.0317226648330688\n",
            "d_loss_fake:0.005042938515543938\n",
            "d_loss_wrong:0.8067020177841187\n",
            "d_loss:0.7187975714914501\n",
            "g_loss:[0.6373961567878723, 0.6274332404136658, 0.0049814567901194096]\n",
            "Batch:30\n",
            "d_loss_real:1.0260124206542969\n",
            "d_loss_fake:0.003833959810435772\n",
            "d_loss_wrong:1.129076361656189\n",
            "d_loss:0.7962337906938046\n",
            "g_loss:[0.6122006773948669, 0.6055872440338135, 0.0033067273907363415]\n",
            "Batch:31\n",
            "d_loss_real:0.954319179058075\n",
            "d_loss_fake:0.00300577818416059\n",
            "d_loss_wrong:0.803473174571991\n",
            "d_loss:0.6787793277180754\n",
            "g_loss:[0.6308347582817078, 0.624093770980835, 0.0033705015666782856]\n",
            "Batch:32\n",
            "d_loss_real:1.1075656414031982\n",
            "d_loss_fake:0.004964668303728104\n",
            "d_loss_wrong:0.6498151421546936\n",
            "d_loss:0.7174777733162045\n",
            "g_loss:[0.6139104962348938, 0.6036195755004883, 0.0051454720087349415]\n",
            "Batch:33\n",
            "d_loss_real:1.0300891399383545\n",
            "d_loss_fake:0.008387953974306583\n",
            "d_loss_wrong:0.7830473184585571\n",
            "d_loss:0.7129033880773932\n",
            "g_loss:[0.6830116510391235, 0.6759385466575623, 0.003536537755280733]\n",
            "Batch:34\n",
            "d_loss_real:1.0194940567016602\n",
            "d_loss_fake:0.017949633300304413\n",
            "d_loss_wrong:0.7504321932792664\n",
            "d_loss:0.7018424849957228\n",
            "g_loss:[0.6503442525863647, 0.6423488855361938, 0.003997696563601494]\n",
            "Batch:35\n",
            "d_loss_real:0.981452226638794\n",
            "d_loss_fake:0.014360652305185795\n",
            "d_loss_wrong:0.8310670256614685\n",
            "d_loss:0.7020830328110605\n",
            "g_loss:[0.6021028757095337, 0.5960016250610352, 0.0030506316106766462]\n",
            "Batch:36\n",
            "d_loss_real:0.9872086048126221\n",
            "d_loss_fake:0.001561282784678042\n",
            "d_loss_wrong:0.7880712747573853\n",
            "d_loss:0.6910124417918269\n",
            "g_loss:[0.6172798871994019, 0.6099330186843872, 0.0036734268069267273]\n",
            "Batch:37\n",
            "d_loss_real:0.9422562122344971\n",
            "d_loss_fake:0.002101288642734289\n",
            "d_loss_wrong:0.9304895997047424\n",
            "d_loss:0.7042758282041177\n",
            "g_loss:[0.6360757946968079, 0.627372682094574, 0.004351568408310413]\n",
            "Batch:38\n",
            "d_loss_real:0.9930087924003601\n",
            "d_loss_fake:0.0030082850717008114\n",
            "d_loss_wrong:0.8372870683670044\n",
            "d_loss:0.7065782345598564\n",
            "g_loss:[0.6031167507171631, 0.595499575138092, 0.0038085849955677986]\n",
            "Batch:39\n",
            "d_loss_real:1.0124759674072266\n",
            "d_loss_fake:0.004682043567299843\n",
            "d_loss_wrong:0.741098940372467\n",
            "d_loss:0.692683229688555\n",
            "g_loss:[0.5888695120811462, 0.5801759958267212, 0.004346769768744707]\n",
            "Batch:40\n",
            "d_loss_real:1.0184705257415771\n",
            "d_loss_fake:0.0028025172650814056\n",
            "d_loss_wrong:1.1028311252593994\n",
            "d_loss:0.7856436735019088\n",
            "g_loss:[0.6524478793144226, 0.6444631814956665, 0.003992339596152306]\n",
            "Batch:41\n",
            "d_loss_real:1.0042089223861694\n",
            "d_loss_fake:0.009713584557175636\n",
            "d_loss_wrong:0.6904903650283813\n",
            "d_loss:0.677155448589474\n",
            "g_loss:[0.6063229441642761, 0.5997557044029236, 0.0032836319878697395]\n",
            "Batch:42\n",
            "d_loss_real:1.0724880695343018\n",
            "d_loss_fake:0.010770324617624283\n",
            "d_loss_wrong:0.734947919845581\n",
            "d_loss:0.7226735958829522\n",
            "g_loss:[0.6122623085975647, 0.6059293150901794, 0.0031665090937167406]\n",
            "Batch:43\n",
            "d_loss_real:0.9988219738006592\n",
            "d_loss_fake:0.0015840099658817053\n",
            "d_loss_wrong:0.6800316572189331\n",
            "d_loss:0.6698149036965333\n",
            "g_loss:[0.5767998099327087, 0.5695269107818604, 0.0036364607512950897]\n",
            "Batch:44\n",
            "d_loss_real:0.9419870376586914\n",
            "d_loss_fake:0.0014967177994549274\n",
            "d_loss_wrong:0.7744073271751404\n",
            "d_loss:0.6649695300729945\n",
            "g_loss:[0.620361864566803, 0.6148383617401123, 0.0027617602609097958]\n",
            "Batch:45\n",
            "d_loss_real:1.0118536949157715\n",
            "d_loss_fake:0.0007563091930933297\n",
            "d_loss_wrong:0.6631014943122864\n",
            "d_loss:0.6718912983342307\n",
            "g_loss:[0.6098242998123169, 0.6032375693321228, 0.0032933722250163555]\n",
            "Batch:46\n",
            "d_loss_real:0.8918063044548035\n",
            "d_loss_fake:0.0016026360681280494\n",
            "d_loss_wrong:0.8026114702224731\n",
            "d_loss:0.646956678800052\n",
            "g_loss:[0.5525081157684326, 0.5451962947845459, 0.00365590606816113]\n",
            "Batch:47\n",
            "d_loss_real:0.8726853132247925\n",
            "d_loss_fake:0.0055689215660095215\n",
            "d_loss_wrong:0.7900212407112122\n",
            "d_loss:0.6352401971817017\n",
            "g_loss:[0.5435789227485657, 0.5370517373085022, 0.003263578750193119]\n",
            "Batch:48\n",
            "d_loss_real:1.01227867603302\n",
            "d_loss_fake:0.0014782247599214315\n",
            "d_loss_wrong:0.695893406867981\n",
            "d_loss:0.6804822459234856\n",
            "g_loss:[0.5440488457679749, 0.5367058515548706, 0.0036714915186166763]\n",
            "Batch:49\n",
            "d_loss_real:0.9190081357955933\n",
            "d_loss_fake:0.0031831725500524044\n",
            "d_loss_wrong:0.7110320925712585\n",
            "d_loss:0.6380578841781244\n",
            "g_loss:[0.5420554876327515, 0.5342212915420532, 0.0039170971140265465]\n",
            "Batch:50\n",
            "d_loss_real:0.9060648083686829\n",
            "d_loss_fake:0.008068794384598732\n",
            "d_loss_wrong:0.7189380526542664\n",
            "d_loss:0.6347841159440577\n",
            "g_loss:[0.5882558226585388, 0.5828965902328491, 0.0026796162128448486]\n",
            "Batch:51\n",
            "d_loss_real:0.9293506145477295\n",
            "d_loss_fake:0.006506561301648617\n",
            "d_loss_wrong:0.7678239345550537\n",
            "d_loss:0.6582579312380403\n",
            "g_loss:[0.6063841581344604, 0.6011427640914917, 0.00262069096788764]\n",
            "Batch:52\n",
            "d_loss_real:0.9142922759056091\n",
            "d_loss_fake:0.005047675222158432\n",
            "d_loss_wrong:0.7525046467781067\n",
            "d_loss:0.6465342184528708\n",
            "g_loss:[0.5759479999542236, 0.5712326765060425, 0.0023576645180583]\n",
            "Batch:53\n",
            "d_loss_real:1.0100739002227783\n",
            "d_loss_fake:0.001457422855310142\n",
            "d_loss_wrong:0.7059229016304016\n",
            "d_loss:0.6818820312328171\n",
            "g_loss:[0.514062225818634, 0.5079586505889893, 0.0030517985578626394]\n",
            "Batch:54\n",
            "d_loss_real:0.8840872049331665\n",
            "d_loss_fake:0.001032682484947145\n",
            "d_loss_wrong:0.7822116613388062\n",
            "d_loss:0.6378546884225216\n",
            "g_loss:[0.519601047039032, 0.5129237174987793, 0.003338651265949011]\n",
            "Batch:55\n",
            "d_loss_real:0.9137076735496521\n",
            "d_loss_fake:0.0015456475084647536\n",
            "d_loss_wrong:0.7205232977867126\n",
            "d_loss:0.6373710730986204\n",
            "g_loss:[0.5347636938095093, 0.5299028158187866, 0.002430453896522522]\n",
            "Batch:56\n",
            "d_loss_real:0.901941180229187\n",
            "d_loss_fake:0.009074034169316292\n",
            "d_loss_wrong:0.805573046207428\n",
            "d_loss:0.6546323602087796\n",
            "g_loss:[0.5332958698272705, 0.5260948538780212, 0.0036005107685923576]\n",
            "Batch:57\n",
            "d_loss_real:0.9729481935501099\n",
            "d_loss_fake:0.0009072799002751708\n",
            "d_loss_wrong:0.6984043717384338\n",
            "d_loss:0.6613020096847322\n",
            "g_loss:[0.569736897945404, 0.5620710849761963, 0.0038329027593135834]\n",
            "Batch:58\n",
            "d_loss_real:0.9281311631202698\n",
            "d_loss_fake:0.0020290864631533623\n",
            "d_loss_wrong:0.7370056509971619\n",
            "d_loss:0.6488242659252137\n",
            "g_loss:[0.6604201197624207, 0.6527730822563171, 0.0038235136307775974]\n",
            "Batch:59\n",
            "d_loss_real:0.9479427337646484\n",
            "d_loss_fake:0.006085445173084736\n",
            "d_loss_wrong:0.755611777305603\n",
            "d_loss:0.6643956725019962\n",
            "g_loss:[0.55660080909729, 0.5504276752471924, 0.0030865794979035854]\n",
            "Batch:60\n",
            "d_loss_real:0.9302310943603516\n",
            "d_loss_fake:0.004540446680039167\n",
            "d_loss_wrong:0.7659931778907776\n",
            "d_loss:0.65774895332288\n",
            "g_loss:[0.5166792273521423, 0.5097834467887878, 0.003447900293394923]\n",
            "Batch:61\n",
            "d_loss_real:0.9433845281600952\n",
            "d_loss_fake:0.00188663590233773\n",
            "d_loss_wrong:0.7542619705200195\n",
            "d_loss:0.6607294156856369\n",
            "g_loss:[0.5192047357559204, 0.5135948657989502, 0.0028049361426383257]\n",
            "Batch:62\n",
            "d_loss_real:0.9641256332397461\n",
            "d_loss_fake:0.002931000431999564\n",
            "d_loss_wrong:0.6944130659103394\n",
            "d_loss:0.6563988332054578\n",
            "g_loss:[0.5363824963569641, 0.5305585265159607, 0.0029119718819856644]\n",
            "Batch:63\n",
            "d_loss_real:0.947136640548706\n",
            "d_loss_fake:0.004306696355342865\n",
            "d_loss_wrong:0.7463311553001404\n",
            "d_loss:0.6612277831882238\n",
            "g_loss:[0.5623993873596191, 0.5566645264625549, 0.0028674346394836903]\n",
            "Batch:64\n",
            "d_loss_real:0.9476838707923889\n",
            "d_loss_fake:0.004419456701725721\n",
            "d_loss_wrong:0.7025036811828613\n",
            "d_loss:0.6505727198673412\n",
            "g_loss:[0.5088316202163696, 0.5011222958564758, 0.0038546486757695675]\n",
            "Batch:65\n",
            "d_loss_real:0.9466674327850342\n",
            "d_loss_fake:0.0009998478926718235\n",
            "d_loss_wrong:0.7788363695144653\n",
            "d_loss:0.6682927707443014\n",
            "g_loss:[0.5227715373039246, 0.5156251192092896, 0.0035732046235352755]\n",
            "Batch:66\n",
            "d_loss_real:0.8525645732879639\n",
            "d_loss_fake:0.00039161485619843006\n",
            "d_loss_wrong:0.7616057395935059\n",
            "d_loss:0.616781625256408\n",
            "g_loss:[0.46275633573532104, 0.45749950408935547, 0.0026284195482730865]\n",
            "Batch:67\n",
            "d_loss_real:1.0031341314315796\n",
            "d_loss_fake:0.001158969127573073\n",
            "d_loss_wrong:0.6658980250358582\n",
            "d_loss:0.6683313142566476\n",
            "g_loss:[0.47458434104919434, 0.4702988862991333, 0.0021427199244499207]\n",
            "Batch:68\n",
            "d_loss_real:0.9218953847885132\n",
            "d_loss_fake:0.0013346397317945957\n",
            "d_loss_wrong:0.794266402721405\n",
            "d_loss:0.6598479530075565\n",
            "g_loss:[0.5185818672180176, 0.5136939287185669, 0.002443957608193159]\n",
            "Batch:69\n",
            "d_loss_real:0.9374182224273682\n",
            "d_loss_fake:0.0012936044950038195\n",
            "d_loss_wrong:0.9228934645652771\n",
            "d_loss:0.6997558784787543\n",
            "g_loss:[0.49126195907592773, 0.4874899685382843, 0.0018860024865716696]\n",
            "Batch:70\n",
            "d_loss_real:0.8728832006454468\n",
            "d_loss_fake:0.0017534360522404313\n",
            "d_loss_wrong:0.742453396320343\n",
            "d_loss:0.6224933084158693\n",
            "g_loss:[0.5137237310409546, 0.5087183117866516, 0.002502724528312683]\n",
            "Batch:71\n",
            "d_loss_real:0.9259558916091919\n",
            "d_loss_fake:0.0035573116037994623\n",
            "d_loss_wrong:0.6746218800544739\n",
            "d_loss:0.6325227437191643\n",
            "g_loss:[0.4582553207874298, 0.45253878831863403, 0.0028582667000591755]\n",
            "Batch:72\n",
            "d_loss_real:0.9329173564910889\n",
            "d_loss_fake:0.0005732316058129072\n",
            "d_loss_wrong:0.7069621682167053\n",
            "d_loss:0.643342528201174\n",
            "g_loss:[0.5382359027862549, 0.5327315926551819, 0.0027521688025444746]\n",
            "Batch:73\n",
            "d_loss_real:0.8963631987571716\n",
            "d_loss_fake:0.0005397889763116837\n",
            "d_loss_wrong:0.7428154349327087\n",
            "d_loss:0.6340204053558409\n",
            "g_loss:[0.4231732487678528, 0.41643214225769043, 0.003370546270161867]\n",
            "Batch:74\n",
            "d_loss_real:0.971671462059021\n",
            "d_loss_fake:0.0015927646309137344\n",
            "d_loss_wrong:0.7326819896697998\n",
            "d_loss:0.6694044196046889\n",
            "g_loss:[0.42995163798332214, 0.4244251549243927, 0.002763239201158285]\n",
            "Batch:75\n",
            "d_loss_real:0.9686691761016846\n",
            "d_loss_fake:0.002440457930788398\n",
            "d_loss_wrong:0.7100285887718201\n",
            "d_loss:0.6624518497264944\n",
            "g_loss:[0.5128619074821472, 0.5064689517021179, 0.0031964911613613367]\n",
            "Batch:76\n",
            "d_loss_real:0.9086893796920776\n",
            "d_loss_fake:0.006747485604137182\n",
            "d_loss_wrong:0.6960693597793579\n",
            "d_loss:0.6300489011919126\n",
            "g_loss:[0.536245584487915, 0.5308574438095093, 0.002694082912057638]\n",
            "Batch:77\n",
            "d_loss_real:0.9195529222488403\n",
            "d_loss_fake:0.0004574871272780001\n",
            "d_loss_wrong:0.7271345853805542\n",
            "d_loss:0.6416744792513782\n",
            "g_loss:[0.4275974631309509, 0.4214068055152893, 0.0030953316017985344]\n",
            "Batch:78\n",
            "d_loss_real:0.8791055679321289\n",
            "d_loss_fake:0.0004791885439772159\n",
            "d_loss_wrong:0.7354830503463745\n",
            "d_loss:0.6235433436886524\n",
            "g_loss:[0.4306896924972534, 0.42414140701293945, 0.0032741499599069357]\n",
            "Batch:79\n",
            "d_loss_real:0.9126467704772949\n",
            "d_loss_fake:0.0003123530186712742\n",
            "d_loss_wrong:0.683107852935791\n",
            "d_loss:0.627178436727263\n",
            "g_loss:[0.40309590101242065, 0.39682191610336304, 0.0031369896605610847]\n",
            "Batch:80\n",
            "d_loss_real:0.9027778506278992\n",
            "d_loss_fake:0.00020687031792476773\n",
            "d_loss_wrong:0.6928008198738098\n",
            "d_loss:0.6246408478618832\n",
            "g_loss:[0.43003809452056885, 0.42464232444763184, 0.002697883639484644]\n",
            "Batch:81\n",
            "d_loss_real:0.9120281934738159\n",
            "d_loss_fake:0.0005957981920801103\n",
            "d_loss_wrong:0.6617166996002197\n",
            "d_loss:0.6215922211849829\n",
            "g_loss:[0.4418879747390747, 0.43648889660835266, 0.0026995441876351833]\n",
            "Batch:82\n",
            "d_loss_real:0.977274477481842\n",
            "d_loss_fake:0.00250707333907485\n",
            "d_loss_wrong:0.7255170345306396\n",
            "d_loss:0.6706432657083496\n",
            "g_loss:[0.47481611371040344, 0.4691641926765442, 0.00282595818862319]\n",
            "Batch:83\n",
            "d_loss_real:0.840800404548645\n",
            "d_loss_fake:0.002637821715325117\n",
            "d_loss_wrong:0.688216507434845\n",
            "d_loss:0.593113784561865\n",
            "g_loss:[0.45332959294319153, 0.44697630405426025, 0.00317664397880435]\n",
            "Batch:84\n",
            "d_loss_real:0.8705724477767944\n",
            "d_loss_fake:0.001957723405212164\n",
            "d_loss_wrong:0.7295357584953308\n",
            "d_loss:0.618159594363533\n",
            "g_loss:[0.4281075596809387, 0.42063093185424805, 0.0037383201997727156]\n",
            "Batch:85\n",
            "d_loss_real:0.8676921129226685\n",
            "d_loss_fake:0.00012633853475563228\n",
            "d_loss_wrong:0.7271145582199097\n",
            "d_loss:0.6156562806500006\n",
            "g_loss:[0.44144871830940247, 0.43467187881469727, 0.0033884262666106224]\n",
            "Batch:86\n",
            "d_loss_real:0.8876731395721436\n",
            "d_loss_fake:0.00023813098960090429\n",
            "d_loss_wrong:0.6898745894432068\n",
            "d_loss:0.6163647498942737\n",
            "g_loss:[0.4317757487297058, 0.42566823959350586, 0.0030537471175193787]\n",
            "Batch:87\n",
            "d_loss_real:0.8968526124954224\n",
            "d_loss_fake:0.000296806450933218\n",
            "d_loss_wrong:0.6899994015693665\n",
            "d_loss:0.6210003582527861\n",
            "g_loss:[0.3881484866142273, 0.3804935812950134, 0.0038274554535746574]\n",
            "Batch:88\n",
            "d_loss_real:0.8915827870368958\n",
            "d_loss_fake:0.0002356167242396623\n",
            "d_loss_wrong:0.7322083711624146\n",
            "d_loss:0.6289023904901114\n",
            "g_loss:[0.3766802251338959, 0.3698192238807678, 0.003430494572967291]\n",
            "Batch:89\n",
            "d_loss_real:0.93266761302948\n",
            "d_loss_fake:0.0011264050845056772\n",
            "d_loss_wrong:0.7556267976760864\n",
            "d_loss:0.655522107204888\n",
            "g_loss:[0.41992875933647156, 0.41186580061912537, 0.004031484015285969]\n",
            "Batch:90\n",
            "d_loss_real:0.8800376653671265\n",
            "d_loss_fake:0.0005563535960391164\n",
            "d_loss_wrong:0.7535808682441711\n",
            "d_loss:0.6285531381436158\n",
            "g_loss:[0.41011926531791687, 0.40335264801979065, 0.0033833065535873175]\n",
            "Batch:91\n",
            "d_loss_real:0.8673332333564758\n",
            "d_loss_fake:0.0015391005435958505\n",
            "d_loss_wrong:0.7495747208595276\n",
            "d_loss:0.6214450720290188\n",
            "g_loss:[0.4283200204372406, 0.42142412066459656, 0.003447949420660734]\n",
            "Batch:92\n",
            "d_loss_real:0.9821648001670837\n",
            "d_loss_fake:0.0008476866059936583\n",
            "d_loss_wrong:0.7427908778190613\n",
            "d_loss:0.6769920411898056\n",
            "g_loss:[0.504729688167572, 0.49648940563201904, 0.00412013428285718]\n",
            "Batch:93\n",
            "d_loss_real:0.9134315252304077\n",
            "d_loss_fake:0.0008646606002002954\n",
            "d_loss_wrong:0.674612283706665\n",
            "d_loss:0.6255849986919202\n",
            "g_loss:[0.4975764751434326, 0.4865063428878784, 0.005535067990422249]\n",
            "Batch:94\n",
            "d_loss_real:0.8760411739349365\n",
            "d_loss_fake:0.008591334335505962\n",
            "d_loss_wrong:0.7806214690208435\n",
            "d_loss:0.6353237878065556\n",
            "g_loss:[0.48609089851379395, 0.4757937788963318, 0.005148560740053654]\n",
            "Batch:95\n",
            "d_loss_real:0.8902943134307861\n",
            "d_loss_fake:0.0001881594507722184\n",
            "d_loss_wrong:0.7127673029899597\n",
            "d_loss:0.623386022325576\n",
            "g_loss:[0.43196308612823486, 0.42151424288749695, 0.005224416498094797]\n",
            "Batch:96\n",
            "d_loss_real:0.8393733501434326\n",
            "d_loss_fake:0.00014747012755833566\n",
            "d_loss_wrong:0.7062753438949585\n",
            "d_loss:0.5962923785773455\n",
            "g_loss:[0.4193258583545685, 0.4048888087272644, 0.0072185262106359005]\n",
            "Batch:97\n",
            "d_loss_real:0.8979350328445435\n",
            "d_loss_fake:0.00342541397549212\n",
            "d_loss_wrong:0.6922845840454102\n",
            "d_loss:0.6228950159274973\n",
            "g_loss:[0.41355404257774353, 0.4024449586868286, 0.005554544739425182]\n",
            "Batch:98\n",
            "d_loss_real:0.8817138075828552\n",
            "d_loss_fake:0.0002235301653854549\n",
            "d_loss_wrong:0.7327072024345398\n",
            "d_loss:0.6240895869414089\n",
            "g_loss:[0.4825037717819214, 0.4719330072402954, 0.005285387858748436]\n",
            "Batch:99\n",
            "d_loss_real:0.9238750338554382\n",
            "d_loss_fake:0.000397161697037518\n",
            "d_loss_wrong:0.6525294184684753\n",
            "d_loss:0.6251691619690973\n",
            "g_loss:[0.425128310918808, 0.4135807752609253, 0.005773766897618771]\n",
            "Batch:100\n",
            "d_loss_real:0.9338783025741577\n",
            "d_loss_fake:0.00024409889010712504\n",
            "d_loss_wrong:0.6489206552505493\n",
            "d_loss:0.629230339822243\n",
            "g_loss:[0.3761071562767029, 0.364101767539978, 0.0060026990249753]\n",
            "Batch:101\n",
            "d_loss_real:0.913345456123352\n",
            "d_loss_fake:0.00046635675244033337\n",
            "d_loss_wrong:0.7456564903259277\n",
            "d_loss:0.643203439831268\n",
            "g_loss:[0.38922086358070374, 0.380622535943985, 0.0042991628870368]\n",
            "Batch:102\n",
            "d_loss_real:0.901374101638794\n",
            "d_loss_fake:0.00015603392967022955\n",
            "d_loss_wrong:0.7003106474876404\n",
            "d_loss:0.6258037211737246\n",
            "g_loss:[0.3674265742301941, 0.3581503629684448, 0.004638100974261761]\n",
            "Batch:103\n",
            "d_loss_real:0.9539517760276794\n",
            "d_loss_fake:0.00028069206746295094\n",
            "d_loss_wrong:0.6575466990470886\n",
            "d_loss:0.6414327357924776\n",
            "g_loss:[0.3604620099067688, 0.3522922992706299, 0.004084858577698469]\n",
            "Batch:104\n",
            "d_loss_real:0.9278910756111145\n",
            "d_loss_fake:0.000642751925624907\n",
            "d_loss_wrong:0.7268571257591248\n",
            "d_loss:0.6458205072267447\n",
            "g_loss:[0.344064861536026, 0.3366520404815674, 0.003706410527229309]\n",
            "Batch:105\n",
            "d_loss_real:0.9072067737579346\n",
            "d_loss_fake:0.003174953628331423\n",
            "d_loss_wrong:0.7374427318572998\n",
            "d_loss:0.6387578082503751\n",
            "g_loss:[0.37934890389442444, 0.3739897608757019, 0.0026795677840709686]\n",
            "Batch:106\n",
            "d_loss_real:0.8498094081878662\n",
            "d_loss_fake:0.00020947010489180684\n",
            "d_loss_wrong:0.7123776078224182\n",
            "d_loss:0.6030514735757606\n",
            "g_loss:[0.3653469979763031, 0.35970279574394226, 0.0028220952954143286]\n",
            "Batch:107\n",
            "d_loss_real:0.896611213684082\n",
            "d_loss_fake:0.0004552221216727048\n",
            "d_loss_wrong:0.7087608575820923\n",
            "d_loss:0.6256096267679823\n",
            "g_loss:[0.3480779230594635, 0.3409670293331146, 0.0035554510541260242]\n",
            "Batch:108\n",
            "d_loss_real:0.9083969593048096\n",
            "d_loss_fake:0.00517989881336689\n",
            "d_loss_wrong:0.6693787574768066\n",
            "d_loss:0.6228381437249482\n",
            "g_loss:[0.3574400842189789, 0.3505588173866272, 0.003440628992393613]\n",
            "Batch:109\n",
            "d_loss_real:0.8995856046676636\n",
            "d_loss_fake:0.0002982457517646253\n",
            "d_loss_wrong:0.6985154151916504\n",
            "d_loss:0.6244962175696855\n",
            "g_loss:[0.34680435061454773, 0.3404015302658081, 0.0032014092430472374]\n",
            "Batch:110\n",
            "d_loss_real:0.8491870760917664\n",
            "d_loss_fake:0.0002586439368315041\n",
            "d_loss_wrong:0.7070651650428772\n",
            "d_loss:0.6014244902908104\n",
            "g_loss:[0.3901503384113312, 0.3836246728897095, 0.0032628392800688744]\n",
            "Batch:111\n",
            "d_loss_real:0.8754453659057617\n",
            "d_loss_fake:0.0002560845168773085\n",
            "d_loss_wrong:0.6739894151687622\n",
            "d_loss:0.6062840578742907\n",
            "g_loss:[0.36420077085494995, 0.35803818702697754, 0.0030812881886959076]\n",
            "Batch:112\n",
            "d_loss_real:0.9073438048362732\n",
            "d_loss_fake:0.0008401355007663369\n",
            "d_loss_wrong:0.6997206807136536\n",
            "d_loss:0.6288121064717416\n",
            "g_loss:[0.3563735783100128, 0.3495715856552124, 0.0034009935334324837]\n",
            "Batch:113\n",
            "d_loss_real:0.8872965574264526\n",
            "d_loss_fake:0.001059501664713025\n",
            "d_loss_wrong:0.6868534684181213\n",
            "d_loss:0.6156265212339349\n",
            "g_loss:[0.45909857749938965, 0.45213666558265686, 0.0034809608478099108]\n",
            "Batch:114\n",
            "d_loss_real:0.8431137204170227\n",
            "d_loss_fake:0.0012972832191735506\n",
            "d_loss_wrong:0.6709078550338745\n",
            "d_loss:0.5896081447717734\n",
            "g_loss:[0.3541150987148285, 0.3447756767272949, 0.00466971704736352]\n",
            "Batch:115\n",
            "d_loss_real:0.8616430759429932\n",
            "d_loss_fake:0.0008957127574831247\n",
            "d_loss_wrong:0.6950947046279907\n",
            "d_loss:0.604819142317865\n",
            "g_loss:[0.354136198759079, 0.34607768058776855, 0.004029254429042339]\n",
            "Batch:116\n",
            "d_loss_real:0.915353536605835\n",
            "d_loss_fake:0.0003473063698038459\n",
            "d_loss_wrong:0.7100013494491577\n",
            "d_loss:0.6352639322576579\n",
            "g_loss:[0.3957216441631317, 0.3874971866607666, 0.004112230613827705]\n",
            "Batch:117\n",
            "d_loss_real:0.8820139169692993\n",
            "d_loss_fake:0.002418368123471737\n",
            "d_loss_wrong:0.7133534550666809\n",
            "d_loss:0.6199499142821878\n",
            "g_loss:[0.3470470607280731, 0.34029531478881836, 0.0033758743666112423]\n",
            "Batch:118\n",
            "d_loss_real:0.8553318381309509\n",
            "d_loss_fake:0.0011134177912026644\n",
            "d_loss_wrong:0.686654806137085\n",
            "d_loss:0.5996079750475474\n",
            "g_loss:[0.35013172030448914, 0.34252047538757324, 0.0038056191988289356]\n",
            "Batch:119\n",
            "d_loss_real:0.8682940006256104\n",
            "d_loss_fake:0.0007807434303686023\n",
            "d_loss_wrong:0.6853324174880981\n",
            "d_loss:0.6056752905424219\n",
            "g_loss:[0.3905601501464844, 0.38394278287887573, 0.00330868037417531]\n",
            "Batch:120\n",
            "d_loss_real:0.8737332820892334\n",
            "d_loss_fake:0.0005873978370800614\n",
            "d_loss_wrong:0.6946978569030762\n",
            "d_loss:0.6106879547296558\n",
            "g_loss:[0.3525233268737793, 0.34477850794792175, 0.003872411325573921]\n",
            "Batch:121\n",
            "d_loss_real:0.9086478352546692\n",
            "d_loss_fake:0.0005193289835005999\n",
            "d_loss_wrong:0.6928853988647461\n",
            "d_loss:0.6276750995893963\n",
            "g_loss:[0.3466135859489441, 0.3382605314254761, 0.004176534712314606]\n",
            "Batch:122\n",
            "d_loss_real:0.8527888059616089\n",
            "d_loss_fake:0.0003668712452054024\n",
            "d_loss_wrong:0.6943511962890625\n",
            "d_loss:0.6000739198643714\n",
            "g_loss:[0.35545265674591064, 0.3478284478187561, 0.003812108188867569]\n",
            "Batch:123\n",
            "d_loss_real:0.9815685749053955\n",
            "d_loss_fake:0.0009034069953486323\n",
            "d_loss_wrong:0.7181522250175476\n",
            "d_loss:0.6705481954559218\n",
            "g_loss:[0.3395520746707916, 0.3329766094684601, 0.0032877367921173573]\n",
            "Batch:124\n",
            "d_loss_real:0.8907009959220886\n",
            "d_loss_fake:0.0008899124804884195\n",
            "d_loss_wrong:0.6828093528747559\n",
            "d_loss:0.6162753142998554\n",
            "g_loss:[0.33589261770248413, 0.33025091886520386, 0.0028208456933498383]\n",
            "Batch:125\n",
            "d_loss_real:0.814842939376831\n",
            "d_loss_fake:0.0005602500168606639\n",
            "d_loss_wrong:0.7043341994285583\n",
            "d_loss:0.5836450820497703\n",
            "g_loss:[0.34237223863601685, 0.33615976572036743, 0.0031062341295182705]\n",
            "Batch:126\n",
            "d_loss_real:0.8541427850723267\n",
            "d_loss_fake:0.0005217056605033576\n",
            "d_loss_wrong:0.6897229552268982\n",
            "d_loss:0.5996325577580137\n",
            "g_loss:[0.33368608355522156, 0.32758766412734985, 0.0030492024961858988]\n",
            "Batch:127\n",
            "d_loss_real:0.9370562434196472\n",
            "d_loss_fake:0.0071832649409770966\n",
            "d_loss_wrong:0.6571006774902344\n",
            "d_loss:0.6345991073176265\n",
            "g_loss:[0.3542458713054657, 0.3491961359977722, 0.002524866722524166]\n",
            "Batch:128\n",
            "d_loss_real:0.856520414352417\n",
            "d_loss_fake:0.00011333469592500478\n",
            "d_loss_wrong:0.7354704737663269\n",
            "d_loss:0.6121561592917715\n",
            "g_loss:[0.412892609834671, 0.40457457304000854, 0.004159017466008663]\n",
            "Batch:129\n",
            "d_loss_real:0.8779416680335999\n",
            "d_loss_fake:0.00021585257491096854\n",
            "d_loss_wrong:0.7002078890800476\n",
            "d_loss:0.6140767694305396\n",
            "g_loss:[0.385537326335907, 0.37509259581565857, 0.005222367122769356]\n",
            "Batch:130\n",
            "d_loss_real:0.8471308946609497\n",
            "d_loss_fake:0.0017272481927648187\n",
            "d_loss_wrong:0.7257950901985168\n",
            "d_loss:0.6054460319282953\n",
            "g_loss:[0.34366676211357117, 0.3359379172325134, 0.0038644266314804554]\n",
            "Batch:131\n",
            "d_loss_real:0.9265989065170288\n",
            "d_loss_fake:0.0004934509634040296\n",
            "d_loss_wrong:0.6904138326644897\n",
            "d_loss:0.6360262741654878\n",
            "g_loss:[0.35017305612564087, 0.33793389797210693, 0.006119575351476669]\n",
            "Batch:132\n",
            "d_loss_real:0.8629624843597412\n",
            "d_loss_fake:0.0006844192976132035\n",
            "d_loss_wrong:0.6929040551185608\n",
            "d_loss:0.6048783607839141\n",
            "g_loss:[0.37061139941215515, 0.36410486698150635, 0.0032532732002437115]\n",
            "Batch:133\n",
            "d_loss_real:0.8605294227600098\n",
            "d_loss_fake:0.00015442428411915898\n",
            "d_loss_wrong:0.697077214717865\n",
            "d_loss:0.6045726211305009\n",
            "g_loss:[0.3626979887485504, 0.3577418029308319, 0.0024780910462141037]\n",
            "Batch:134\n",
            "d_loss_real:0.8627545237541199\n",
            "d_loss_fake:0.0008609180222265422\n",
            "d_loss_wrong:0.6909361481666565\n",
            "d_loss:0.6043265284242807\n",
            "g_loss:[0.3344414532184601, 0.3281416893005371, 0.003149887081235647]\n",
            "Batch:135\n",
            "d_loss_real:0.8920506834983826\n",
            "d_loss_fake:0.0005135530955158174\n",
            "d_loss_wrong:0.6621055006980896\n",
            "d_loss:0.6116801051975926\n",
            "g_loss:[0.34601128101348877, 0.3403995633125305, 0.002805862110108137]\n",
            "Batch:136\n",
            "d_loss_real:0.8617851734161377\n",
            "d_loss_fake:0.0008627027273178101\n",
            "d_loss_wrong:0.694832444190979\n",
            "d_loss:0.604816373437643\n",
            "g_loss:[0.3636585772037506, 0.35841768980026245, 0.0026204432360827923]\n",
            "Batch:137\n",
            "d_loss_real:0.8526523113250732\n",
            "d_loss_fake:6.837100227130577e-05\n",
            "d_loss_wrong:0.6975870132446289\n",
            "d_loss:0.6007400017242617\n",
            "g_loss:[0.37321990728378296, 0.36729806661605835, 0.0029609189368784428]\n",
            "Batch:138\n",
            "d_loss_real:0.8636800646781921\n",
            "d_loss_fake:0.0010870754485949874\n",
            "d_loss_wrong:0.6668433547019958\n",
            "d_loss:0.5988226398767438\n",
            "g_loss:[0.3462267220020294, 0.3388988673686981, 0.003663932904601097]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "Epoch is: 1\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.8938331604003906\n",
            "d_loss_fake:0.0005900347605347633\n",
            "d_loss_wrong:0.7289400100708008\n",
            "d_loss:0.6292990914080292\n",
            "g_loss:[0.3769528865814209, 0.36833709478378296, 0.00430790102109313]\n",
            "Batch:2\n",
            "d_loss_real:0.8593814373016357\n",
            "d_loss_fake:0.00032024853862822056\n",
            "d_loss_wrong:0.7101219892501831\n",
            "d_loss:0.6073012780980207\n",
            "g_loss:[0.335723340511322, 0.3263460099697113, 0.004688662011176348]\n",
            "Batch:3\n",
            "d_loss_real:0.8906345367431641\n",
            "d_loss_fake:0.00044142341357655823\n",
            "d_loss_wrong:0.6792443990707397\n",
            "d_loss:0.6152387239926611\n",
            "g_loss:[0.43147721886634827, 0.42235302925109863, 0.004562088288366795]\n",
            "Batch:4\n",
            "d_loss_real:0.918898344039917\n",
            "d_loss_fake:0.0005355054745450616\n",
            "d_loss_wrong:0.7680108547210693\n",
            "d_loss:0.6515857620688621\n",
            "g_loss:[0.4909147620201111, 0.4797860383987427, 0.005564369261264801]\n",
            "Batch:5\n",
            "d_loss_real:0.8473870754241943\n",
            "d_loss_fake:0.0010604423005133867\n",
            "d_loss_wrong:0.8057271242141724\n",
            "d_loss:0.6253904293407686\n",
            "g_loss:[0.44968679547309875, 0.43845289945602417, 0.0056169466115534306]\n",
            "Batch:6\n",
            "d_loss_real:0.8858883380889893\n",
            "d_loss_fake:0.0016858605667948723\n",
            "d_loss_wrong:0.8008967041969299\n",
            "d_loss:0.6435898102354258\n",
            "g_loss:[0.39106619358062744, 0.38001498579978943, 0.005525610875338316]\n",
            "Batch:7\n",
            "d_loss_real:0.8993322849273682\n",
            "d_loss_fake:0.011022204533219337\n",
            "d_loss_wrong:0.6739071011543274\n",
            "d_loss:0.6208984688855708\n",
            "g_loss:[0.4233895242214203, 0.41139358282089233, 0.005997976288199425]\n",
            "Batch:8\n",
            "d_loss_real:0.9186403751373291\n",
            "d_loss_fake:0.0006719164666719735\n",
            "d_loss_wrong:0.6043236255645752\n",
            "d_loss:0.6105690730764763\n",
            "g_loss:[0.45649704337120056, 0.43959692120552063, 0.008450055494904518]\n",
            "Batch:9\n",
            "d_loss_real:0.9134644269943237\n",
            "d_loss_fake:0.0005726096569560468\n",
            "d_loss_wrong:0.6465643048286438\n",
            "d_loss:0.6185164421185618\n",
            "g_loss:[0.38199520111083984, 0.36424556374549866, 0.008874814957380295]\n",
            "Batch:10\n",
            "d_loss_real:0.8925950527191162\n",
            "d_loss_fake:0.0002975050010718405\n",
            "d_loss_wrong:0.6476495862007141\n",
            "d_loss:0.6082842991600046\n",
            "g_loss:[0.36034128069877625, 0.34452393651008606, 0.007908672094345093]\n",
            "Batch:11\n",
            "d_loss_real:0.9089131355285645\n",
            "d_loss_fake:0.00020198235870338976\n",
            "d_loss_wrong:0.6531288027763367\n",
            "d_loss:0.6177892640480422\n",
            "g_loss:[0.4136820137500763, 0.40135300159454346, 0.006164503283798695]\n",
            "Batch:12\n",
            "d_loss_real:0.8810968399047852\n",
            "d_loss_fake:0.0009836668614298105\n",
            "d_loss_wrong:0.6872949004173279\n",
            "d_loss:0.612618061772082\n",
            "g_loss:[0.4152989387512207, 0.4023817181587219, 0.006458606570959091]\n",
            "Batch:13\n",
            "d_loss_real:0.8590635061264038\n",
            "d_loss_fake:0.0010144691914319992\n",
            "d_loss_wrong:0.6952290534973145\n",
            "d_loss:0.6035926337353885\n",
            "g_loss:[0.4132576286792755, 0.3969123065471649, 0.008172664791345596]\n",
            "Batch:14\n",
            "d_loss_real:0.9018853306770325\n",
            "d_loss_fake:0.0005734703736379743\n",
            "d_loss_wrong:0.6986381411552429\n",
            "d_loss:0.6257455682207365\n",
            "g_loss:[0.34625938534736633, 0.33406978845596313, 0.006094795651733875]\n",
            "Batch:15\n",
            "d_loss_real:0.8887333869934082\n",
            "d_loss_fake:0.00040541973430663347\n",
            "d_loss_wrong:0.7482160329818726\n",
            "d_loss:0.6315220566757489\n",
            "g_loss:[0.34708747267723083, 0.32907888293266296, 0.009004296734929085]\n",
            "Batch:16\n",
            "d_loss_real:0.8592718839645386\n",
            "d_loss_fake:0.007889164611697197\n",
            "d_loss_wrong:0.7421534657478333\n",
            "d_loss:0.6171465995721519\n",
            "g_loss:[0.4922894239425659, 0.4791485369205475, 0.0065704467706382275]\n",
            "Batch:17\n",
            "d_loss_real:0.9055907726287842\n",
            "d_loss_fake:0.0005555043462663889\n",
            "d_loss_wrong:0.8023563027381897\n",
            "d_loss:0.6535233380855061\n",
            "g_loss:[0.3632839024066925, 0.3515501916408539, 0.005866861902177334]\n",
            "Batch:18\n",
            "d_loss_real:0.8885098099708557\n",
            "d_loss_fake:0.01068038959056139\n",
            "d_loss_wrong:0.67299485206604\n",
            "d_loss:0.6151737153995782\n",
            "g_loss:[0.36571797728538513, 0.3553599417209625, 0.005179012194275856]\n",
            "Batch:19\n",
            "d_loss_real:0.9558565616607666\n",
            "d_loss_fake:0.00014485177234746516\n",
            "d_loss_wrong:0.6842397451400757\n",
            "d_loss:0.6490244300584891\n",
            "g_loss:[0.354519784450531, 0.3440069854259491, 0.005256392061710358]\n",
            "Batch:20\n",
            "d_loss_real:0.9393191337585449\n",
            "d_loss_fake:0.0005735288141295314\n",
            "d_loss_wrong:0.7364198565483093\n",
            "d_loss:0.6539079132198822\n",
            "g_loss:[0.4185687005519867, 0.4100896418094635, 0.004239535890519619]\n",
            "Batch:21\n",
            "d_loss_real:0.9136010408401489\n",
            "d_loss_fake:0.00023905823763925582\n",
            "d_loss_wrong:0.6288489699363708\n",
            "d_loss:0.614072527463577\n",
            "g_loss:[0.3442915678024292, 0.33374983072280884, 0.005270867608487606]\n",
            "Batch:22\n",
            "d_loss_real:0.873956561088562\n",
            "d_loss_fake:0.00036897434620186687\n",
            "d_loss_wrong:0.7193267941474915\n",
            "d_loss:0.6169022226677043\n",
            "g_loss:[0.40622076392173767, 0.3957907557487488, 0.005215007811784744]\n",
            "Batch:23\n",
            "d_loss_real:0.8387444019317627\n",
            "d_loss_fake:0.0002322239161003381\n",
            "d_loss_wrong:0.7112122178077698\n",
            "d_loss:0.5972333113968489\n",
            "g_loss:[0.4577776789665222, 0.44651177525520325, 0.005632944405078888]\n",
            "Batch:24\n",
            "d_loss_real:0.8533050417900085\n",
            "d_loss_fake:0.005892378743737936\n",
            "d_loss_wrong:0.6688059568405151\n",
            "d_loss:0.5953271047910675\n",
            "g_loss:[0.41299623250961304, 0.40298452973365784, 0.005005852319300175]\n",
            "Batch:25\n",
            "d_loss_real:0.8876322507858276\n",
            "d_loss_fake:0.00048511088243685663\n",
            "d_loss_wrong:0.7469066381454468\n",
            "d_loss:0.6306640626498847\n",
            "g_loss:[0.3699311912059784, 0.3566705882549286, 0.006630297750234604]\n",
            "Batch:26\n",
            "d_loss_real:0.8796916007995605\n",
            "d_loss_fake:0.0008965219021774828\n",
            "d_loss_wrong:0.683840811252594\n",
            "d_loss:0.6110301336884731\n",
            "g_loss:[0.34265002608299255, 0.32876265048980713, 0.006943685468286276]\n",
            "Batch:27\n",
            "d_loss_real:0.9483434557914734\n",
            "d_loss_fake:0.009102155454456806\n",
            "d_loss_wrong:0.7624669671058655\n",
            "d_loss:0.6670640085358173\n",
            "g_loss:[0.35898345708847046, 0.34973758459091187, 0.0046229432336986065]\n",
            "Batch:28\n",
            "d_loss_real:0.8761287331581116\n",
            "d_loss_fake:5.582470475928858e-05\n",
            "d_loss_wrong:0.6253042221069336\n",
            "d_loss:0.594404378281979\n",
            "g_loss:[0.3852480947971344, 0.3721637725830078, 0.0065421550534665585]\n",
            "Batch:29\n",
            "d_loss_real:0.8843446969985962\n",
            "d_loss_fake:9.882537415251136e-05\n",
            "d_loss_wrong:0.6720441579818726\n",
            "d_loss:0.6102080943383044\n",
            "g_loss:[0.48386529088020325, 0.47156834602355957, 0.006148471496999264]\n",
            "Batch:30\n",
            "d_loss_real:0.8929853439331055\n",
            "d_loss_fake:0.0002463731507305056\n",
            "d_loss_wrong:0.7867274880409241\n",
            "d_loss:0.6432361372644664\n",
            "g_loss:[0.34741926193237305, 0.3365079164505005, 0.005455667153000832]\n",
            "Batch:31\n",
            "d_loss_real:0.8474215269088745\n",
            "d_loss_fake:0.0003233697498217225\n",
            "d_loss_wrong:0.6984769105911255\n",
            "d_loss:0.5984108335396741\n",
            "g_loss:[0.4532845914363861, 0.4413631558418274, 0.005960715934634209]\n",
            "Batch:32\n",
            "d_loss_real:0.8861211538314819\n",
            "d_loss_fake:0.0007005424704402685\n",
            "d_loss_wrong:0.627417266368866\n",
            "d_loss:0.6000900291255675\n",
            "g_loss:[0.40477681159973145, 0.3854685425758362, 0.009654141962528229]\n",
            "Batch:33\n",
            "d_loss_real:0.8858849406242371\n",
            "d_loss_fake:0.0009392024949193001\n",
            "d_loss_wrong:0.6693712472915649\n",
            "d_loss:0.6105200827587396\n",
            "g_loss:[0.3664296865463257, 0.34985584020614624, 0.008286917582154274]\n",
            "Batch:34\n",
            "d_loss_real:0.8756786584854126\n",
            "d_loss_fake:0.0006163420621305704\n",
            "d_loss_wrong:0.6616584062576294\n",
            "d_loss:0.6034080163226463\n",
            "g_loss:[0.41986045241355896, 0.40294361114501953, 0.008458424359560013]\n",
            "Batch:35\n",
            "d_loss_real:0.8882142901420593\n",
            "d_loss_fake:0.0008007858414202929\n",
            "d_loss_wrong:0.7050281167030334\n",
            "d_loss:0.6205643707071431\n",
            "g_loss:[0.3866070508956909, 0.3707598149776459, 0.007923616096377373]\n",
            "Batch:36\n",
            "d_loss_real:0.849855899810791\n",
            "d_loss_fake:0.009019790217280388\n",
            "d_loss_wrong:0.6933373808860779\n",
            "d_loss:0.6005172426812351\n",
            "g_loss:[0.36141151189804077, 0.34843307733535767, 0.006489219143986702]\n",
            "Batch:37\n",
            "d_loss_real:0.8593559265136719\n",
            "d_loss_fake:9.654353925725445e-05\n",
            "d_loss_wrong:0.7358149886131287\n",
            "d_loss:0.6136558462949324\n",
            "g_loss:[0.3469948172569275, 0.33474594354629517, 0.006124439649283886]\n",
            "Batch:38\n",
            "d_loss_real:0.9079997539520264\n",
            "d_loss_fake:0.00010482277139090002\n",
            "d_loss_wrong:0.7008146047592163\n",
            "d_loss:0.629229733858665\n",
            "g_loss:[0.3431192636489868, 0.33294954895973206, 0.005084855481982231]\n",
            "Batch:39\n",
            "d_loss_real:0.8802403211593628\n",
            "d_loss_fake:0.0004380374157335609\n",
            "d_loss_wrong:0.6755469441413879\n",
            "d_loss:0.6091164059689618\n",
            "g_loss:[0.3362373113632202, 0.3266026973724365, 0.004817309323698282]\n",
            "Batch:40\n",
            "d_loss_real:0.8979108929634094\n",
            "d_loss_fake:0.0005675713764503598\n",
            "d_loss_wrong:0.8446677923202515\n",
            "d_loss:0.6602642874058802\n",
            "g_loss:[0.3341450095176697, 0.3263930678367615, 0.0038759708404541016]\n",
            "Batch:41\n",
            "d_loss_real:0.8787044286727905\n",
            "d_loss_fake:0.00023868319112807512\n",
            "d_loss_wrong:0.670784592628479\n",
            "d_loss:0.607108033291297\n",
            "g_loss:[0.3466566503047943, 0.33958640694618225, 0.0035351156257092953]\n",
            "Batch:42\n",
            "d_loss_real:0.9365589618682861\n",
            "d_loss_fake:0.0006070845993235707\n",
            "d_loss_wrong:0.6716037392616272\n",
            "d_loss:0.6363321868993808\n",
            "g_loss:[0.3363562822341919, 0.3282634913921356, 0.004046394489705563]\n",
            "Batch:43\n",
            "d_loss_real:0.849994421005249\n",
            "d_loss_fake:0.0005329634295776486\n",
            "d_loss_wrong:0.6555505394935608\n",
            "d_loss:0.5890180862334091\n",
            "g_loss:[0.3403102457523346, 0.3273327946662903, 0.006488721817731857]\n",
            "Batch:44\n",
            "d_loss_real:0.8563029766082764\n",
            "d_loss_fake:0.0016434193821623921\n",
            "d_loss_wrong:0.6920274496078491\n",
            "d_loss:0.6015692055516411\n",
            "g_loss:[0.3368348479270935, 0.326854407787323, 0.0049902270548045635]\n",
            "Batch:45\n",
            "d_loss_real:0.8532201051712036\n",
            "d_loss_fake:0.000789343030191958\n",
            "d_loss_wrong:0.6359784603118896\n",
            "d_loss:0.5858020034211222\n",
            "g_loss:[0.3551788926124573, 0.3459588587284088, 0.004610011354088783]\n",
            "Batch:46\n",
            "d_loss_real:0.8634540438652039\n",
            "d_loss_fake:0.0002578580460976809\n",
            "d_loss_wrong:0.6880624890327454\n",
            "d_loss:0.6038071087023127\n",
            "g_loss:[0.4886802136898041, 0.48066380620002747, 0.004008207470178604]\n",
            "Batch:47\n",
            "d_loss_real:0.8609167337417603\n",
            "d_loss_fake:0.002750229323282838\n",
            "d_loss_wrong:0.6969373226165771\n",
            "d_loss:0.6053802548558451\n",
            "g_loss:[0.37166088819503784, 0.3615613579750061, 0.005049758590757847]\n",
            "Batch:48\n",
            "d_loss_real:0.879180371761322\n",
            "d_loss_fake:0.004084745887666941\n",
            "d_loss_wrong:0.6526625156402588\n",
            "d_loss:0.6037770012626424\n",
            "g_loss:[0.345493346452713, 0.3307124376296997, 0.0073904599994421005]\n",
            "Batch:49\n",
            "d_loss_real:0.8491119742393494\n",
            "d_loss_fake:0.00018277435447089374\n",
            "d_loss_wrong:0.6488488912582397\n",
            "d_loss:0.5868139035228523\n",
            "g_loss:[0.3809328079223633, 0.3661578893661499, 0.007387458346784115]\n",
            "Batch:50\n",
            "d_loss_real:0.8517429828643799\n",
            "d_loss_fake:0.0007868333486840129\n",
            "d_loss_wrong:0.6658044457435608\n",
            "d_loss:0.5925193112052511\n",
            "g_loss:[0.34107866883277893, 0.32986852526664734, 0.005605077371001244]\n",
            "Batch:51\n",
            "d_loss_real:0.8626385927200317\n",
            "d_loss_fake:0.001940425019711256\n",
            "d_loss_wrong:0.6821213960647583\n",
            "d_loss:0.6023347516311333\n",
            "g_loss:[0.33782461285591125, 0.32812514901161194, 0.004849736578762531]\n",
            "Batch:52\n",
            "d_loss_real:0.8596096634864807\n",
            "d_loss_fake:0.0035919491201639175\n",
            "d_loss_wrong:0.6907389760017395\n",
            "d_loss:0.6033875630237162\n",
            "g_loss:[0.3962502181529999, 0.3884662985801697, 0.0038919581566005945]\n",
            "Batch:53\n",
            "d_loss_real:0.8764675855636597\n",
            "d_loss_fake:0.00012226690887473524\n",
            "d_loss_wrong:0.6678289771080017\n",
            "d_loss:0.605221603786049\n",
            "g_loss:[0.35415634512901306, 0.342117577791214, 0.006019388325512409]\n",
            "Batch:54\n",
            "d_loss_real:0.8496533632278442\n",
            "d_loss_fake:0.0026037266943603754\n",
            "d_loss_wrong:0.6935490965843201\n",
            "d_loss:0.5988648874335922\n",
            "g_loss:[0.40785539150238037, 0.39774394035339355, 0.005055719055235386]\n",
            "Batch:55\n",
            "d_loss_real:0.850996732711792\n",
            "d_loss_fake:0.001197872799821198\n",
            "d_loss_wrong:0.6723746061325073\n",
            "d_loss:0.5938914860889781\n",
            "g_loss:[0.389714777469635, 0.37811487913131714, 0.005799945443868637]\n",
            "Batch:56\n",
            "d_loss_real:0.8773053884506226\n",
            "d_loss_fake:0.0001842122001107782\n",
            "d_loss_wrong:0.7190166115760803\n",
            "d_loss:0.618452900169359\n",
            "g_loss:[0.3508959710597992, 0.338512659072876, 0.006191660184413195]\n",
            "Batch:57\n",
            "d_loss_real:0.8720169067382812\n",
            "d_loss_fake:0.000700195727404207\n",
            "d_loss_wrong:0.6623387932777405\n",
            "d_loss:0.6017682006204268\n",
            "g_loss:[0.343258261680603, 0.3311060965061188, 0.006076081655919552]\n",
            "Batch:58\n",
            "d_loss_real:0.8504495620727539\n",
            "d_loss_fake:0.0003062281757593155\n",
            "d_loss_wrong:0.6738999485969543\n",
            "d_loss:0.5937763252295554\n",
            "g_loss:[0.348177969455719, 0.33591845631599426, 0.006129755638539791]\n",
            "Batch:59\n",
            "d_loss_real:0.8880555033683777\n",
            "d_loss_fake:0.005783585831522942\n",
            "d_loss_wrong:0.688362181186676\n",
            "d_loss:0.6175641934387386\n",
            "g_loss:[0.3375603258609772, 0.3272644281387329, 0.00514794560149312]\n",
            "Batch:60\n",
            "d_loss_real:0.8754820823669434\n",
            "d_loss_fake:0.013992677442729473\n",
            "d_loss_wrong:0.6981216669082642\n",
            "d_loss:0.6157696272712201\n",
            "g_loss:[0.36135488748550415, 0.35167691111564636, 0.004838980734348297]\n",
            "Batch:61\n",
            "d_loss_real:0.8831145167350769\n",
            "d_loss_fake:4.8034551582532004e-05\n",
            "d_loss_wrong:0.6799107193946838\n",
            "d_loss:0.611546946854105\n",
            "g_loss:[0.36809706687927246, 0.3585757613182068, 0.004760647192597389]\n",
            "Batch:62\n",
            "d_loss_real:0.8892642855644226\n",
            "d_loss_fake:0.001835677307099104\n",
            "d_loss_wrong:0.659185528755188\n",
            "d_loss:0.6098874442977831\n",
            "g_loss:[0.6737186908721924, 0.6624582409858704, 0.005630212370306253]\n",
            "Batch:63\n",
            "d_loss_real:0.8802796006202698\n",
            "d_loss_fake:0.0015212555881589651\n",
            "d_loss_wrong:0.682104766368866\n",
            "d_loss:0.6110463057993911\n",
            "g_loss:[0.4708351790904999, 0.45730897784233093, 0.006763107143342495]\n",
            "Batch:64\n",
            "d_loss_real:0.8598850965499878\n",
            "d_loss_fake:0.0002695979783311486\n",
            "d_loss_wrong:0.6630688905715942\n",
            "d_loss:0.5957771704124752\n",
            "g_loss:[0.4293734133243561, 0.4159379005432129, 0.006717751733958721]\n",
            "Batch:65\n",
            "d_loss_real:0.904116153717041\n",
            "d_loss_fake:0.0010686481837183237\n",
            "d_loss_wrong:0.7196804285049438\n",
            "d_loss:0.632245346030686\n",
            "g_loss:[0.49786898493766785, 0.4843573570251465, 0.0067558204755187035]\n",
            "Batch:66\n",
            "d_loss_real:0.8231316804885864\n",
            "d_loss_fake:0.0025816247798502445\n",
            "d_loss_wrong:0.6926484704017639\n",
            "d_loss:0.5853733640396968\n",
            "g_loss:[0.4044816792011261, 0.389964759349823, 0.007258464582264423]\n",
            "Batch:67\n",
            "d_loss_real:0.9078329801559448\n",
            "d_loss_fake:0.00031688425224274397\n",
            "d_loss_wrong:0.6398090720176697\n",
            "d_loss:0.6139479791454505\n",
            "g_loss:[0.353301465511322, 0.33926528692245483, 0.007018087897449732]\n",
            "Batch:68\n",
            "d_loss_real:0.87827467918396\n",
            "d_loss_fake:0.0002683007041923702\n",
            "d_loss_wrong:0.7133784294128418\n",
            "d_loss:0.6175490221212385\n",
            "g_loss:[0.35472729802131653, 0.3382495939731598, 0.00823885016143322]\n",
            "Batch:69\n",
            "d_loss_real:0.8882231712341309\n",
            "d_loss_fake:0.001424361951649189\n",
            "d_loss_wrong:0.7608801126480103\n",
            "d_loss:0.6346877042669803\n",
            "g_loss:[0.36852598190307617, 0.35020485520362854, 0.009160557761788368]\n",
            "Batch:70\n",
            "d_loss_real:0.844428300857544\n",
            "d_loss_fake:0.01120670698583126\n",
            "d_loss_wrong:0.6975826621055603\n",
            "d_loss:0.5994114927016199\n",
            "g_loss:[0.47043082118034363, 0.4521753787994385, 0.009127719327807426]\n",
            "Batch:71\n",
            "d_loss_real:0.8543155193328857\n",
            "d_loss_fake:0.00321867223829031\n",
            "d_loss_wrong:0.6566861867904663\n",
            "d_loss:0.592133974423632\n",
            "g_loss:[0.3603547513484955, 0.3406381905078888, 0.009858284145593643]\n",
            "Batch:72\n",
            "d_loss_real:0.8829635381698608\n",
            "d_loss_fake:0.0004393126000650227\n",
            "d_loss_wrong:0.6727113127708435\n",
            "d_loss:0.6097694254276576\n",
            "g_loss:[0.34829211235046387, 0.33023542165756226, 0.009028350003063679]\n",
            "Batch:73\n",
            "d_loss_real:0.8647053241729736\n",
            "d_loss_fake:0.002356781857088208\n",
            "d_loss_wrong:0.6858865022659302\n",
            "d_loss:0.6044134831172414\n",
            "g_loss:[0.34372565150260925, 0.3283233642578125, 0.0077011482790112495]\n",
            "Batch:74\n",
            "d_loss_real:0.9193759560585022\n",
            "d_loss_fake:0.011538799852132797\n",
            "d_loss_wrong:0.6956313848495483\n",
            "d_loss:0.6364805242046714\n",
            "g_loss:[0.5564356446266174, 0.5455329418182373, 0.00545136071741581]\n",
            "Batch:75\n",
            "d_loss_real:0.9022824764251709\n",
            "d_loss_fake:0.04410216212272644\n",
            "d_loss_wrong:0.6547404527664185\n",
            "d_loss:0.6258518919348717\n",
            "g_loss:[0.6605786681175232, 0.6439416408538818, 0.008318513631820679]\n",
            "Batch:76\n",
            "d_loss_real:0.899299144744873\n",
            "d_loss_fake:5.514272561413236e-05\n",
            "d_loss_wrong:0.6415064930915833\n",
            "d_loss:0.6100399813267359\n",
            "g_loss:[0.5782896876335144, 0.5595143437385559, 0.009387658908963203]\n",
            "Batch:77\n",
            "d_loss_real:0.8865131139755249\n",
            "d_loss_fake:8.104636071948335e-05\n",
            "d_loss_wrong:0.6758460402488708\n",
            "d_loss:0.61223832864016\n",
            "g_loss:[0.4759056866168976, 0.45402801036834717, 0.010938843712210655]\n",
            "Batch:78\n",
            "d_loss_real:0.8553664088249207\n",
            "d_loss_fake:0.00012827810132876039\n",
            "d_loss_wrong:0.6844143867492676\n",
            "d_loss:0.5988188706251094\n",
            "g_loss:[0.40067437291145325, 0.38186758756637573, 0.009403390809893608]\n",
            "Batch:79\n",
            "d_loss_real:0.8709245920181274\n",
            "d_loss_fake:0.0013803107431158423\n",
            "d_loss_wrong:0.6629074215888977\n",
            "d_loss:0.6015342290920671\n",
            "g_loss:[0.37591663002967834, 0.35805457830429077, 0.008931029587984085]\n",
            "Batch:80\n",
            "d_loss_real:0.8562179803848267\n",
            "d_loss_fake:0.00014007306890562177\n",
            "d_loss_wrong:0.6622961163520813\n",
            "d_loss:0.5937180375476601\n",
            "g_loss:[0.5701500773429871, 0.5538132190704346, 0.008168429136276245]\n",
            "Batch:81\n",
            "d_loss_real:0.8679938912391663\n",
            "d_loss_fake:0.002340009668841958\n",
            "d_loss_wrong:0.6390981674194336\n",
            "d_loss:0.594356489891652\n",
            "g_loss:[0.4148460030555725, 0.3907466530799866, 0.012049674056470394]\n",
            "Batch:82\n",
            "d_loss_real:0.9246364235877991\n",
            "d_loss_fake:0.017511967569589615\n",
            "d_loss_wrong:0.674491822719574\n",
            "d_loss:0.6353191593661904\n",
            "g_loss:[0.5368474125862122, 0.5085163116455078, 0.014165552332997322]\n",
            "Batch:83\n",
            "d_loss_real:0.8157585859298706\n",
            "d_loss_fake:0.0029619880951941013\n",
            "d_loss_wrong:0.6527104377746582\n",
            "d_loss:0.5717973994323984\n",
            "g_loss:[0.4204283356666565, 0.3886038362979889, 0.0159122534096241]\n",
            "Batch:84\n",
            "d_loss_real:0.8672078847885132\n",
            "d_loss_fake:0.0011992001673206687\n",
            "d_loss_wrong:0.6819233894348145\n",
            "d_loss:0.6043845897947904\n",
            "g_loss:[0.373679518699646, 0.33952823281288147, 0.017075642943382263]\n",
            "Batch:85\n",
            "d_loss_real:0.852677047252655\n",
            "d_loss_fake:0.004003525711596012\n",
            "d_loss_wrong:0.6850994825363159\n",
            "d_loss:0.5986142756883055\n",
            "g_loss:[0.39102059602737427, 0.35986942052841187, 0.015575593337416649]\n",
            "Batch:86\n",
            "d_loss_real:0.8565780520439148\n",
            "d_loss_fake:0.0017765637021511793\n",
            "d_loss_wrong:0.663827657699585\n",
            "d_loss:0.5946900813723914\n",
            "g_loss:[0.3597734570503235, 0.33286455273628235, 0.013454452157020569]\n",
            "Batch:87\n",
            "d_loss_real:0.8648030757904053\n",
            "d_loss_fake:0.0004930903087370098\n",
            "d_loss_wrong:0.6574674844741821\n",
            "d_loss:0.5968916815909324\n",
            "g_loss:[0.45600682497024536, 0.43247437477111816, 0.0117662213742733]\n",
            "Batch:88\n",
            "d_loss_real:0.8695380091667175\n",
            "d_loss_fake:0.009525800123810768\n",
            "d_loss_wrong:0.6902583241462708\n",
            "d_loss:0.6097150356508791\n",
            "g_loss:[0.43369948863983154, 0.4075586199760437, 0.013070432469248772]\n",
            "Batch:89\n",
            "d_loss_real:0.885231614112854\n",
            "d_loss_fake:0.0009697406203486025\n",
            "d_loss_wrong:0.6869438290596008\n",
            "d_loss:0.6145941994764144\n",
            "g_loss:[0.36074209213256836, 0.3354734182357788, 0.012634331360459328]\n",
            "Batch:90\n",
            "d_loss_real:0.8537000417709351\n",
            "d_loss_fake:0.00021198141621425748\n",
            "d_loss_wrong:0.7076992392539978\n",
            "d_loss:0.6038278260530205\n",
            "g_loss:[0.3623514771461487, 0.3345993757247925, 0.013876058161258698]\n",
            "Batch:91\n",
            "d_loss_real:0.8559285402297974\n",
            "d_loss_fake:0.001123621128499508\n",
            "d_loss_wrong:0.7032937407493591\n",
            "d_loss:0.6040686105843633\n",
            "g_loss:[0.5457217693328857, 0.5175437927246094, 0.014088992029428482]\n",
            "Batch:92\n",
            "d_loss_real:0.9074270725250244\n",
            "d_loss_fake:0.0015980481402948499\n",
            "d_loss_wrong:0.6985465288162231\n",
            "d_loss:0.6287496805016417\n",
            "g_loss:[0.7188214063644409, 0.6924701929092407, 0.0131756030023098]\n",
            "Batch:93\n",
            "d_loss_real:0.863312840461731\n",
            "d_loss_fake:0.002085726708173752\n",
            "d_loss_wrong:0.6528745889663696\n",
            "d_loss:0.5953964991495013\n",
            "g_loss:[0.37347403168678284, 0.3385600447654724, 0.017456989735364914]\n",
            "Batch:94\n",
            "d_loss_real:0.8604551553726196\n",
            "d_loss_fake:0.00612118374556303\n",
            "d_loss_wrong:0.7091866731643677\n",
            "d_loss:0.6090545419137925\n",
            "g_loss:[0.42140117287635803, 0.38507717847824097, 0.018161997199058533]\n",
            "Batch:95\n",
            "d_loss_real:0.8752585649490356\n",
            "d_loss_fake:0.003635046537965536\n",
            "d_loss_wrong:0.684940755367279\n",
            "d_loss:0.609773232950829\n",
            "g_loss:[0.3804452419281006, 0.3472151458263397, 0.016615044325590134]\n",
            "Batch:96\n",
            "d_loss_real:0.8216091394424438\n",
            "d_loss_fake:0.0010724863968789577\n",
            "d_loss_wrong:0.6821196675300598\n",
            "d_loss:0.5816026082029566\n",
            "g_loss:[0.36792394518852234, 0.33791300654411316, 0.015005475841462612]\n",
            "Batch:97\n",
            "d_loss_real:0.8675788044929504\n",
            "d_loss_fake:0.0002366302505834028\n",
            "d_loss_wrong:0.6598548889160156\n",
            "d_loss:0.598812282038125\n",
            "g_loss:[0.34880170226097107, 0.32639411091804504, 0.011203796602785587]\n",
            "Batch:98\n",
            "d_loss_real:0.8694961667060852\n",
            "d_loss_fake:0.00045548417256213725\n",
            "d_loss_wrong:0.7079559564590454\n",
            "d_loss:0.6118509435109445\n",
            "g_loss:[0.35080376267433167, 0.33383357524871826, 0.008485088124871254]\n",
            "Batch:99\n",
            "d_loss_real:0.8654931783676147\n",
            "d_loss_fake:0.0006625776877626777\n",
            "d_loss_wrong:0.6462528705596924\n",
            "d_loss:0.5944754512456711\n",
            "g_loss:[0.35680538415908813, 0.3263421654701233, 0.015231605619192123]\n",
            "Batch:100\n",
            "d_loss_real:0.8794635534286499\n",
            "d_loss_fake:0.0006516030407510698\n",
            "d_loss_wrong:0.6354978084564209\n",
            "d_loss:0.5987691295886179\n",
            "g_loss:[0.502794086933136, 0.4681968688964844, 0.017298609018325806]\n",
            "Batch:101\n",
            "d_loss_real:0.8982739448547363\n",
            "d_loss_fake:0.0014720619656145573\n",
            "d_loss_wrong:0.7038136124610901\n",
            "d_loss:0.6254583910340443\n",
            "g_loss:[0.3614834249019623, 0.3251572251319885, 0.01816309615969658]\n",
            "Batch:102\n",
            "d_loss_real:0.874691903591156\n",
            "d_loss_fake:0.0007213350618258119\n",
            "d_loss_wrong:0.6625548005104065\n",
            "d_loss:0.6031649856886361\n",
            "g_loss:[0.35308870673179626, 0.3266453146934509, 0.01322169229388237]\n",
            "Batch:103\n",
            "d_loss_real:0.9006258249282837\n",
            "d_loss_fake:0.00539172999560833\n",
            "d_loss_wrong:0.6362634897232056\n",
            "d_loss:0.6107267173938453\n",
            "g_loss:[0.48505672812461853, 0.45939260721206665, 0.01283206231892109]\n",
            "Batch:104\n",
            "d_loss_real:0.8867833614349365\n",
            "d_loss_fake:0.0008756280294619501\n",
            "d_loss_wrong:0.6879911422729492\n",
            "d_loss:0.615608373293071\n",
            "g_loss:[0.37533342838287354, 0.34661275148391724, 0.014360336586833]\n",
            "Batch:105\n",
            "d_loss_real:0.8974900245666504\n",
            "d_loss_fake:0.0005846007843501866\n",
            "d_loss_wrong:0.6935446858406067\n",
            "d_loss:0.6222773339395644\n",
            "g_loss:[0.4244847595691681, 0.3992484211921692, 0.012618174776434898]\n",
            "Batch:106\n",
            "d_loss_real:0.8272778987884521\n",
            "d_loss_fake:0.0016077379696071148\n",
            "d_loss_wrong:0.6877446174621582\n",
            "d_loss:0.5859770382521674\n",
            "g_loss:[0.3678683042526245, 0.3381267488002777, 0.014870782382786274]\n",
            "Batch:107\n",
            "d_loss_real:0.8680328726768494\n",
            "d_loss_fake:0.0013237595558166504\n",
            "d_loss_wrong:0.6823873519897461\n",
            "d_loss:0.6049442142248154\n",
            "g_loss:[0.36622247099876404, 0.3315817415714264, 0.017320364713668823]\n",
            "Batch:108\n",
            "d_loss_real:0.870901346206665\n",
            "d_loss_fake:0.0010530310682952404\n",
            "d_loss_wrong:0.6524873375892639\n",
            "d_loss:0.5988357652677223\n",
            "g_loss:[0.35956907272338867, 0.3263832926750183, 0.01659289561212063]\n",
            "Batch:109\n",
            "d_loss_real:0.8682840466499329\n",
            "d_loss_fake:0.003526876447722316\n",
            "d_loss_wrong:0.6716721653938293\n",
            "d_loss:0.6029417837853543\n",
            "g_loss:[0.3507039248943329, 0.32714563608169556, 0.011779149062931538]\n",
            "Batch:110\n",
            "d_loss_real:0.831721842288971\n",
            "d_loss_fake:0.0010386952199041843\n",
            "d_loss_wrong:0.6818369626998901\n",
            "d_loss:0.586579835624434\n",
            "g_loss:[0.4102182686328888, 0.3898739218711853, 0.010172171518206596]\n",
            "Batch:111\n",
            "d_loss_real:0.8414673805236816\n",
            "d_loss_fake:0.0005986643955111504\n",
            "d_loss_wrong:0.6521481871604919\n",
            "d_loss:0.5839204031508416\n",
            "g_loss:[0.34989652037620544, 0.3267879784107208, 0.011554265394806862]\n",
            "Batch:112\n",
            "d_loss_real:0.8628079891204834\n",
            "d_loss_fake:0.0002563869347795844\n",
            "d_loss_wrong:0.6584761142730713\n",
            "d_loss:0.5960871198622044\n",
            "g_loss:[0.3488568365573883, 0.3260137438774109, 0.011421547271311283]\n",
            "Batch:113\n",
            "d_loss_real:0.8628547787666321\n",
            "d_loss_fake:0.006598657928407192\n",
            "d_loss_wrong:0.6615374684333801\n",
            "d_loss:0.5984614209737629\n",
            "g_loss:[0.6269393563270569, 0.6065528392791748, 0.010193254798650742]\n",
            "Batch:114\n",
            "d_loss_real:0.8201130628585815\n",
            "d_loss_fake:0.0005027696024626493\n",
            "d_loss_wrong:0.65301114320755\n",
            "d_loss:0.573435009631794\n",
            "g_loss:[0.37314990162849426, 0.3449925482273102, 0.014078682288527489]\n",
            "Batch:115\n",
            "d_loss_real:0.8489521741867065\n",
            "d_loss_fake:0.0018363350536674261\n",
            "d_loss_wrong:0.6602118611335754\n",
            "d_loss:0.589988136140164\n",
            "g_loss:[0.3703506588935852, 0.3380563259124756, 0.016147173941135406]\n",
            "Batch:116\n",
            "d_loss_real:0.8797734975814819\n",
            "d_loss_fake:0.0017410259461030364\n",
            "d_loss_wrong:0.6827942132949829\n",
            "d_loss:0.6110205586010125\n",
            "g_loss:[0.36740994453430176, 0.33947616815567017, 0.013966894708573818]\n",
            "Batch:117\n",
            "d_loss_real:0.8761997222900391\n",
            "d_loss_fake:0.00039749586721882224\n",
            "d_loss_wrong:0.6815091371536255\n",
            "d_loss:0.6085765194002306\n",
            "g_loss:[0.35635775327682495, 0.32753434777259827, 0.01441169623285532]\n",
            "Batch:118\n",
            "d_loss_real:0.838911235332489\n",
            "d_loss_fake:0.0034785897005349398\n",
            "d_loss_wrong:0.6655137538909912\n",
            "d_loss:0.586703703564126\n",
            "g_loss:[0.3516354560852051, 0.327508807182312, 0.012063322588801384]\n",
            "Batch:119\n",
            "d_loss_real:0.8491138815879822\n",
            "d_loss_fake:0.0017270958051085472\n",
            "d_loss_wrong:0.6623482704162598\n",
            "d_loss:0.5905757823493332\n",
            "g_loss:[0.34930020570755005, 0.3255104720592499, 0.011894868686795235]\n",
            "Batch:120\n",
            "d_loss_real:0.8523210287094116\n",
            "d_loss_fake:0.0009648210252635181\n",
            "d_loss_wrong:0.6722391247749329\n",
            "d_loss:0.5944615008047549\n",
            "g_loss:[0.34763723611831665, 0.3253583610057831, 0.011139440350234509]\n",
            "Batch:121\n",
            "d_loss_real:0.8826127648353577\n",
            "d_loss_fake:0.0006607884424738586\n",
            "d_loss_wrong:0.6647622585296631\n",
            "d_loss:0.6076621441607131\n",
            "g_loss:[0.3455090820789337, 0.3269995450973511, 0.009254769422113895]\n",
            "Batch:122\n",
            "d_loss_real:0.8393265008926392\n",
            "d_loss_fake:0.0018083829199895263\n",
            "d_loss_wrong:0.6701399683952332\n",
            "d_loss:0.5876503382751253\n",
            "g_loss:[0.34594953060150146, 0.3300890028476715, 0.007930267602205276]\n",
            "Batch:123\n",
            "d_loss_real:0.9315590858459473\n",
            "d_loss_fake:0.00029700680170208216\n",
            "d_loss_wrong:0.7007538676261902\n",
            "d_loss:0.6410422615299467\n",
            "g_loss:[0.7101859450340271, 0.6943907737731934, 0.007897571660578251]\n",
            "Batch:124\n",
            "d_loss_real:0.8748855590820312\n",
            "d_loss_fake:0.0018039646092802286\n",
            "d_loss_wrong:0.6542097926139832\n",
            "d_loss:0.6014462188468315\n",
            "g_loss:[0.35425499081611633, 0.33718621730804443, 0.0085343848913908]\n",
            "Batch:125\n",
            "d_loss_real:0.8102595806121826\n",
            "d_loss_fake:0.0014797732001170516\n",
            "d_loss_wrong:0.6775931715965271\n",
            "d_loss:0.5748980265052523\n",
            "g_loss:[0.6111661195755005, 0.5928420424461365, 0.009162035770714283]\n",
            "Batch:126\n",
            "d_loss_real:0.8361677527427673\n",
            "d_loss_fake:0.0020122104324400425\n",
            "d_loss_wrong:0.6676227450370789\n",
            "d_loss:0.5854926152387634\n",
            "g_loss:[0.36957550048828125, 0.3455367386341095, 0.012019379064440727]\n",
            "Batch:127\n",
            "d_loss_real:0.8978943824768066\n",
            "d_loss_fake:0.00045652390690520406\n",
            "d_loss_wrong:0.6435267925262451\n",
            "d_loss:0.6099430203466909\n",
            "g_loss:[0.610302746295929, 0.5877334475517273, 0.011284641921520233]\n",
            "Batch:128\n",
            "d_loss_real:0.8446645736694336\n",
            "d_loss_fake:0.0009065918857231736\n",
            "d_loss_wrong:0.6918802261352539\n",
            "d_loss:0.5955289913399611\n",
            "g_loss:[0.36411383748054504, 0.3316303491592407, 0.016241738572716713]\n",
            "Batch:129\n",
            "d_loss_real:0.8467332124710083\n",
            "d_loss_fake:0.0015730083687230945\n",
            "d_loss_wrong:0.6769421100616455\n",
            "d_loss:0.5929953858430963\n",
            "g_loss:[0.37323248386383057, 0.3428625464439392, 0.015184962190687656]\n",
            "Batch:130\n",
            "d_loss_real:0.8380252718925476\n",
            "d_loss_fake:0.0009137581801041961\n",
            "d_loss_wrong:0.693780779838562\n",
            "d_loss:0.5926862704509404\n",
            "g_loss:[0.3630523085594177, 0.34151574969291687, 0.010768283158540726]\n",
            "Batch:131\n",
            "d_loss_real:0.8988298177719116\n",
            "d_loss_fake:0.0018202477367594838\n",
            "d_loss_wrong:0.6724363565444946\n",
            "d_loss:0.6179790599562693\n",
            "g_loss:[0.36134469509124756, 0.3409992754459381, 0.010172704234719276]\n",
            "Batch:132\n",
            "d_loss_real:0.837831974029541\n",
            "d_loss_fake:0.0008092215866781771\n",
            "d_loss_wrong:0.6742483377456665\n",
            "d_loss:0.5876803768478567\n",
            "g_loss:[0.3613135516643524, 0.339852511882782, 0.010730516165494919]\n",
            "Batch:133\n",
            "d_loss_real:0.8369749188423157\n",
            "d_loss_fake:0.0012921278830617666\n",
            "d_loss_wrong:0.6804651021957397\n",
            "d_loss:0.5889267669408582\n",
            "g_loss:[0.3498575687408447, 0.32554516196250916, 0.012156201526522636]\n",
            "Batch:134\n",
            "d_loss_real:0.8440746068954468\n",
            "d_loss_fake:0.0007667913450859487\n",
            "d_loss_wrong:0.6673819422721863\n",
            "d_loss:0.5890744868520414\n",
            "g_loss:[0.35181158781051636, 0.3295297622680664, 0.011140909045934677]\n",
            "Batch:135\n",
            "d_loss_real:0.8694909811019897\n",
            "d_loss_fake:0.0008555533131584525\n",
            "d_loss_wrong:0.650153398513794\n",
            "d_loss:0.597497728507733\n",
            "g_loss:[0.3484233319759369, 0.3253011703491211, 0.0115610770881176]\n",
            "Batch:136\n",
            "d_loss_real:0.8470260500907898\n",
            "d_loss_fake:0.0002037506055785343\n",
            "d_loss_wrong:0.6721387505531311\n",
            "d_loss:0.5915986503350723\n",
            "g_loss:[0.34468284249305725, 0.32588744163513184, 0.009397699497640133]\n",
            "Batch:137\n",
            "d_loss_real:0.8366326093673706\n",
            "d_loss_fake:0.00039116875268518925\n",
            "d_loss_wrong:0.6708250641822815\n",
            "d_loss:0.586120362917427\n",
            "g_loss:[0.3442458510398865, 0.32610195875167847, 0.009071948006749153]\n",
            "Batch:138\n",
            "d_loss_real:0.8430774211883545\n",
            "d_loss_fake:0.0013519605854526162\n",
            "d_loss_wrong:0.6566141247749329\n",
            "d_loss:0.5860302319342736\n",
            "g_loss:[0.6296730041503906, 0.6119705438613892, 0.00885123573243618]\n",
            "========================================\n",
            "Epoch is: 2\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.878711462020874\n",
            "d_loss_fake:0.000958452292252332\n",
            "d_loss_wrong:0.6984763741493225\n",
            "d_loss:0.6142144376208307\n",
            "g_loss:[0.37817278504371643, 0.3651227355003357, 0.006525025703012943]\n",
            "Batch:2\n",
            "d_loss_real:0.8476652503013611\n",
            "d_loss_fake:0.0005415121559053659\n",
            "d_loss_wrong:0.6889017224311829\n",
            "d_loss:0.5961934337974526\n",
            "g_loss:[0.4579567015171051, 0.4444882571697235, 0.006734216120094061]\n",
            "Batch:3\n",
            "d_loss_real:0.8597545623779297\n",
            "d_loss_fake:0.0005879274685867131\n",
            "d_loss_wrong:0.6665317416191101\n",
            "d_loss:0.596657198460889\n",
            "g_loss:[0.3451637923717499, 0.3316698670387268, 0.006746969185769558]\n",
            "Batch:4\n",
            "d_loss_real:0.8953574299812317\n",
            "d_loss_fake:0.0005886434228159487\n",
            "d_loss_wrong:0.722836434841156\n",
            "d_loss:0.6285349845566088\n",
            "g_loss:[0.36139437556266785, 0.34423184394836426, 0.008581267669796944]\n",
            "Batch:5\n",
            "d_loss_real:0.8384578227996826\n",
            "d_loss_fake:0.00032063317485153675\n",
            "d_loss_wrong:0.741772472858429\n",
            "d_loss:0.6047521879081614\n",
            "g_loss:[0.362548828125, 0.3433244228363037, 0.009612204506993294]\n",
            "Batch:6\n",
            "d_loss_real:0.8523908257484436\n",
            "d_loss_fake:0.0008636885322630405\n",
            "d_loss_wrong:0.7543393969535828\n",
            "d_loss:0.6149961842456833\n",
            "g_loss:[0.3490387499332428, 0.32811611890792847, 0.010461321100592613]\n",
            "Batch:7\n",
            "d_loss_real:0.8574789762496948\n",
            "d_loss_fake:0.001670128433033824\n",
            "d_loss_wrong:0.6679440140724182\n",
            "d_loss:0.5961430237512104\n",
            "g_loss:[0.3508076071739197, 0.33287352323532104, 0.008967035450041294]\n",
            "Batch:8\n",
            "d_loss_real:0.8625329732894897\n",
            "d_loss_fake:0.0009623933583498001\n",
            "d_loss_wrong:0.6127068400382996\n",
            "d_loss:0.5846837949939072\n",
            "g_loss:[0.3670006990432739, 0.34620964527130127, 0.010395534336566925]\n",
            "Batch:9\n",
            "d_loss_real:0.8686643838882446\n",
            "d_loss_fake:0.00027373075135983527\n",
            "d_loss_wrong:0.6427939534187317\n",
            "d_loss:0.5950991129866452\n",
            "g_loss:[0.34525471925735474, 0.3262307047843933, 0.00951200071722269]\n",
            "Batch:10\n",
            "d_loss_real:0.8703527450561523\n",
            "d_loss_fake:0.0008841206436045468\n",
            "d_loss_wrong:0.6334819197654724\n",
            "d_loss:0.5937678826303454\n",
            "g_loss:[0.34020471572875977, 0.32591554522514343, 0.0071445852518081665]\n",
            "Batch:11\n",
            "d_loss_real:0.8926022052764893\n",
            "d_loss_fake:0.0006150125991553068\n",
            "d_loss_wrong:0.6371887922286987\n",
            "d_loss:0.6057520538452081\n",
            "g_loss:[0.39633283019065857, 0.3811044991016388, 0.007614158559590578]\n",
            "Batch:12\n",
            "d_loss_real:0.8665453791618347\n",
            "d_loss_fake:0.000669631757773459\n",
            "d_loss_wrong:0.6689814329147339\n",
            "d_loss:0.6006854557490442\n",
            "g_loss:[0.34659644961357117, 0.3294413089752197, 0.008577566593885422]\n",
            "Batch:13\n",
            "d_loss_real:0.8433396816253662\n",
            "d_loss_fake:0.0006541617913171649\n",
            "d_loss_wrong:0.6780909895896912\n",
            "d_loss:0.5913561286579352\n",
            "g_loss:[0.3621324896812439, 0.34635838866233826, 0.007887046784162521]\n",
            "Batch:14\n",
            "d_loss_real:0.877932071685791\n",
            "d_loss_fake:0.0006906442577019334\n",
            "d_loss_wrong:0.6824259757995605\n",
            "d_loss:0.6097451908572111\n",
            "g_loss:[0.34282541275024414, 0.3275207281112671, 0.007652335334569216]\n",
            "Batch:15\n",
            "d_loss_real:0.8678299784660339\n",
            "d_loss_fake:0.029336504638195038\n",
            "d_loss_wrong:0.695169985294342\n",
            "d_loss:0.6150416117161512\n",
            "g_loss:[0.34676292538642883, 0.3340006470680237, 0.0063811433501541615]\n",
            "Batch:16\n",
            "d_loss_real:0.863591194152832\n",
            "d_loss_fake:0.00035970270982943475\n",
            "d_loss_wrong:0.7080801725387573\n",
            "d_loss:0.6089055658885627\n",
            "g_loss:[0.7498927712440491, 0.736700177192688, 0.006596295163035393]\n",
            "Batch:17\n",
            "d_loss_real:0.8892734050750732\n",
            "d_loss_fake:0.002533902646973729\n",
            "d_loss_wrong:0.7463525533676147\n",
            "d_loss:0.6318583165411837\n",
            "g_loss:[0.5057756900787354, 0.48789897561073303, 0.008938344195485115]\n",
            "Batch:18\n",
            "d_loss_real:0.8671334981918335\n",
            "d_loss_fake:0.014288818463683128\n",
            "d_loss_wrong:0.6530504822731018\n",
            "d_loss:0.600401574280113\n",
            "g_loss:[0.45854470133781433, 0.43572503328323364, 0.011409839615225792]\n",
            "Batch:19\n",
            "d_loss_real:0.9261130094528198\n",
            "d_loss_fake:6.34690368315205e-05\n",
            "d_loss_wrong:0.6699246764183044\n",
            "d_loss:0.6305535410901939\n",
            "g_loss:[0.5115424394607544, 0.4895137548446655, 0.011014342308044434]\n",
            "Batch:20\n",
            "d_loss_real:0.9043653011322021\n",
            "d_loss_fake:0.0002808196877595037\n",
            "d_loss_wrong:0.7093116044998169\n",
            "d_loss:0.6295807566129952\n",
            "g_loss:[0.48346850275993347, 0.4555080533027649, 0.013980230316519737]\n",
            "Batch:21\n",
            "d_loss_real:0.8901269435882568\n",
            "d_loss_fake:0.0011814525350928307\n",
            "d_loss_wrong:0.622495710849762\n",
            "d_loss:0.6009827626403421\n",
            "g_loss:[0.5194945931434631, 0.4916660785675049, 0.013914271257817745]\n",
            "Batch:22\n",
            "d_loss_real:0.8685963749885559\n",
            "d_loss_fake:0.0036085848696529865\n",
            "d_loss_wrong:0.6947773694992065\n",
            "d_loss:0.6088946760864928\n",
            "g_loss:[0.4375452995300293, 0.40789344906806946, 0.014825931750237942]\n",
            "Batch:23\n",
            "d_loss_real:0.8368802666664124\n",
            "d_loss_fake:0.005549749359488487\n",
            "d_loss_wrong:0.6885004639625549\n",
            "d_loss:0.591952686663717\n",
            "g_loss:[0.4190160036087036, 0.39100927114486694, 0.014003363437950611]\n",
            "Batch:24\n",
            "d_loss_real:0.837932288646698\n",
            "d_loss_fake:0.0029345781076699495\n",
            "d_loss_wrong:0.6561340093612671\n",
            "d_loss:0.5837332911905833\n",
            "g_loss:[0.4974765181541443, 0.46980154514312744, 0.0138374799862504]\n",
            "Batch:25\n",
            "d_loss_real:0.8830790519714355\n",
            "d_loss_fake:0.0016771471127867699\n",
            "d_loss_wrong:0.7194169759750366\n",
            "d_loss:0.6218130567576736\n",
            "g_loss:[0.4070860743522644, 0.3723422884941101, 0.01737188920378685]\n",
            "Batch:26\n",
            "d_loss_real:0.861288845539093\n",
            "d_loss_fake:0.0010637848172336817\n",
            "d_loss_wrong:0.6696814894676208\n",
            "d_loss:0.5983307413407601\n",
            "g_loss:[0.3785615563392639, 0.35100993514060974, 0.013775814324617386]\n",
            "Batch:27\n",
            "d_loss_real:0.9251152276992798\n",
            "d_loss_fake:0.001819771365262568\n",
            "d_loss_wrong:0.7360183596611023\n",
            "d_loss:0.6470171466062311\n",
            "g_loss:[0.37002885341644287, 0.338062047958374, 0.015983404591679573]\n",
            "Batch:28\n",
            "d_loss_real:0.8476372957229614\n",
            "d_loss_fake:0.0009151166887022555\n",
            "d_loss_wrong:0.6213377714157104\n",
            "d_loss:0.5793818698875839\n",
            "g_loss:[0.3757491409778595, 0.3463602364063263, 0.014694456942379475]\n",
            "Batch:29\n",
            "d_loss_real:0.8665378093719482\n",
            "d_loss_fake:0.0005294795846566558\n",
            "d_loss_wrong:0.6603776216506958\n",
            "d_loss:0.5984956799948122\n",
            "g_loss:[0.3586604595184326, 0.33334606885910034, 0.01265719160437584]\n",
            "Batch:30\n",
            "d_loss_real:0.8714938163757324\n",
            "d_loss_fake:0.00022382003953680396\n",
            "d_loss_wrong:0.7480118274688721\n",
            "d_loss:0.6228058200649684\n",
            "g_loss:[0.35126733779907227, 0.3268394470214844, 0.012213950976729393]\n",
            "Batch:31\n",
            "d_loss_real:0.832861602306366\n",
            "d_loss_fake:0.0009890457149595022\n",
            "d_loss_wrong:0.6850386261940002\n",
            "d_loss:0.5879377191304229\n",
            "g_loss:[0.5455883145332336, 0.5193289518356323, 0.013129671104252338]\n",
            "Batch:32\n",
            "d_loss_real:0.8663833141326904\n",
            "d_loss_fake:0.00030600157333537936\n",
            "d_loss_wrong:0.6241582632064819\n",
            "d_loss:0.5893077232612995\n",
            "g_loss:[0.3654995858669281, 0.3303915560245514, 0.017554011195898056]\n",
            "Batch:33\n",
            "d_loss_real:0.8609954118728638\n",
            "d_loss_fake:0.0008436235948465765\n",
            "d_loss_wrong:0.6581709980964661\n",
            "d_loss:0.59525136135926\n",
            "g_loss:[0.3674432337284088, 0.3416450023651123, 0.012899109162390232]\n",
            "Batch:34\n",
            "d_loss_real:0.8617123961448669\n",
            "d_loss_fake:0.001388241769745946\n",
            "d_loss_wrong:0.6421812772750854\n",
            "d_loss:0.5917485778336413\n",
            "g_loss:[0.5310977101325989, 0.5053822994232178, 0.012857701629400253]\n",
            "Batch:35\n",
            "d_loss_real:0.8765345811843872\n",
            "d_loss_fake:0.002629882888868451\n",
            "d_loss_wrong:0.6876693367958069\n",
            "d_loss:0.6108420955133624\n",
            "g_loss:[0.36998724937438965, 0.3404127061367035, 0.014787274412810802]\n",
            "Batch:36\n",
            "d_loss_real:0.8325831890106201\n",
            "d_loss_fake:0.001308509730733931\n",
            "d_loss_wrong:0.6717057228088379\n",
            "d_loss:0.584545152640203\n",
            "g_loss:[0.3624110817909241, 0.3368260860443115, 0.012792503461241722]\n",
            "Batch:37\n",
            "d_loss_real:0.846107542514801\n",
            "d_loss_fake:0.0004331468662712723\n",
            "d_loss_wrong:0.7072023749351501\n",
            "d_loss:0.5999626517077559\n",
            "g_loss:[0.3564688265323639, 0.3338412046432495, 0.011313805356621742]\n",
            "Batch:38\n",
            "d_loss_real:0.8857196569442749\n",
            "d_loss_fake:0.0008252008119598031\n",
            "d_loss_wrong:0.6853086352348328\n",
            "d_loss:0.6143932874838356\n",
            "g_loss:[0.5013678669929504, 0.4804476797580719, 0.01046009175479412]\n",
            "Batch:39\n",
            "d_loss_real:0.8522059917449951\n",
            "d_loss_fake:0.0006507680518552661\n",
            "d_loss_wrong:0.669055163860321\n",
            "d_loss:0.5935294788505416\n",
            "g_loss:[0.35479307174682617, 0.32716307044029236, 0.013815001584589481]\n",
            "Batch:40\n",
            "d_loss_real:0.8699607253074646\n",
            "d_loss_fake:0.0009143503848463297\n",
            "d_loss_wrong:0.7964450716972351\n",
            "d_loss:0.6343202181742527\n",
            "g_loss:[0.35958802700042725, 0.3292902410030365, 0.0151488883420825]\n",
            "Batch:41\n",
            "d_loss_real:0.8640660047531128\n",
            "d_loss_fake:0.002193025778979063\n",
            "d_loss_wrong:0.6604994535446167\n",
            "d_loss:0.5977061222074553\n",
            "g_loss:[0.5496699810028076, 0.521652102470398, 0.014008946716785431]\n",
            "Batch:42\n",
            "d_loss_real:0.9169960021972656\n",
            "d_loss_fake:0.0004917967016808689\n",
            "d_loss_wrong:0.6604297161102295\n",
            "d_loss:0.6237283793016104\n",
            "g_loss:[0.37096720933914185, 0.32908380031585693, 0.020941710099577904]\n",
            "Batch:43\n",
            "d_loss_real:0.8351641893386841\n",
            "d_loss_fake:0.0004758173308800906\n",
            "d_loss_wrong:0.6465833187103271\n",
            "d_loss:0.5793468786796439\n",
            "g_loss:[0.4466133117675781, 0.3981696665287018, 0.024221817031502724]\n",
            "Batch:44\n",
            "d_loss_real:0.8518375754356384\n",
            "d_loss_fake:0.000726841390132904\n",
            "d_loss_wrong:0.680445671081543\n",
            "d_loss:0.5962119158357382\n",
            "g_loss:[0.40131527185440063, 0.3587837219238281, 0.021265767514705658]\n",
            "Batch:45\n",
            "d_loss_real:0.824402391910553\n",
            "d_loss_fake:0.0005873260088264942\n",
            "d_loss_wrong:0.6368468999862671\n",
            "d_loss:0.5715597524540499\n",
            "g_loss:[0.3839986026287079, 0.34335434436798096, 0.020322129130363464]\n",
            "Batch:46\n",
            "d_loss_real:0.8517758846282959\n",
            "d_loss_fake:0.0006506336503662169\n",
            "d_loss_wrong:0.6728644371032715\n",
            "d_loss:0.5942667100025574\n",
            "g_loss:[0.3769248127937317, 0.33665671944618225, 0.02013404667377472]\n",
            "Batch:47\n",
            "d_loss_real:0.8580509424209595\n",
            "d_loss_fake:0.0012002174044027925\n",
            "d_loss_wrong:0.6827002763748169\n",
            "d_loss:0.6000005946552847\n",
            "g_loss:[0.3703455328941345, 0.3314056694507599, 0.01946992427110672]\n",
            "Batch:48\n",
            "d_loss_real:0.8609133958816528\n",
            "d_loss_fake:0.0006294094491750002\n",
            "d_loss_wrong:0.6468454003334045\n",
            "d_loss:0.5923254003864713\n",
            "g_loss:[0.37911364436149597, 0.3427354693412781, 0.018189091235399246]\n",
            "Batch:49\n",
            "d_loss_real:0.8376089930534363\n",
            "d_loss_fake:0.00288602989166975\n",
            "d_loss_wrong:0.6398940682411194\n",
            "d_loss:0.5794995210599154\n",
            "g_loss:[0.3677845299243927, 0.33608973026275635, 0.015847403556108475]\n",
            "Batch:50\n",
            "d_loss_real:0.8417942523956299\n",
            "d_loss_fake:0.000489741622004658\n",
            "d_loss_wrong:0.6550344228744507\n",
            "d_loss:0.5847781673219288\n",
            "g_loss:[0.3595157861709595, 0.33032339811325073, 0.014596192166209221]\n",
            "Batch:51\n",
            "d_loss_real:0.8506050705909729\n",
            "d_loss_fake:0.00019025268557015806\n",
            "d_loss_wrong:0.6646252870559692\n",
            "d_loss:0.5915064202308713\n",
            "g_loss:[0.3575041592121124, 0.3317659795284271, 0.012869087979197502]\n",
            "Batch:52\n",
            "d_loss_real:0.8543707728385925\n",
            "d_loss_fake:0.00015929777873679996\n",
            "d_loss_wrong:0.6831628680229187\n",
            "d_loss:0.5980159278697101\n",
            "g_loss:[0.35169926285743713, 0.32622361183166504, 0.01273783203214407]\n",
            "Batch:53\n",
            "d_loss_real:0.854885995388031\n",
            "d_loss_fake:0.0005153627716936171\n",
            "d_loss_wrong:0.6557976007461548\n",
            "d_loss:0.5915212385734776\n",
            "g_loss:[0.35084396600723267, 0.3295513391494751, 0.010646319016814232]\n",
            "Batch:54\n",
            "d_loss_real:0.8361692428588867\n",
            "d_loss_fake:0.00031751469941809773\n",
            "d_loss_wrong:0.68901526927948\n",
            "d_loss:0.5904178174241679\n",
            "g_loss:[0.3458239436149597, 0.32874083518981934, 0.008541553281247616]\n",
            "Batch:55\n",
            "d_loss_real:0.8336343765258789\n",
            "d_loss_fake:0.0002494736691005528\n",
            "d_loss_wrong:0.6632875800132751\n",
            "d_loss:0.5827014516835334\n",
            "g_loss:[0.3484745919704437, 0.32877886295318604, 0.009847869165241718]\n",
            "Batch:56\n",
            "d_loss_real:0.8728256225585938\n",
            "d_loss_fake:0.0004615952493622899\n",
            "d_loss_wrong:0.7070493698120117\n",
            "d_loss:0.6132905525446404\n",
            "g_loss:[0.35164302587509155, 0.32866084575653076, 0.01149109099060297]\n",
            "Batch:57\n",
            "d_loss_real:0.8558734655380249\n",
            "d_loss_fake:0.00023302968475036323\n",
            "d_loss_wrong:0.6554028391838074\n",
            "d_loss:0.5918456999861519\n",
            "g_loss:[0.3514363765716553, 0.33144235610961914, 0.00999701488763094]\n",
            "Batch:58\n",
            "d_loss_real:0.835866391658783\n",
            "d_loss_fake:0.0005027440492995083\n",
            "d_loss_wrong:0.659489631652832\n",
            "d_loss:0.5829312897549244\n",
            "g_loss:[0.34693145751953125, 0.3284466564655304, 0.009242394007742405]\n",
            "Batch:59\n",
            "d_loss_real:0.874320387840271\n",
            "d_loss_fake:0.000244633003603667\n",
            "d_loss_wrong:0.6759335994720459\n",
            "d_loss:0.6062047520390479\n",
            "g_loss:[0.34707432985305786, 0.32892146706581116, 0.009076436050236225]\n",
            "Batch:60\n",
            "d_loss_real:0.85779869556427\n",
            "d_loss_fake:0.00018375774379819632\n",
            "d_loss_wrong:0.6967217326164246\n",
            "d_loss:0.6031257203721907\n",
            "g_loss:[0.3475237190723419, 0.32824546098709106, 0.009639127179980278]\n",
            "Batch:61\n",
            "d_loss_real:0.854996919631958\n",
            "d_loss_fake:0.0002522264840081334\n",
            "d_loss_wrong:0.675315797328949\n",
            "d_loss:0.5963904657692183\n",
            "g_loss:[0.34462857246398926, 0.325685977935791, 0.009471300058066845]\n",
            "Batch:62\n",
            "d_loss_real:0.862642228603363\n",
            "d_loss_fake:0.0002266366791445762\n",
            "d_loss_wrong:0.6558681726455688\n",
            "d_loss:0.5953448166328599\n",
            "g_loss:[0.343363881111145, 0.3266584873199463, 0.008352698758244514]\n",
            "Batch:63\n",
            "d_loss_real:0.858269989490509\n",
            "d_loss_fake:0.0003529053064994514\n",
            "d_loss_wrong:0.6720832586288452\n",
            "d_loss:0.5972440357290907\n",
            "g_loss:[0.34534090757369995, 0.32771745324134827, 0.008811727166175842]\n",
            "Batch:64\n",
            "d_loss_real:0.8351017832756042\n",
            "d_loss_fake:0.0006785694276914\n",
            "d_loss_wrong:0.6563345789909363\n",
            "d_loss:0.581804178742459\n",
            "g_loss:[0.3432042896747589, 0.32611000537872314, 0.008547138422727585]\n",
            "Batch:65\n",
            "d_loss_real:0.8992764353752136\n",
            "d_loss_fake:0.0005186758935451508\n",
            "d_loss_wrong:0.707764208316803\n",
            "d_loss:0.6267089387401938\n",
            "g_loss:[0.34089070558547974, 0.32524460554122925, 0.007823044434189796]\n",
            "Batch:66\n",
            "d_loss_real:0.8112819790840149\n",
            "d_loss_fake:0.0004948610439896584\n",
            "d_loss_wrong:0.6778366565704346\n",
            "d_loss:0.5752238689456135\n",
            "g_loss:[0.34244051575660706, 0.3263940215110779, 0.008023250848054886]\n",
            "Batch:67\n",
            "d_loss_real:0.8853795528411865\n",
            "d_loss_fake:0.0001505694235675037\n",
            "d_loss_wrong:0.6348198056221008\n",
            "d_loss:0.6014323701820103\n",
            "g_loss:[0.3500128984451294, 0.33564600348472595, 0.007183448877185583]\n",
            "Batch:68\n",
            "d_loss_real:0.867634117603302\n",
            "d_loss_fake:0.00022104506206233054\n",
            "d_loss_wrong:0.6962162256240845\n",
            "d_loss:0.6079263764731877\n",
            "g_loss:[0.3429873287677765, 0.3285573124885559, 0.007215003948658705]\n",
            "Batch:69\n",
            "d_loss_real:0.8787065148353577\n",
            "d_loss_fake:0.0005322340875864029\n",
            "d_loss_wrong:0.7250677943229675\n",
            "d_loss:0.6207532645203173\n",
            "g_loss:[0.3467530310153961, 0.3324822187423706, 0.007135411258786917]\n",
            "Batch:70\n",
            "d_loss_real:0.8371354341506958\n",
            "d_loss_fake:0.0001942725502885878\n",
            "d_loss_wrong:0.6895344257354736\n",
            "d_loss:0.5909998916467885\n",
            "g_loss:[0.4607662260532379, 0.44678860902786255, 0.006988812237977982]\n",
            "Batch:71\n",
            "d_loss_real:0.8315685391426086\n",
            "d_loss_fake:0.0007724204333499074\n",
            "d_loss_wrong:0.6621204018592834\n",
            "d_loss:0.5815074751444627\n",
            "g_loss:[0.3616270422935486, 0.3463992476463318, 0.007613890338689089]\n",
            "Batch:72\n",
            "d_loss_real:0.859532356262207\n",
            "d_loss_fake:0.0006584989605471492\n",
            "d_loss_wrong:0.6747887134552002\n",
            "d_loss:0.5986279812350404\n",
            "g_loss:[0.34451836347579956, 0.3305061459541321, 0.007006111554801464]\n",
            "Batch:73\n",
            "d_loss_real:0.8446624875068665\n",
            "d_loss_fake:0.00040870480006560683\n",
            "d_loss_wrong:0.676054060459137\n",
            "d_loss:0.5914469350682339\n",
            "g_loss:[0.35189923644065857, 0.33515864610671997, 0.008370301686227322]\n",
            "Batch:74\n",
            "d_loss_real:0.8931593894958496\n",
            "d_loss_fake:0.0009359396062791348\n",
            "d_loss_wrong:0.6861979365348816\n",
            "d_loss:0.618363163783215\n",
            "g_loss:[0.46000489592552185, 0.4433438181877136, 0.008330542594194412]\n",
            "Batch:75\n",
            "d_loss_real:0.8688080906867981\n",
            "d_loss_fake:0.010774897411465645\n",
            "d_loss_wrong:0.6623207926750183\n",
            "d_loss:0.60267796786502\n",
            "g_loss:[0.4278210699558258, 0.4115787744522095, 0.008121142163872719]\n",
            "Batch:76\n",
            "d_loss_real:0.8595507740974426\n",
            "d_loss_fake:0.00010206212755292654\n",
            "d_loss_wrong:0.6594972014427185\n",
            "d_loss:0.5946752029412892\n",
            "g_loss:[0.4075399339199066, 0.39159226417541504, 0.007973829284310341]\n",
            "Batch:77\n",
            "d_loss_real:0.8581562042236328\n",
            "d_loss_fake:0.0011073166970163584\n",
            "d_loss_wrong:0.6690248847007751\n",
            "d_loss:0.5966111524612643\n",
            "g_loss:[0.37400054931640625, 0.35667306184768677, 0.008663751184940338]\n",
            "Batch:78\n",
            "d_loss_real:0.850256621837616\n",
            "d_loss_fake:0.0008197148563340306\n",
            "d_loss_wrong:0.6686000227928162\n",
            "d_loss:0.5924832453310955\n",
            "g_loss:[0.3810904622077942, 0.3658201992511749, 0.007635126356035471]\n",
            "Batch:79\n",
            "d_loss_real:0.8497650027275085\n",
            "d_loss_fake:0.00028863822808489203\n",
            "d_loss_wrong:0.6596660017967224\n",
            "d_loss:0.5898711613699561\n",
            "g_loss:[0.4143199324607849, 0.3982768654823303, 0.008021536283195019]\n",
            "Batch:80\n",
            "d_loss_real:0.8376717567443848\n",
            "d_loss_fake:0.00018918140267487615\n",
            "d_loss_wrong:0.6605064272880554\n",
            "d_loss:0.584009780544875\n",
            "g_loss:[0.7673933506011963, 0.7500748038291931, 0.00865928828716278]\n",
            "Batch:81\n",
            "d_loss_real:0.8531114459037781\n",
            "d_loss_fake:0.0005225301720201969\n",
            "d_loss_wrong:0.6322993040084839\n",
            "d_loss:0.5847611814970151\n",
            "g_loss:[0.37672606110572815, 0.35328808426856995, 0.01171899028122425]\n",
            "Batch:82\n",
            "d_loss_real:0.9028341174125671\n",
            "d_loss_fake:0.00018787813314702362\n",
            "d_loss_wrong:0.6705033779144287\n",
            "d_loss:0.6190898727181775\n",
            "g_loss:[0.3956387937068939, 0.36947041749954224, 0.01308419369161129]\n",
            "Batch:83\n",
            "d_loss_real:0.7985625267028809\n",
            "d_loss_fake:7.414798892568797e-05\n",
            "d_loss_wrong:0.6517122387886047\n",
            "d_loss:0.562227860045823\n",
            "g_loss:[0.3923218250274658, 0.36698585748672485, 0.012667980045080185]\n",
            "Batch:84\n",
            "d_loss_real:0.8527880907058716\n",
            "d_loss_fake:0.00012030461221002042\n",
            "d_loss_wrong:0.6760287284851074\n",
            "d_loss:0.5954313036272652\n",
            "g_loss:[0.3669033944606781, 0.34247905015945435, 0.012212173081934452]\n",
            "Batch:85\n",
            "d_loss_real:0.8355850577354431\n",
            "d_loss_fake:0.008805861696600914\n",
            "d_loss_wrong:0.6739220023155212\n",
            "d_loss:0.5884744948707521\n",
            "g_loss:[0.35547441244125366, 0.3319636583328247, 0.01175536960363388]\n",
            "Batch:86\n",
            "d_loss_real:0.8424980640411377\n",
            "d_loss_fake:0.0005241351900622249\n",
            "d_loss_wrong:0.6559406518936157\n",
            "d_loss:0.5853652287914883\n",
            "g_loss:[0.3559352159500122, 0.33441388607025146, 0.010760667733848095]\n",
            "Batch:87\n",
            "d_loss_real:0.8436992764472961\n",
            "d_loss_fake:0.0002514598018024117\n",
            "d_loss_wrong:0.6554483771324158\n",
            "d_loss:0.5857745974572026\n",
            "g_loss:[0.35005316138267517, 0.33040568232536316, 0.009823733940720558]\n",
            "Batch:88\n",
            "d_loss_real:0.8554667234420776\n",
            "d_loss_fake:0.00019258708925917745\n",
            "d_loss_wrong:0.6839731335639954\n",
            "d_loss:0.5987747918843525\n",
            "g_loss:[0.34884071350097656, 0.33162879943847656, 0.008605963550508022]\n",
            "Batch:89\n",
            "d_loss_real:0.8597025871276855\n",
            "d_loss_fake:0.00017108270549215376\n",
            "d_loss_wrong:0.6683660745620728\n",
            "d_loss:0.596985582880734\n",
            "g_loss:[0.34378883242607117, 0.3255653977394104, 0.009111721999943256]\n",
            "Batch:90\n",
            "d_loss_real:0.8451478481292725\n",
            "d_loss_fake:0.0001680710120126605\n",
            "d_loss_wrong:0.6844254732131958\n",
            "d_loss:0.5937223101209383\n",
            "g_loss:[0.5380358695983887, 0.5189337730407715, 0.009551046416163445]\n",
            "Batch:91\n",
            "d_loss_real:0.8444889783859253\n",
            "d_loss_fake:0.000522518006619066\n",
            "d_loss_wrong:0.6915596723556519\n",
            "d_loss:0.5952650367835304\n",
            "g_loss:[0.35901594161987305, 0.3337189555168152, 0.012648490257561207]\n",
            "Batch:92\n",
            "d_loss_real:0.8820702433586121\n",
            "d_loss_fake:0.0007451542187482119\n",
            "d_loss_wrong:0.6757732033729553\n",
            "d_loss:0.6101647110772319\n",
            "g_loss:[0.37955355644226074, 0.34284427762031555, 0.018354635685682297]\n",
            "Batch:93\n",
            "d_loss_real:0.8399685621261597\n",
            "d_loss_fake:0.00044071575393900275\n",
            "d_loss_wrong:0.6496356725692749\n",
            "d_loss:0.5825033781438833\n",
            "g_loss:[0.3585171401500702, 0.33189189434051514, 0.013312622904777527]\n",
            "Batch:94\n",
            "d_loss_real:0.8452332615852356\n",
            "d_loss_fake:0.0050414931029081345\n",
            "d_loss_wrong:0.691470742225647\n",
            "d_loss:0.5967446896247566\n",
            "g_loss:[0.37343400716781616, 0.3513832092285156, 0.01102539524435997]\n",
            "Batch:95\n",
            "d_loss_real:0.8681414127349854\n",
            "d_loss_fake:7.977589848451316e-05\n",
            "d_loss_wrong:0.675565242767334\n",
            "d_loss:0.6029819610339473\n",
            "g_loss:[0.48308876156806946, 0.46210411190986633, 0.010492321103811264]\n",
            "Batch:96\n",
            "d_loss_real:0.8102636933326721\n",
            "d_loss_fake:4.0436338167637587e-05\n",
            "d_loss_wrong:0.6762098073959351\n",
            "d_loss:0.5741944075998617\n",
            "g_loss:[0.4114183187484741, 0.3827880620956421, 0.01431512925773859]\n",
            "Batch:97\n",
            "d_loss_real:0.8450107574462891\n",
            "d_loss_fake:7.508710405090824e-05\n",
            "d_loss_wrong:0.6569188237190247\n",
            "d_loss:0.5867538564289134\n",
            "g_loss:[0.42048174142837524, 0.3884349763393402, 0.016023389995098114]\n",
            "Batch:98\n",
            "d_loss_real:0.8634195327758789\n",
            "d_loss_fake:0.00011777336476370692\n",
            "d_loss_wrong:0.7005730867385864\n",
            "d_loss:0.606882481413777\n",
            "g_loss:[0.37313297390937805, 0.3312094807624817, 0.020961740985512733]\n",
            "Batch:99\n",
            "d_loss_real:0.8435344696044922\n",
            "d_loss_fake:0.00017529977776575834\n",
            "d_loss_wrong:0.6426001787185669\n",
            "d_loss:0.5824611044263293\n",
            "g_loss:[0.35844042897224426, 0.33002984523773193, 0.014205296523869038]\n",
            "Batch:100\n",
            "d_loss_real:0.8481976389884949\n",
            "d_loss_fake:0.00024565879721194506\n",
            "d_loss_wrong:0.6342431306838989\n",
            "d_loss:0.5827210168645252\n",
            "g_loss:[0.3497013449668884, 0.3279656171798706, 0.010867862030863762]\n",
            "Batch:101\n",
            "d_loss_real:0.8918068408966064\n",
            "d_loss_fake:0.0003644137759692967\n",
            "d_loss_wrong:0.6840341091156006\n",
            "d_loss:0.6170030511711957\n",
            "g_loss:[0.34904685616493225, 0.32780128717422485, 0.01062278263270855]\n",
            "Batch:102\n",
            "d_loss_real:0.8469424843788147\n",
            "d_loss_fake:0.0004869055701419711\n",
            "d_loss_wrong:0.6571651697158813\n",
            "d_loss:0.5878842610109132\n",
            "g_loss:[0.34933459758758545, 0.3253931403160095, 0.011970724910497665]\n",
            "Batch:103\n",
            "d_loss_real:0.8770444393157959\n",
            "d_loss_fake:0.0019647942390292883\n",
            "d_loss_wrong:0.6301651000976562\n",
            "d_loss:0.5965546932420693\n",
            "g_loss:[0.3468524217605591, 0.3270135521888733, 0.00991943757981062]\n",
            "Batch:104\n",
            "d_loss_real:0.8511884212493896\n",
            "d_loss_fake:0.00012934124970342964\n",
            "d_loss_wrong:0.6835430860519409\n",
            "d_loss:0.5965123174501059\n",
            "g_loss:[0.3476991355419159, 0.32917726039886475, 0.009260936640202999]\n",
            "Batch:105\n",
            "d_loss_real:0.8854726552963257\n",
            "d_loss_fake:0.0012415024684742093\n",
            "d_loss_wrong:0.6753517985343933\n",
            "d_loss:0.6118846528988797\n",
            "g_loss:[0.3443419635295868, 0.3265739679336548, 0.00888399500399828]\n",
            "Batch:106\n",
            "d_loss_real:0.8227638006210327\n",
            "d_loss_fake:0.00014028472651261836\n",
            "d_loss_wrong:0.672400712966919\n",
            "d_loss:0.5795171497338742\n",
            "g_loss:[0.34174901247024536, 0.3253093957901001, 0.008219812996685505]\n",
            "Batch:107\n",
            "d_loss_real:0.8583742380142212\n",
            "d_loss_fake:0.0001453660661354661\n",
            "d_loss_wrong:0.6717893481254578\n",
            "d_loss:0.5971707975550089\n",
            "g_loss:[0.34241604804992676, 0.32619935274124146, 0.008108343929052353]\n",
            "Batch:108\n",
            "d_loss_real:0.8540340662002563\n",
            "d_loss_fake:0.001186545705422759\n",
            "d_loss_wrong:0.6468076705932617\n",
            "d_loss:0.5890155871747993\n",
            "g_loss:[0.35548558831214905, 0.3381804823875427, 0.008652550168335438]\n",
            "Batch:109\n",
            "d_loss_real:0.8524249792098999\n",
            "d_loss_fake:9.009865607367828e-05\n",
            "d_loss_wrong:0.6636242866516113\n",
            "d_loss:0.5921410859318712\n",
            "g_loss:[0.3424200117588043, 0.3255779445171356, 0.008421040140092373]\n",
            "Batch:110\n",
            "d_loss_real:0.8199347257614136\n",
            "d_loss_fake:0.0005272987764328718\n",
            "d_loss_wrong:0.672431468963623\n",
            "d_loss:0.5782070548157208\n",
            "g_loss:[0.3538171648979187, 0.3380902111530304, 0.007863476872444153]\n",
            "Batch:111\n",
            "d_loss_real:0.8184559345245361\n",
            "d_loss_fake:0.0010127935092896223\n",
            "d_loss_wrong:0.6503318548202515\n",
            "d_loss:0.5720641293446533\n",
            "g_loss:[0.3393174409866333, 0.3255382180213928, 0.006889611016958952]\n",
            "Batch:112\n",
            "d_loss_real:0.8362793922424316\n",
            "d_loss_fake:0.0004195507790427655\n",
            "d_loss_wrong:0.6464407444000244\n",
            "d_loss:0.5798547699159826\n",
            "g_loss:[0.35958459973335266, 0.34518322348594666, 0.007200681138783693]\n",
            "Batch:113\n",
            "d_loss_real:0.8505823016166687\n",
            "d_loss_fake:8.164782775565982e-05\n",
            "d_loss_wrong:0.6514521241188049\n",
            "d_loss:0.5881745937949745\n",
            "g_loss:[0.34099557995796204, 0.32605117559432983, 0.007472202181816101]\n",
            "Batch:114\n",
            "d_loss_real:0.8121216297149658\n",
            "d_loss_fake:0.00015844879089854658\n",
            "d_loss_wrong:0.6467108130455017\n",
            "d_loss:0.567778130316583\n",
            "g_loss:[0.34208691120147705, 0.3279433846473694, 0.007071770261973143]\n",
            "Batch:115\n",
            "d_loss_real:0.8380730152130127\n",
            "d_loss_fake:8.172736852429807e-05\n",
            "d_loss_wrong:0.6518349051475525\n",
            "d_loss:0.5820156657355255\n",
            "g_loss:[0.33948493003845215, 0.326481431722641, 0.006501749623566866]\n",
            "Batch:116\n",
            "d_loss_real:0.850726306438446\n",
            "d_loss_fake:0.0001325833291048184\n",
            "d_loss_wrong:0.676464319229126\n",
            "d_loss:0.5945123788587807\n",
            "g_loss:[0.47237712144851685, 0.46055901050567627, 0.005909052211791277]\n",
            "Batch:117\n",
            "d_loss_real:0.8694944381713867\n",
            "d_loss_fake:0.00010802771430462599\n",
            "d_loss_wrong:0.6662328243255615\n",
            "d_loss:0.6013324320956599\n",
            "g_loss:[0.3498634994029999, 0.3352295160293579, 0.007316985167562962]\n",
            "Batch:118\n",
            "d_loss_real:0.829781174659729\n",
            "d_loss_fake:0.00016501921345479786\n",
            "d_loss_wrong:0.6584056615829468\n",
            "d_loss:0.5795332575289649\n",
            "g_loss:[0.3476717174053192, 0.3282601237297058, 0.009705791249871254]\n",
            "Batch:119\n",
            "d_loss_real:0.8338651061058044\n",
            "d_loss_fake:0.002193555934354663\n",
            "d_loss_wrong:0.6566134691238403\n",
            "d_loss:0.581634309317451\n",
            "g_loss:[0.3457145392894745, 0.32783272862434387, 0.008940905332565308]\n",
            "Batch:120\n",
            "d_loss_real:0.8439937233924866\n",
            "d_loss_fake:0.0001139098167186603\n",
            "d_loss_wrong:0.6579397916793823\n",
            "d_loss:0.5865102870702685\n",
            "g_loss:[0.7737651467323303, 0.7569681406021118, 0.008398490957915783]\n",
            "Batch:121\n",
            "d_loss_real:0.8598322868347168\n",
            "d_loss_fake:0.0014137269463390112\n",
            "d_loss_wrong:0.6583104133605957\n",
            "d_loss:0.5948471784940921\n",
            "g_loss:[0.3696231544017792, 0.34364956617355347, 0.012986792251467705]\n",
            "Batch:122\n",
            "d_loss_real:0.8296743631362915\n",
            "d_loss_fake:0.00020709821546915919\n",
            "d_loss_wrong:0.6583733558654785\n",
            "d_loss:0.5794822950883827\n",
            "g_loss:[0.3913106918334961, 0.35951775312423706, 0.015896471217274666]\n",
            "Batch:123\n",
            "d_loss_real:0.8994525671005249\n",
            "d_loss_fake:0.0002538492262829095\n",
            "d_loss_wrong:0.6984326839447021\n",
            "d_loss:0.6243979168430087\n",
            "g_loss:[0.4070601165294647, 0.3800050616264343, 0.01352753397077322]\n",
            "Batch:124\n",
            "d_loss_real:0.8620390892028809\n",
            "d_loss_fake:0.0002698052558116615\n",
            "d_loss_wrong:0.6439067721366882\n",
            "d_loss:0.5920636889495654\n",
            "g_loss:[0.3610174357891083, 0.335716187953949, 0.012650630436837673]\n",
            "Batch:125\n",
            "d_loss_real:0.8020181655883789\n",
            "d_loss_fake:0.00020833675807807595\n",
            "d_loss_wrong:0.6663254499435425\n",
            "d_loss:0.5676425294695946\n",
            "g_loss:[0.4925987720489502, 0.4647154211997986, 0.013941682875156403]\n",
            "Batch:126\n",
            "d_loss_real:0.8309940099716187\n",
            "d_loss_fake:0.0006288386648520827\n",
            "d_loss_wrong:0.6591393947601318\n",
            "d_loss:0.5804390633420553\n",
            "g_loss:[0.3897332549095154, 0.3541496992111206, 0.01779177039861679]\n",
            "Batch:127\n",
            "d_loss_real:0.8736907243728638\n",
            "d_loss_fake:0.0012437691912055016\n",
            "d_loss_wrong:0.6375495791435242\n",
            "d_loss:0.5965436992701143\n",
            "g_loss:[0.4003148078918457, 0.3737422227859497, 0.0132862888276577]\n",
            "Batch:128\n",
            "d_loss_real:0.8377805948257446\n",
            "d_loss_fake:0.0004139531229157001\n",
            "d_loss_wrong:0.671314001083374\n",
            "d_loss:0.5868222859644447\n",
            "g_loss:[0.35783296823501587, 0.3322035074234009, 0.012814724817872047]\n",
            "Batch:129\n",
            "d_loss_real:0.8316243886947632\n",
            "d_loss_fake:0.00022509717382490635\n",
            "d_loss_wrong:0.6638473868370056\n",
            "d_loss:0.5818303153500892\n",
            "g_loss:[0.3710726499557495, 0.3492676019668579, 0.010902530513703823]\n",
            "Batch:130\n",
            "d_loss_real:0.8316274881362915\n",
            "d_loss_fake:0.0002604830078780651\n",
            "d_loss_wrong:0.67710280418396\n",
            "d_loss:0.5851545658661053\n",
            "g_loss:[0.3564431667327881, 0.3362496793270111, 0.010096743702888489]\n",
            "Batch:131\n",
            "d_loss_real:0.8831315636634827\n",
            "d_loss_fake:0.0002522005815990269\n",
            "d_loss_wrong:0.6663718819618225\n",
            "d_loss:0.6082218024675967\n",
            "g_loss:[0.36072981357574463, 0.33990901708602905, 0.010410403832793236]\n",
            "Batch:132\n",
            "d_loss_real:0.8276972770690918\n",
            "d_loss_fake:0.0002512189093977213\n",
            "d_loss_wrong:0.6642248034477234\n",
            "d_loss:0.5799676441238262\n",
            "g_loss:[0.34914642572402954, 0.32850611209869385, 0.010320160537958145]\n",
            "Batch:133\n",
            "d_loss_real:0.8301483392715454\n",
            "d_loss_fake:0.0002880277461372316\n",
            "d_loss_wrong:0.6686837077140808\n",
            "d_loss:0.5823171035008272\n",
            "g_loss:[0.3495123088359833, 0.32676857709884644, 0.011371860280632973]\n",
            "Batch:134\n",
            "d_loss_real:0.8311452269554138\n",
            "d_loss_fake:0.0002111202193191275\n",
            "d_loss_wrong:0.6588587760925293\n",
            "d_loss:0.580340087555669\n",
            "g_loss:[0.3483710289001465, 0.32623690366744995, 0.011067066341638565]\n",
            "Batch:135\n",
            "d_loss_real:0.8594532012939453\n",
            "d_loss_fake:0.0010279908310621977\n",
            "d_loss_wrong:0.6443684697151184\n",
            "d_loss:0.5910757157835178\n",
            "g_loss:[0.3670603036880493, 0.34413763880729675, 0.01146133616566658]\n",
            "Batch:136\n",
            "d_loss_real:0.836432695388794\n",
            "d_loss_fake:0.00014297844609245658\n",
            "d_loss_wrong:0.6653294563293457\n",
            "d_loss:0.5845844563882565\n",
            "g_loss:[0.550177812576294, 0.5290145874023438, 0.010581612586975098]\n",
            "Batch:137\n",
            "d_loss_real:0.8285627365112305\n",
            "d_loss_fake:0.00011354447633493692\n",
            "d_loss_wrong:0.6552988290786743\n",
            "d_loss:0.5781344616443675\n",
            "g_loss:[0.3586078882217407, 0.3293420672416687, 0.014632907696068287]\n",
            "Batch:138\n",
            "d_loss_real:0.8340730667114258\n",
            "d_loss_fake:0.00016959133790805936\n",
            "d_loss_wrong:0.6542739272117615\n",
            "d_loss:0.5806474129931303\n",
            "g_loss:[0.37346336245536804, 0.33744579553604126, 0.018008779734373093]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "Epoch is: 3\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.8706455826759338\n",
            "d_loss_fake:0.00012513849651440978\n",
            "d_loss_wrong:0.6880132555961609\n",
            "d_loss:0.6073573898611357\n",
            "g_loss:[0.36711055040359497, 0.3362061381340027, 0.01545221358537674]\n",
            "Batch:2\n",
            "d_loss_real:0.8427366614341736\n",
            "d_loss_fake:0.0001001374184852466\n",
            "d_loss_wrong:0.6800286173820496\n",
            "d_loss:0.5914005194172205\n",
            "g_loss:[0.36380770802497864, 0.3353099524974823, 0.014248879626393318]\n",
            "Batch:3\n",
            "d_loss_real:0.8441360592842102\n",
            "d_loss_fake:0.00041244307067245245\n",
            "d_loss_wrong:0.6621512770652771\n",
            "d_loss:0.5877089596760925\n",
            "g_loss:[0.38724884390830994, 0.35935574769973755, 0.01394654344767332]\n",
            "Batch:4\n",
            "d_loss_real:0.8816400766372681\n",
            "d_loss_fake:0.00017122147255577147\n",
            "d_loss_wrong:0.6997655034065247\n",
            "d_loss:0.6158042195384041\n",
            "g_loss:[0.3560025095939636, 0.32784605026245117, 0.014078234322369099]\n",
            "Batch:5\n",
            "d_loss_real:0.8331975340843201\n",
            "d_loss_fake:0.0002244003990199417\n",
            "d_loss_wrong:0.7102445363998413\n",
            "d_loss:0.5942160012418753\n",
            "g_loss:[0.3592832088470459, 0.3329364061355591, 0.013173406012356281]\n",
            "Batch:6\n",
            "d_loss_real:0.8493173122406006\n",
            "d_loss_fake:0.0004468925471883267\n",
            "d_loss_wrong:0.7222262024879456\n",
            "d_loss:0.6053269298790838\n",
            "g_loss:[0.3542885482311249, 0.3296832740306854, 0.012302631512284279]\n",
            "Batch:7\n",
            "d_loss_real:0.840778648853302\n",
            "d_loss_fake:0.0003004099999088794\n",
            "d_loss_wrong:0.6615273356437683\n",
            "d_loss:0.5858462608375703\n",
            "g_loss:[0.34892538189888, 0.32800933718681335, 0.0104580232873559]\n",
            "Batch:8\n",
            "d_loss_real:0.8346332311630249\n",
            "d_loss_fake:0.0001852092973422259\n",
            "d_loss_wrong:0.6169705390930176\n",
            "d_loss:0.5716055526791024\n",
            "g_loss:[0.3639602065086365, 0.3368619680404663, 0.013549122959375381]\n",
            "Batch:9\n",
            "d_loss_real:0.8437376618385315\n",
            "d_loss_fake:0.0001844104699557647\n",
            "d_loss_wrong:0.6437928080558777\n",
            "d_loss:0.5828631355507241\n",
            "g_loss:[0.3521749973297119, 0.3265901505947113, 0.01279242243617773]\n",
            "Batch:10\n",
            "d_loss_real:0.854029655456543\n",
            "d_loss_fake:0.0001168946037068963\n",
            "d_loss_wrong:0.6286657452583313\n",
            "d_loss:0.584210487693781\n",
            "g_loss:[0.3505662679672241, 0.329606831073761, 0.01047972310334444]\n",
            "Batch:11\n",
            "d_loss_real:0.8724701404571533\n",
            "d_loss_fake:0.00013707646576222032\n",
            "d_loss_wrong:0.6360280513763428\n",
            "d_loss:0.5952763521891029\n",
            "g_loss:[0.34880882501602173, 0.3288019597530365, 0.010003432631492615]\n",
            "Batch:12\n",
            "d_loss_real:0.8579936623573303\n",
            "d_loss_fake:0.00031038213637657464\n",
            "d_loss_wrong:0.6547095775604248\n",
            "d_loss:0.5927518211028655\n",
            "g_loss:[0.6951800584793091, 0.6742697954177856, 0.010455125011503696]\n",
            "Batch:13\n",
            "d_loss_real:0.8348754644393921\n",
            "d_loss_fake:0.00017592388030607253\n",
            "d_loss_wrong:0.6698077917098999\n",
            "d_loss:0.5849336611172475\n",
            "g_loss:[0.35226142406463623, 0.3297426104545593, 0.01125941053032875]\n",
            "Batch:14\n",
            "d_loss_real:0.8612744212150574\n",
            "d_loss_fake:0.00048823520774021745\n",
            "d_loss_wrong:0.6774261593818665\n",
            "d_loss:0.6001158092549304\n",
            "g_loss:[0.3726644217967987, 0.35267531871795654, 0.009994551539421082]\n",
            "Batch:15\n",
            "d_loss_real:0.8574073314666748\n",
            "d_loss_fake:0.00010699176345951855\n",
            "d_loss_wrong:0.68979412317276\n",
            "d_loss:0.6011789444673923\n",
            "g_loss:[0.3565102219581604, 0.33815521001815796, 0.00917750969529152]\n",
            "Batch:16\n",
            "d_loss_real:0.8451968431472778\n",
            "d_loss_fake:0.0005646939971484244\n",
            "d_loss_wrong:0.701245129108429\n",
            "d_loss:0.5980508773500333\n",
            "g_loss:[0.39993032813072205, 0.3800423741340637, 0.009943975135684013]\n",
            "Batch:17\n",
            "d_loss_real:0.8586960434913635\n",
            "d_loss_fake:0.00040020415326580405\n",
            "d_loss_wrong:0.7228306531906128\n",
            "d_loss:0.6101557360816514\n",
            "g_loss:[0.3487417697906494, 0.33048996329307556, 0.00912589579820633]\n",
            "Batch:18\n",
            "d_loss_real:0.8437939882278442\n",
            "d_loss_fake:0.0008405194967053831\n",
            "d_loss_wrong:0.6539146304130554\n",
            "d_loss:0.5855857815913623\n",
            "g_loss:[0.36776888370513916, 0.34733474254608154, 0.010217073373496532]\n",
            "Batch:19\n",
            "d_loss_real:0.8886404037475586\n",
            "d_loss_fake:0.0028839348815381527\n",
            "d_loss_wrong:0.672896683216095\n",
            "d_loss:0.6132653563981876\n",
            "g_loss:[0.3678846061229706, 0.3455800414085388, 0.011152276769280434]\n",
            "Batch:20\n",
            "d_loss_real:0.8814048171043396\n",
            "d_loss_fake:0.0005786058027297258\n",
            "d_loss_wrong:0.6988963484764099\n",
            "d_loss:0.6155711471219547\n",
            "g_loss:[0.3580504059791565, 0.3374477028846741, 0.01030135527253151]\n",
            "Batch:21\n",
            "d_loss_real:0.8431991338729858\n",
            "d_loss_fake:0.00019944916130043566\n",
            "d_loss_wrong:0.6236916184425354\n",
            "d_loss:0.5775723338374519\n",
            "g_loss:[0.37064802646636963, 0.34717220067977905, 0.01173790916800499]\n",
            "Batch:22\n",
            "d_loss_real:0.86841881275177\n",
            "d_loss_fake:8.153643284458667e-05\n",
            "d_loss_wrong:0.6835353970527649\n",
            "d_loss:0.6051136397472874\n",
            "g_loss:[0.3655506372451782, 0.3423619866371155, 0.01159432902932167]\n",
            "Batch:23\n",
            "d_loss_real:0.8349916934967041\n",
            "d_loss_fake:0.0002967629407066852\n",
            "d_loss_wrong:0.6741149425506592\n",
            "d_loss:0.5860987731211935\n",
            "g_loss:[0.35281115770339966, 0.33269190788269043, 0.010059626772999763]\n",
            "Batch:24\n",
            "d_loss_real:0.8198633193969727\n",
            "d_loss_fake:0.0017578271217644215\n",
            "d_loss_wrong:0.6483911275863647\n",
            "d_loss:0.5724688983755186\n",
            "g_loss:[0.3629186749458313, 0.3450658917427063, 0.008926399052143097]\n",
            "Batch:25\n",
            "d_loss_real:0.87494295835495\n",
            "d_loss_fake:2.902649066527374e-05\n",
            "d_loss_wrong:0.7044832706451416\n",
            "d_loss:0.6135995534614267\n",
            "g_loss:[0.34628090262413025, 0.3307344317436218, 0.007773238699883223]\n",
            "Batch:26\n",
            "d_loss_real:0.8352124691009521\n",
            "d_loss_fake:0.00024742656387388706\n",
            "d_loss_wrong:0.669280469417572\n",
            "d_loss:0.5849882085458376\n",
            "g_loss:[0.35299116373062134, 0.33402255177497864, 0.009484311565756798]\n",
            "Batch:27\n",
            "d_loss_real:0.8987338542938232\n",
            "d_loss_fake:0.00013337819837033749\n",
            "d_loss_wrong:0.7128363847732544\n",
            "d_loss:0.6276093678898178\n",
            "g_loss:[0.34884005784988403, 0.33180898427963257, 0.00851553026586771]\n",
            "Batch:28\n",
            "d_loss_real:0.8242782354354858\n",
            "d_loss_fake:6.217652116902173e-05\n",
            "d_loss_wrong:0.6229168176651001\n",
            "d_loss:0.5678838662643102\n",
            "g_loss:[0.3477715849876404, 0.329262375831604, 0.00925459899008274]\n",
            "Batch:29\n",
            "d_loss_real:0.8600127696990967\n",
            "d_loss_fake:6.791546911699697e-05\n",
            "d_loss_wrong:0.6502798795700073\n",
            "d_loss:0.5925933336093294\n",
            "g_loss:[0.42731034755706787, 0.4129994809627533, 0.007155430503189564]\n",
            "Batch:30\n",
            "d_loss_real:0.8636846542358398\n",
            "d_loss_fake:0.00011493217607494444\n",
            "d_loss_wrong:0.7092276811599731\n",
            "d_loss:0.6091779804519319\n",
            "g_loss:[0.4196496903896332, 0.40459495782852173, 0.007527362089604139]\n",
            "Batch:31\n",
            "d_loss_real:0.826115071773529\n",
            "d_loss_fake:0.0006694058538414538\n",
            "d_loss_wrong:0.6726229190826416\n",
            "d_loss:0.5813806171208853\n",
            "g_loss:[0.3512211740016937, 0.33096104860305786, 0.010130069218575954]\n",
            "Batch:32\n",
            "d_loss_real:0.8442291021347046\n",
            "d_loss_fake:0.0008734959410503507\n",
            "d_loss_wrong:0.6283787488937378\n",
            "d_loss:0.5794276122760493\n",
            "g_loss:[0.7852934002876282, 0.7645255327224731, 0.01038392260670662]\n",
            "Batch:33\n",
            "d_loss_real:0.8468085527420044\n",
            "d_loss_fake:0.0006048263749107718\n",
            "d_loss_wrong:0.650037407875061\n",
            "d_loss:0.5860648349334951\n",
            "g_loss:[0.36810579895973206, 0.34178197383880615, 0.013161910697817802]\n",
            "Batch:34\n",
            "d_loss_real:0.8419271111488342\n",
            "d_loss_fake:0.0009154294384643435\n",
            "d_loss_wrong:0.6366907358169556\n",
            "d_loss:0.5803650968882721\n",
            "g_loss:[0.3624052405357361, 0.3375409245491028, 0.01243215799331665]\n",
            "Batch:35\n",
            "d_loss_real:0.8675875663757324\n",
            "d_loss_fake:0.0006943107000552118\n",
            "d_loss_wrong:0.6777554750442505\n",
            "d_loss:0.6034062296239426\n",
            "g_loss:[0.3655414581298828, 0.344227135181427, 0.010657155886292458]\n",
            "Batch:36\n",
            "d_loss_real:0.8235759735107422\n",
            "d_loss_fake:9.091146057471633e-05\n",
            "d_loss_wrong:0.6609053611755371\n",
            "d_loss:0.577037054914399\n",
            "g_loss:[0.35861021280288696, 0.3356590270996094, 0.011475600302219391]\n",
            "Batch:37\n",
            "d_loss_real:0.8382039070129395\n",
            "d_loss_fake:0.00011362522491253912\n",
            "d_loss_wrong:0.6909009218215942\n",
            "d_loss:0.5918555902680964\n",
            "g_loss:[0.3582582473754883, 0.33392974734306335, 0.012164250947535038]\n",
            "Batch:38\n",
            "d_loss_real:0.8654607534408569\n",
            "d_loss_fake:9.69153770711273e-05\n",
            "d_loss_wrong:0.6756995916366577\n",
            "d_loss:0.6016795034738607\n",
            "g_loss:[0.354523241519928, 0.33516812324523926, 0.009677562862634659]\n",
            "Batch:39\n",
            "d_loss_real:0.8387067914009094\n",
            "d_loss_fake:0.0014246259815990925\n",
            "d_loss_wrong:0.6656132340431213\n",
            "d_loss:0.5861128607066348\n",
            "g_loss:[0.35148248076438904, 0.3309926390647888, 0.010244918055832386]\n",
            "Batch:40\n",
            "d_loss_real:0.8599189519882202\n",
            "d_loss_fake:0.0001356828142888844\n",
            "d_loss_wrong:0.767525315284729\n",
            "d_loss:0.6218747255188646\n",
            "g_loss:[0.41509315371513367, 0.39919960498809814, 0.007946773432195187]\n",
            "Batch:41\n",
            "d_loss_real:0.8513051867485046\n",
            "d_loss_fake:0.0003707441792357713\n",
            "d_loss_wrong:0.6579593420028687\n",
            "d_loss:0.5902351149197784\n",
            "g_loss:[0.37028488516807556, 0.35040712356567383, 0.009938881732523441]\n",
            "Batch:42\n",
            "d_loss_real:0.8989366888999939\n",
            "d_loss_fake:0.0003154499572701752\n",
            "d_loss_wrong:0.658012330532074\n",
            "d_loss:0.614050289572333\n",
            "g_loss:[0.35345548391342163, 0.33255553245544434, 0.010449972003698349]\n",
            "Batch:43\n",
            "d_loss_real:0.81913161277771\n",
            "d_loss_fake:0.0012056659907102585\n",
            "d_loss_wrong:0.640885591506958\n",
            "d_loss:0.570088620763272\n",
            "g_loss:[0.66953045129776, 0.6436439752578735, 0.012943236157298088]\n",
            "Batch:44\n",
            "d_loss_real:0.853634238243103\n",
            "d_loss_fake:0.01684616506099701\n",
            "d_loss_wrong:0.6631631851196289\n",
            "d_loss:0.596819456666708\n",
            "g_loss:[0.46840596199035645, 0.4397851526737213, 0.01431040745228529]\n",
            "Batch:45\n",
            "d_loss_real:0.8110613822937012\n",
            "d_loss_fake:9.779335414350498e-06\n",
            "d_loss_wrong:0.6296129822731018\n",
            "d_loss:0.5629363815489796\n",
            "g_loss:[0.41809505224227905, 0.38278064131736755, 0.0176572073251009]\n",
            "Batch:46\n",
            "d_loss_real:0.8567013740539551\n",
            "d_loss_fake:9.90103289950639e-05\n",
            "d_loss_wrong:0.6552329063415527\n",
            "d_loss:0.5921836661946145\n",
            "g_loss:[0.4632842540740967, 0.43469369411468506, 0.014295285567641258]\n",
            "Batch:47\n",
            "d_loss_real:0.8539647459983826\n",
            "d_loss_fake:6.175439921207726e-05\n",
            "d_loss_wrong:0.6710273623466492\n",
            "d_loss:0.5947546521856566\n",
            "g_loss:[0.3871644139289856, 0.3624403178691864, 0.012362048029899597]\n",
            "Batch:48\n",
            "d_loss_real:0.8476461172103882\n",
            "d_loss_fake:4.5553326344816014e-05\n",
            "d_loss_wrong:0.6407097578048706\n",
            "d_loss:0.584011886387998\n",
            "g_loss:[0.3791974186897278, 0.3519574999809265, 0.013619959354400635]\n",
            "Batch:49\n",
            "d_loss_real:0.8314773440361023\n",
            "d_loss_fake:9.17242286959663e-05\n",
            "d_loss_wrong:0.6326848268508911\n",
            "d_loss:0.5739328097879479\n",
            "g_loss:[0.39578184485435486, 0.3666178584098816, 0.014581995084881783]\n",
            "Batch:50\n",
            "d_loss_real:0.8340495228767395\n",
            "d_loss_fake:8.779645577305928e-05\n",
            "d_loss_wrong:0.6501942873001099\n",
            "d_loss:0.5795952823773405\n",
            "g_loss:[0.36624875664711, 0.3436805009841919, 0.011284122243523598]\n",
            "Batch:51\n",
            "d_loss_real:0.8350214958190918\n",
            "d_loss_fake:0.00015190104022622108\n",
            "d_loss_wrong:0.6588014960289001\n",
            "d_loss:0.5822490971768275\n",
            "g_loss:[0.39160385727882385, 0.3674391508102417, 0.012082346715033054]\n",
            "Batch:52\n",
            "d_loss_real:0.8476455807685852\n",
            "d_loss_fake:5.989068449707702e-05\n",
            "d_loss_wrong:0.6767614483833313\n",
            "d_loss:0.5930281251512497\n",
            "g_loss:[0.37808650732040405, 0.35739824175834656, 0.010344138368964195]\n",
            "Batch:53\n",
            "d_loss_real:0.8468571305274963\n",
            "d_loss_fake:4.671864735428244e-05\n",
            "d_loss_wrong:0.6504971981048584\n",
            "d_loss:0.5860645444518013\n",
            "g_loss:[0.40045657753944397, 0.3792591392993927, 0.010598713532090187]\n",
            "Batch:54\n",
            "d_loss_real:0.8335707783699036\n",
            "d_loss_fake:0.0001273104571737349\n",
            "d_loss_wrong:0.6798528432846069\n",
            "d_loss:0.586780427620397\n",
            "g_loss:[0.36987465620040894, 0.3533726632595062, 0.008250994607806206]\n",
            "Batch:55\n",
            "d_loss_real:0.8253170251846313\n",
            "d_loss_fake:5.058151509729214e-05\n",
            "d_loss_wrong:0.6577368974685669\n",
            "d_loss:0.5771053823382317\n",
            "g_loss:[0.363295316696167, 0.3433699905872345, 0.009962659329175949]\n",
            "Batch:56\n",
            "d_loss_real:0.8633816242218018\n",
            "d_loss_fake:0.00010797826689668\n",
            "d_loss_wrong:0.7006712555885315\n",
            "d_loss:0.6068856205747579\n",
            "g_loss:[0.3596668839454651, 0.33443957567214966, 0.012613660655915737]\n",
            "Batch:57\n",
            "d_loss_real:0.8422516584396362\n",
            "d_loss_fake:7.997851935215294e-05\n",
            "d_loss_wrong:0.6495589017868042\n",
            "d_loss:0.5835355492963572\n",
            "g_loss:[0.35407179594039917, 0.33228373527526855, 0.01089402288198471]\n",
            "Batch:58\n",
            "d_loss_real:0.8280950784683228\n",
            "d_loss_fake:0.0004025021044071764\n",
            "d_loss_wrong:0.6489618420600891\n",
            "d_loss:0.5763886252752854\n",
            "g_loss:[0.3561190068721771, 0.33494436740875244, 0.010587320663034916]\n",
            "Batch:59\n",
            "d_loss_real:0.8618661761283875\n",
            "d_loss_fake:0.00030338740907609463\n",
            "d_loss_wrong:0.6722316145896912\n",
            "d_loss:0.5990668385638855\n",
            "g_loss:[0.34982219338417053, 0.33399567008018494, 0.007913262583315372]\n",
            "Batch:60\n",
            "d_loss_real:0.8511717319488525\n",
            "d_loss_fake:8.261202310677618e-05\n",
            "d_loss_wrong:0.6878302097320557\n",
            "d_loss:0.5975640714132169\n",
            "g_loss:[0.3644702136516571, 0.3484085202217102, 0.008030841127038002]\n",
            "Batch:61\n",
            "d_loss_real:0.8456745147705078\n",
            "d_loss_fake:4.67492027382832e-05\n",
            "d_loss_wrong:0.6674306392669678\n",
            "d_loss:0.5897066045026804\n",
            "g_loss:[0.3524726331233978, 0.3364136815071106, 0.008029472082853317]\n",
            "Batch:62\n",
            "d_loss_real:0.8532194495201111\n",
            "d_loss_fake:6.362137355608866e-05\n",
            "d_loss_wrong:0.6528728604316711\n",
            "d_loss:0.5898438452113623\n",
            "g_loss:[0.35119521617889404, 0.3366965651512146, 0.007249319925904274]\n",
            "Batch:63\n",
            "d_loss_real:0.8490030765533447\n",
            "d_loss_fake:0.00021646093227900565\n",
            "d_loss_wrong:0.6622985005378723\n",
            "d_loss:0.5901302786442102\n",
            "g_loss:[0.3483392894268036, 0.3317338824272156, 0.008302699774503708]\n",
            "Batch:64\n",
            "d_loss_real:0.8242344260215759\n",
            "d_loss_fake:6.908073555678129e-05\n",
            "d_loss_wrong:0.6487728357315063\n",
            "d_loss:0.5743276921275537\n",
            "g_loss:[0.3858618438243866, 0.36828678846359253, 0.008787522092461586]\n",
            "Batch:65\n",
            "d_loss_real:0.896446168422699\n",
            "d_loss_fake:0.00016534878523088992\n",
            "d_loss_wrong:0.7001611590385437\n",
            "d_loss:0.6233047111672931\n",
            "g_loss:[0.34321439266204834, 0.327897846698761, 0.007658269256353378]\n",
            "Batch:66\n",
            "d_loss_real:0.8067502379417419\n",
            "d_loss_fake:0.0001597288646735251\n",
            "d_loss_wrong:0.6658011674880981\n",
            "d_loss:0.5698653430590639\n",
            "g_loss:[0.345378577709198, 0.32830554246902466, 0.008536513894796371]\n",
            "Batch:67\n",
            "d_loss_real:0.873599112033844\n",
            "d_loss_fake:0.0003109077224507928\n",
            "d_loss_wrong:0.6304168105125427\n",
            "d_loss:0.5944814855756704\n",
            "g_loss:[0.3437981605529785, 0.329170823097229, 0.007313672453165054]\n",
            "Batch:68\n",
            "d_loss_real:0.8567938804626465\n",
            "d_loss_fake:0.0014943017158657312\n",
            "d_loss_wrong:0.6858646273612976\n",
            "d_loss:0.6002366725006141\n",
            "g_loss:[0.3521581292152405, 0.3406297564506531, 0.0057641929015517235]\n",
            "Batch:69\n",
            "d_loss_real:0.8639401793479919\n",
            "d_loss_fake:0.003658522851765156\n",
            "d_loss_wrong:0.6996875405311584\n",
            "d_loss:0.6078066055197269\n",
            "g_loss:[0.34142401814460754, 0.32944515347480774, 0.005989430006593466]\n",
            "Batch:70\n",
            "d_loss_real:0.8350337743759155\n",
            "d_loss_fake:0.00011316197196720168\n",
            "d_loss_wrong:0.6810057163238525\n",
            "d_loss:0.5877966067619127\n",
            "g_loss:[0.3420781195163727, 0.32919859886169434, 0.006439754739403725]\n",
            "Batch:71\n",
            "d_loss_real:0.8283770084381104\n",
            "d_loss_fake:0.0002514127700123936\n",
            "d_loss_wrong:0.6554972529411316\n",
            "d_loss:0.5781256706468412\n",
            "g_loss:[0.3543328642845154, 0.34030717611312866, 0.007012845017015934]\n",
            "Batch:72\n",
            "d_loss_real:0.8559538125991821\n",
            "d_loss_fake:0.0002469765895511955\n",
            "d_loss_wrong:0.6652833223342896\n",
            "d_loss:0.5943594810305513\n",
            "g_loss:[0.34066134691238403, 0.3289356231689453, 0.005862866528332233]\n",
            "Batch:73\n",
            "d_loss_real:0.8389924764633179\n",
            "d_loss_fake:8.248524682130665e-05\n",
            "d_loss_wrong:0.6671351194381714\n",
            "d_loss:0.5863006394029071\n",
            "g_loss:[0.3473142683506012, 0.33332815766334534, 0.006993050687015057]\n",
            "Batch:74\n",
            "d_loss_real:0.8783214092254639\n",
            "d_loss_fake:6.574511644430459e-05\n",
            "d_loss_wrong:0.6830300092697144\n",
            "d_loss:0.6099346432092716\n",
            "g_loss:[0.5801534652709961, 0.5652098655700684, 0.007471811026334763]\n",
            "Batch:75\n",
            "d_loss_real:0.8563593626022339\n",
            "d_loss_fake:0.010180342011153698\n",
            "d_loss_wrong:0.6601027250289917\n",
            "d_loss:0.5957504480611533\n",
            "g_loss:[0.7097482085227966, 0.6953251957893372, 0.007211498916149139]\n",
            "Batch:76\n",
            "d_loss_real:0.8542313575744629\n",
            "d_loss_fake:0.00016030162805691361\n",
            "d_loss_wrong:0.6550014019012451\n",
            "d_loss:0.590906104669557\n",
            "g_loss:[0.5148153901100159, 0.4973984956741333, 0.008708460256457329]\n",
            "Batch:77\n",
            "d_loss_real:0.8529635667800903\n",
            "d_loss_fake:5.316560418577865e-05\n",
            "d_loss_wrong:0.663565993309021\n",
            "d_loss:0.5923865731183469\n",
            "g_loss:[0.46678605675697327, 0.44844016432762146, 0.009172946214675903]\n",
            "Batch:78\n",
            "d_loss_real:0.8429625034332275\n",
            "d_loss_fake:0.0008125546155497432\n",
            "d_loss_wrong:0.6640681624412537\n",
            "d_loss:0.5877014309808146\n",
            "g_loss:[0.43406713008880615, 0.4180569648742676, 0.00800507515668869]\n",
            "Batch:79\n",
            "d_loss_real:0.8432595729827881\n",
            "d_loss_fake:0.00048449847963638604\n",
            "d_loss_wrong:0.6562555432319641\n",
            "d_loss:0.5858147969192942\n",
            "g_loss:[0.4267185628414154, 0.4088912308216095, 0.008913662284612656]\n",
            "Batch:80\n",
            "d_loss_real:0.8317985534667969\n",
            "d_loss_fake:0.006482572294771671\n",
            "d_loss_wrong:0.6538674831390381\n",
            "d_loss:0.5809867905918509\n",
            "g_loss:[0.4823738932609558, 0.4641416668891907, 0.00911610759794712]\n",
            "Batch:81\n",
            "d_loss_real:0.8441380858421326\n",
            "d_loss_fake:6.293995829764754e-05\n",
            "d_loss_wrong:0.6281731128692627\n",
            "d_loss:0.5791280561279564\n",
            "g_loss:[0.5061578750610352, 0.4874078035354614, 0.009375039488077164]\n",
            "Batch:82\n",
            "d_loss_real:0.8958420753479004\n",
            "d_loss_fake:0.000690174289047718\n",
            "d_loss_wrong:0.6623141765594482\n",
            "d_loss:0.6136721253860742\n",
            "g_loss:[0.40990978479385376, 0.3881361484527588, 0.010886812582612038]\n",
            "Batch:83\n",
            "d_loss_real:0.7965105175971985\n",
            "d_loss_fake:0.0002573049277998507\n",
            "d_loss_wrong:0.6437056660652161\n",
            "d_loss:0.5592460015468532\n",
            "g_loss:[0.4068867862224579, 0.3850697875022888, 0.010908495634794235]\n",
            "Batch:84\n",
            "d_loss_real:0.8528260588645935\n",
            "d_loss_fake:0.00018402488785795867\n",
            "d_loss_wrong:0.6681151390075684\n",
            "d_loss:0.5934878204061533\n",
            "g_loss:[0.3874298632144928, 0.3661386966705322, 0.010645577684044838]\n",
            "Batch:85\n",
            "d_loss_real:0.8329640626907349\n",
            "d_loss_fake:0.00029256101697683334\n",
            "d_loss_wrong:0.6704660058021545\n",
            "d_loss:0.5841716730501503\n",
            "g_loss:[0.3834114074707031, 0.36436012387275696, 0.009525642730295658]\n",
            "Batch:86\n",
            "d_loss_real:0.8326416611671448\n",
            "d_loss_fake:0.00030897819669917226\n",
            "d_loss_wrong:0.6546812057495117\n",
            "d_loss:0.5800683765701251\n",
            "g_loss:[0.37535709142684937, 0.3583444654941559, 0.00850631296634674]\n",
            "Batch:87\n",
            "d_loss_real:0.8327081203460693\n",
            "d_loss_fake:0.00013578071957454085\n",
            "d_loss_wrong:0.6543668508529663\n",
            "d_loss:0.5799797180661699\n",
            "g_loss:[0.40682321786880493, 0.39080649614334106, 0.008008359931409359]\n",
            "Batch:88\n",
            "d_loss_real:0.8483450412750244\n",
            "d_loss_fake:0.00046325504081323743\n",
            "d_loss_wrong:0.6784558892250061\n",
            "d_loss:0.593902306703967\n",
            "g_loss:[0.36526110768318176, 0.34772661328315735, 0.00876724161207676]\n",
            "Batch:89\n",
            "d_loss_real:0.8429350852966309\n",
            "d_loss_fake:0.00042450521141290665\n",
            "d_loss_wrong:0.6609187126159668\n",
            "d_loss:0.5868033471051604\n",
            "g_loss:[0.358323335647583, 0.34366294741630554, 0.007330195978283882]\n",
            "Batch:90\n",
            "d_loss_real:0.8372142314910889\n",
            "d_loss_fake:0.0002108805056195706\n",
            "d_loss_wrong:0.6774216294288635\n",
            "d_loss:0.5880152432291652\n",
            "g_loss:[0.36385342478752136, 0.34780749678611755, 0.008022964000701904]\n",
            "Batch:91\n",
            "d_loss_real:0.8420236110687256\n",
            "d_loss_fake:0.000467842910438776\n",
            "d_loss_wrong:0.6799821257591248\n",
            "d_loss:0.5911242977017537\n",
            "g_loss:[0.35704171657562256, 0.3410259485244751, 0.008007880300283432]\n",
            "Batch:92\n",
            "d_loss_real:0.8668911457061768\n",
            "d_loss_fake:0.00019856193102896214\n",
            "d_loss_wrong:0.6702178716659546\n",
            "d_loss:0.6010496812523343\n",
            "g_loss:[0.601962149143219, 0.5869891047477722, 0.007486508693546057]\n",
            "Batch:93\n",
            "d_loss_real:0.8271805047988892\n",
            "d_loss_fake:0.0004480471252463758\n",
            "d_loss_wrong:0.6466028094291687\n",
            "d_loss:0.5753529665380483\n",
            "g_loss:[0.369720458984375, 0.34646475315093994, 0.01162785105407238]\n",
            "Batch:94\n",
            "d_loss_real:0.8439159393310547\n",
            "d_loss_fake:0.0003440355067141354\n",
            "d_loss_wrong:0.6786388754844666\n",
            "d_loss:0.5917036974133225\n",
            "g_loss:[0.36328256130218506, 0.34774935245513916, 0.007766603492200375]\n",
            "Batch:95\n",
            "d_loss_real:0.8585590124130249\n",
            "d_loss_fake:0.0010308866621926427\n",
            "d_loss_wrong:0.672685980796814\n",
            "d_loss:0.5977087230712641\n",
            "g_loss:[0.3539852201938629, 0.3389050364494324, 0.00754009373486042]\n",
            "Batch:96\n",
            "d_loss_real:0.8061084747314453\n",
            "d_loss_fake:0.0001260996941709891\n",
            "d_loss_wrong:0.6725921630859375\n",
            "d_loss:0.5712338030607498\n",
            "g_loss:[0.39286381006240845, 0.3770029544830322, 0.007930420339107513]\n",
            "Batch:97\n",
            "d_loss_real:0.8352965116500854\n",
            "d_loss_fake:0.0003436667029745877\n",
            "d_loss_wrong:0.6514816880226135\n",
            "d_loss:0.5806045945064398\n",
            "g_loss:[0.35533004999160767, 0.3396737575531006, 0.007828153669834137]\n",
            "Batch:98\n",
            "d_loss_real:0.8621736764907837\n",
            "d_loss_fake:0.00040010642260313034\n",
            "d_loss_wrong:0.6959604024887085\n",
            "d_loss:0.6051769654732198\n",
            "g_loss:[0.3550873398780823, 0.34083396196365356, 0.007126682437956333]\n",
            "Batch:99\n",
            "d_loss_real:0.8312921524047852\n",
            "d_loss_fake:0.0003385584568604827\n",
            "d_loss_wrong:0.6421240568161011\n",
            "d_loss:0.576261730020633\n",
            "g_loss:[0.35772034525871277, 0.3376381993293762, 0.010041067376732826]\n",
            "Batch:100\n",
            "d_loss_real:0.8355106115341187\n",
            "d_loss_fake:0.0004905803361907601\n",
            "d_loss_wrong:0.6330408453941345\n",
            "d_loss:0.5761381621996406\n",
            "g_loss:[0.35618218779563904, 0.33584725856781006, 0.010167470201849937]\n",
            "Batch:101\n",
            "d_loss_real:0.8814521431922913\n",
            "d_loss_fake:0.00025370108778588474\n",
            "d_loss_wrong:0.6737039089202881\n",
            "d_loss:0.6092154740981641\n",
            "g_loss:[0.38575220108032227, 0.37010228633880615, 0.007824964821338654]\n",
            "Batch:102\n",
            "d_loss_real:0.8398489952087402\n",
            "d_loss_fake:0.0006969566456973553\n",
            "d_loss_wrong:0.6484049558639526\n",
            "d_loss:0.5821999757317826\n",
            "g_loss:[0.3460274040699005, 0.33244797587394714, 0.006789710372686386]\n",
            "Batch:103\n",
            "d_loss_real:0.8648397326469421\n",
            "d_loss_fake:0.00025158183416351676\n",
            "d_loss_wrong:0.6322789788246155\n",
            "d_loss:0.5905525064881658\n",
            "g_loss:[0.35121530294418335, 0.33554744720458984, 0.007833931595087051]\n",
            "Batch:104\n",
            "d_loss_real:0.8344940543174744\n",
            "d_loss_fake:0.0001558393705636263\n",
            "d_loss_wrong:0.68295818567276\n",
            "d_loss:0.5880255334195681\n",
            "g_loss:[0.35651662945747375, 0.3397279381752014, 0.008394341915845871]\n",
            "Batch:105\n",
            "d_loss_real:0.8727536797523499\n",
            "d_loss_fake:0.0003007383784279227\n",
            "d_loss_wrong:0.6685840487480164\n",
            "d_loss:0.603598036657786\n",
            "g_loss:[0.35641080141067505, 0.34345701336860657, 0.00647689588367939]\n",
            "Batch:106\n",
            "d_loss_real:0.822504460811615\n",
            "d_loss_fake:0.0005046993028372526\n",
            "d_loss_wrong:0.6627169251441956\n",
            "d_loss:0.5770576365175657\n",
            "g_loss:[0.3722817897796631, 0.35821712017059326, 0.00703232828527689]\n",
            "Batch:107\n",
            "d_loss_real:0.8525195121765137\n",
            "d_loss_fake:0.0002680940378922969\n",
            "d_loss_wrong:0.6631650328636169\n",
            "d_loss:0.5921180378136341\n",
            "g_loss:[0.3508133888244629, 0.33425241708755493, 0.008280487731099129]\n",
            "Batch:108\n",
            "d_loss_real:0.8474453687667847\n",
            "d_loss_fake:0.00031065987423062325\n",
            "d_loss_wrong:0.6443468928337097\n",
            "d_loss:0.5848870725603774\n",
            "g_loss:[0.3610779047012329, 0.3467356562614441, 0.007171123754233122]\n",
            "Batch:109\n",
            "d_loss_real:0.8452038764953613\n",
            "d_loss_fake:0.00022718853142578155\n",
            "d_loss_wrong:0.6553860902786255\n",
            "d_loss:0.5865052579501935\n",
            "g_loss:[0.3567429780960083, 0.34562253952026367, 0.005560225807130337]\n",
            "Batch:110\n",
            "d_loss_real:0.8173907995223999\n",
            "d_loss_fake:0.00015606533270329237\n",
            "d_loss_wrong:0.6653132438659668\n",
            "d_loss:0.5750627270608675\n",
            "g_loss:[0.3521900475025177, 0.3382173180580139, 0.006986361928284168]\n",
            "Batch:111\n",
            "d_loss_real:0.8118758201599121\n",
            "d_loss_fake:8.57041304698214e-05\n",
            "d_loss_wrong:0.6468768119812012\n",
            "d_loss:0.5676785391078738\n",
            "g_loss:[0.34797483682632446, 0.33242425322532654, 0.007775299251079559]\n",
            "Batch:112\n",
            "d_loss_real:0.8246294260025024\n",
            "d_loss_fake:0.0002747667022049427\n",
            "d_loss_wrong:0.6394261121749878\n",
            "d_loss:0.5722399327205494\n",
            "g_loss:[0.34605181217193604, 0.33393585681915283, 0.0060579730197787285]\n",
            "Batch:113\n",
            "d_loss_real:0.8422810435295105\n",
            "d_loss_fake:0.0002130706561729312\n",
            "d_loss_wrong:0.6473617553710938\n",
            "d_loss:0.5830342282715719\n",
            "g_loss:[0.3476469814777374, 0.33417874574661255, 0.006734119728207588]\n",
            "Batch:114\n",
            "d_loss_real:0.8069658279418945\n",
            "d_loss_fake:0.0009988720994442701\n",
            "d_loss_wrong:0.6405099034309387\n",
            "d_loss:0.563860107853543\n",
            "g_loss:[0.34971189498901367, 0.3357941508293152, 0.006958876736462116]\n",
            "Batch:115\n",
            "d_loss_real:0.8319506049156189\n",
            "d_loss_fake:0.0001189917529700324\n",
            "d_loss_wrong:0.6466471552848816\n",
            "d_loss:0.5776668392172724\n",
            "g_loss:[0.3445286750793457, 0.3320438265800476, 0.0062424237839877605]\n",
            "Batch:116\n",
            "d_loss_real:0.8388000726699829\n",
            "d_loss_fake:0.000368816195987165\n",
            "d_loss_wrong:0.6728121042251587\n",
            "d_loss:0.5876952664402779\n",
            "g_loss:[0.37679997086524963, 0.3654182255268097, 0.005690871737897396]\n",
            "Batch:117\n",
            "d_loss_real:0.8664722442626953\n",
            "d_loss_fake:0.00024811355979181826\n",
            "d_loss_wrong:0.6555159091949463\n",
            "d_loss:0.5971771278200322\n",
            "g_loss:[0.3464810252189636, 0.3357584476470947, 0.005361293442547321]\n",
            "Batch:118\n",
            "d_loss_real:0.8253631591796875\n",
            "d_loss_fake:0.00045882287668064237\n",
            "d_loss_wrong:0.6550276279449463\n",
            "d_loss:0.5765531922952505\n",
            "g_loss:[0.41143155097961426, 0.39923346042633057, 0.0060990480706095695]\n",
            "Batch:119\n",
            "d_loss_real:0.828177809715271\n",
            "d_loss_fake:0.00025549824931658804\n",
            "d_loss_wrong:0.6513445377349854\n",
            "d_loss:0.576988913853711\n",
            "g_loss:[0.35093823075294495, 0.3353939950466156, 0.007772121578454971]\n",
            "Batch:120\n",
            "d_loss_real:0.8378024101257324\n",
            "d_loss_fake:0.0012990535469725728\n",
            "d_loss_wrong:0.6479562520980835\n",
            "d_loss:0.5812150314741302\n",
            "g_loss:[0.35096099972724915, 0.3345766067504883, 0.008192192763090134]\n",
            "Batch:121\n",
            "d_loss_real:0.8496255278587341\n",
            "d_loss_fake:0.0001353036059299484\n",
            "d_loss_wrong:0.6576887965202332\n",
            "d_loss:0.5892687889609078\n",
            "g_loss:[0.36253130435943604, 0.3464135527610779, 0.008058873005211353]\n",
            "Batch:122\n",
            "d_loss_real:0.8244526386260986\n",
            "d_loss_fake:3.473517426755279e-05\n",
            "d_loss_wrong:0.6501508355140686\n",
            "d_loss:0.5747727119851334\n",
            "g_loss:[0.3532065451145172, 0.3370909094810486, 0.008057813160121441]\n",
            "Batch:123\n",
            "d_loss_real:0.8812711238861084\n",
            "d_loss_fake:0.00010726253094617277\n",
            "d_loss_wrong:0.7001075744628906\n",
            "d_loss:0.6156892711915134\n",
            "g_loss:[0.35303956270217896, 0.33944085240364075, 0.006799354217946529]\n",
            "Batch:124\n",
            "d_loss_real:0.851667046546936\n",
            "d_loss_fake:0.00013689458137378097\n",
            "d_loss_wrong:0.6393172144889832\n",
            "d_loss:0.5856970505410573\n",
            "g_loss:[0.35238856077194214, 0.34026315808296204, 0.006062704604119062]\n",
            "Batch:125\n",
            "d_loss_real:0.8038216829299927\n",
            "d_loss_fake:3.5522287362255156e-05\n",
            "d_loss_wrong:0.6547540426254272\n",
            "d_loss:0.5656082326931937\n",
            "g_loss:[0.3465213179588318, 0.3341379165649414, 0.006191699765622616]\n",
            "Batch:126\n",
            "d_loss_real:0.8335073590278625\n",
            "d_loss_fake:9.999699977925047e-05\n",
            "d_loss_wrong:0.6531292200088501\n",
            "d_loss:0.5800609837660886\n",
            "g_loss:[0.4209747016429901, 0.40801817178726196, 0.0064782639965415]\n",
            "Batch:127\n",
            "d_loss_real:0.8588674068450928\n",
            "d_loss_fake:0.00013184576528146863\n",
            "d_loss_wrong:0.6373657584190369\n",
            "d_loss:0.588808104468626\n",
            "g_loss:[0.379589319229126, 0.3673856556415558, 0.006101827137172222]\n",
            "Batch:128\n",
            "d_loss_real:0.8335950374603271\n",
            "d_loss_fake:0.0003045378834940493\n",
            "d_loss_wrong:0.6620907187461853\n",
            "d_loss:0.5823963328875834\n",
            "g_loss:[0.38772153854370117, 0.37094706296920776, 0.008387230336666107]\n",
            "Batch:129\n",
            "d_loss_real:0.8233084082603455\n",
            "d_loss_fake:0.0001237152609974146\n",
            "d_loss_wrong:0.6577563285827637\n",
            "d_loss:0.576124215091113\n",
            "g_loss:[0.3613826334476471, 0.3431944251060486, 0.00909410696476698]\n",
            "Batch:130\n",
            "d_loss_real:0.8279978632926941\n",
            "d_loss_fake:0.0004963381215929985\n",
            "d_loss_wrong:0.6675676703453064\n",
            "d_loss:0.5810149337630719\n",
            "g_loss:[0.345563679933548, 0.3336602747440338, 0.005951697938144207]\n",
            "Batch:131\n",
            "d_loss_real:0.8725631833076477\n",
            "d_loss_fake:0.0004914707969874144\n",
            "d_loss_wrong:0.6638398766517639\n",
            "d_loss:0.6023644285160117\n",
            "g_loss:[0.35977622866630554, 0.3424960970878601, 0.008640068583190441]\n",
            "Batch:132\n",
            "d_loss_real:0.8225221633911133\n",
            "d_loss_fake:0.0003418960841372609\n",
            "d_loss_wrong:0.6589087843894958\n",
            "d_loss:0.5760737518139649\n",
            "g_loss:[0.3606770634651184, 0.3488587737083435, 0.0059091467410326]\n",
            "Batch:133\n",
            "d_loss_real:0.8271745443344116\n",
            "d_loss_fake:0.0001849490508902818\n",
            "d_loss_wrong:0.6624153256416321\n",
            "d_loss:0.5792373408403364\n",
            "g_loss:[0.3458704352378845, 0.33253660798072815, 0.006666906177997589]\n",
            "Batch:134\n",
            "d_loss_real:0.8273894786834717\n",
            "d_loss_fake:0.00020542292622849345\n",
            "d_loss_wrong:0.6532162427902222\n",
            "d_loss:0.5770501557708485\n",
            "g_loss:[0.35014382004737854, 0.33618462085723877, 0.006979603786021471]\n",
            "Batch:135\n",
            "d_loss_real:0.8500979542732239\n",
            "d_loss_fake:0.00027821550611406565\n",
            "d_loss_wrong:0.6438683867454529\n",
            "d_loss:0.5860856276995037\n",
            "g_loss:[0.36553847789764404, 0.3507271707057953, 0.007405657321214676]\n",
            "Batch:136\n",
            "d_loss_real:0.8326964378356934\n",
            "d_loss_fake:0.000281585322227329\n",
            "d_loss_wrong:0.6593170166015625\n",
            "d_loss:0.5812478693987941\n",
            "g_loss:[0.41142162680625916, 0.39777109026908875, 0.006825265474617481]\n",
            "Batch:137\n",
            "d_loss_real:0.8231604099273682\n",
            "d_loss_fake:7.448607357218862e-05\n",
            "d_loss_wrong:0.6458137035369873\n",
            "d_loss:0.573052252366324\n",
            "g_loss:[0.35465553402900696, 0.3392733931541443, 0.007691066712141037]\n",
            "Batch:138\n",
            "d_loss_real:0.8293115496635437\n",
            "d_loss_fake:0.0023164465092122555\n",
            "d_loss_wrong:0.6491659283638\n",
            "d_loss:0.5775263685500249\n",
            "g_loss:[0.36920881271362305, 0.35340678691864014, 0.007901014760136604]\n",
            "========================================\n",
            "Epoch is: 4\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.8670960664749146\n",
            "d_loss_fake:8.340538624906912e-05\n",
            "d_loss_wrong:0.6815335154533386\n",
            "d_loss:0.6039522634473542\n",
            "g_loss:[0.3531794250011444, 0.34071075916290283, 0.006234339438378811]\n",
            "Batch:2\n",
            "d_loss_real:0.8426651954650879\n",
            "d_loss_fake:0.0001740934094414115\n",
            "d_loss_wrong:0.6741015911102295\n",
            "d_loss:0.5899015188624617\n",
            "g_loss:[0.4896753430366516, 0.4772663712501526, 0.006204483099281788]\n",
            "Batch:3\n",
            "d_loss_real:0.8384692668914795\n",
            "d_loss_fake:0.0009423704468645155\n",
            "d_loss_wrong:0.6582766771316528\n",
            "d_loss:0.5840393953403691\n",
            "g_loss:[0.3560299575328827, 0.34197497367858887, 0.007027496118098497]\n",
            "Batch:4\n",
            "d_loss_real:0.8727004528045654\n",
            "d_loss_fake:0.0006948882946744561\n",
            "d_loss_wrong:0.6878254413604736\n",
            "d_loss:0.6084803088160697\n",
            "g_loss:[0.36058923602104187, 0.3413579761981964, 0.00961562991142273]\n",
            "Batch:5\n",
            "d_loss_real:0.831275463104248\n",
            "d_loss_fake:0.00024545041378587484\n",
            "d_loss_wrong:0.6924332976341248\n",
            "d_loss:0.5888074185641017\n",
            "g_loss:[0.3649970591068268, 0.34480854868888855, 0.010094260796904564]\n",
            "Batch:6\n",
            "d_loss_real:0.8430156707763672\n",
            "d_loss_fake:0.00044292808161117136\n",
            "d_loss_wrong:0.7042092680931091\n",
            "d_loss:0.5976708844318637\n",
            "g_loss:[0.36239469051361084, 0.34476161003112793, 0.008816537447273731]\n",
            "Batch:7\n",
            "d_loss_real:0.8350405097007751\n",
            "d_loss_fake:9.034911636263132e-05\n",
            "d_loss_wrong:0.6550796627998352\n",
            "d_loss:0.581312757829437\n",
            "g_loss:[0.3582564890384674, 0.3428267240524292, 0.0077148801647126675]\n",
            "Batch:8\n",
            "d_loss_real:0.8216311931610107\n",
            "d_loss_fake:0.00011754989100154489\n",
            "d_loss_wrong:0.6177480220794678\n",
            "d_loss:0.5652819895731227\n",
            "g_loss:[0.3633388578891754, 0.34654998779296875, 0.00839443039149046]\n",
            "Batch:9\n",
            "d_loss_real:0.8330094814300537\n",
            "d_loss_fake:0.00011740326590370387\n",
            "d_loss_wrong:0.6446890830993652\n",
            "d_loss:0.5777063623063441\n",
            "g_loss:[0.3573943078517914, 0.3378860056400299, 0.009754147380590439]\n",
            "Batch:10\n",
            "d_loss_real:0.8477343916893005\n",
            "d_loss_fake:0.00012112218973925337\n",
            "d_loss_wrong:0.6228167414665222\n",
            "d_loss:0.5796016617587156\n",
            "g_loss:[0.35632506012916565, 0.3381003141403198, 0.00911236647516489]\n",
            "Batch:11\n",
            "d_loss_real:0.8631874322891235\n",
            "d_loss_fake:0.0030122913885861635\n",
            "d_loss_wrong:0.6333327293395996\n",
            "d_loss:0.5906799713266082\n",
            "g_loss:[0.3556497097015381, 0.3398854732513428, 0.007882116362452507]\n",
            "Batch:12\n",
            "d_loss_real:0.8493417501449585\n",
            "d_loss_fake:7.651025953236967e-05\n",
            "d_loss_wrong:0.6474847197532654\n",
            "d_loss:0.5865611825756787\n",
            "g_loss:[0.36467987298965454, 0.3495599031448364, 0.007559978403151035]\n",
            "Batch:13\n",
            "d_loss_real:0.8341977596282959\n",
            "d_loss_fake:0.00011777674808399752\n",
            "d_loss_wrong:0.6637958288192749\n",
            "d_loss:0.5830772812059877\n",
            "g_loss:[0.35329651832580566, 0.34074127674102783, 0.006277616135776043]\n",
            "Batch:14\n",
            "d_loss_real:0.8493674993515015\n",
            "d_loss_fake:8.09971388662234e-05\n",
            "d_loss_wrong:0.6762353181838989\n",
            "d_loss:0.593762828506442\n",
            "g_loss:[0.3485691547393799, 0.33582863211631775, 0.006370265502482653]\n",
            "Batch:15\n",
            "d_loss_real:0.8517637848854065\n",
            "d_loss_fake:7.573796028736979e-05\n",
            "d_loss_wrong:0.6798509359359741\n",
            "d_loss:0.5958635609167686\n",
            "g_loss:[0.34859979152679443, 0.33592671155929565, 0.006336546503007412]\n",
            "Batch:16\n",
            "d_loss_real:0.8449043035507202\n",
            "d_loss_fake:0.00014086982992012054\n",
            "d_loss_wrong:0.692676305770874\n",
            "d_loss:0.5956564456755586\n",
            "g_loss:[0.35320451855659485, 0.3402264416217804, 0.0064890324138104916]\n",
            "Batch:17\n",
            "d_loss_real:0.849694013595581\n",
            "d_loss_fake:0.0006988473469391465\n",
            "d_loss_wrong:0.7069730162620544\n",
            "d_loss:0.6017649727000389\n",
            "g_loss:[0.3492341935634613, 0.3372820317745209, 0.005976080894470215]\n",
            "Batch:18\n",
            "d_loss_real:0.8372611999511719\n",
            "d_loss_fake:0.00034164756652899086\n",
            "d_loss_wrong:0.6495915055274963\n",
            "d_loss:0.5811138882490923\n",
            "g_loss:[0.3578540086746216, 0.34606659412384033, 0.005893709138035774]\n",
            "Batch:19\n",
            "d_loss_real:0.8727430105209351\n",
            "d_loss_fake:0.00023742100165691227\n",
            "d_loss_wrong:0.6752784252166748\n",
            "d_loss:0.6052504668150505\n",
            "g_loss:[0.37332233786582947, 0.3619142472743988, 0.005704045295715332]\n",
            "Batch:20\n",
            "d_loss_real:0.8713414072990417\n",
            "d_loss_fake:0.001440756255760789\n",
            "d_loss_wrong:0.6874372363090515\n",
            "d_loss:0.607890201790724\n",
            "g_loss:[0.39831259846687317, 0.3870302736759186, 0.005641156807541847]\n",
            "Batch:21\n",
            "d_loss_real:0.8364140391349792\n",
            "d_loss_fake:0.00026127498131245375\n",
            "d_loss_wrong:0.619696319103241\n",
            "d_loss:0.573196418088628\n",
            "g_loss:[0.46751868724823, 0.45501255989074707, 0.006253065541386604]\n",
            "Batch:22\n",
            "d_loss_real:0.8678551912307739\n",
            "d_loss_fake:6.573103019036353e-05\n",
            "d_loss_wrong:0.6812576055526733\n",
            "d_loss:0.6042584297611029\n",
            "g_loss:[0.4090919494628906, 0.3967313766479492, 0.006180292926728725]\n",
            "Batch:23\n",
            "d_loss_real:0.832965612411499\n",
            "d_loss_fake:0.0003088689991272986\n",
            "d_loss_wrong:0.6675158143043518\n",
            "d_loss:0.5834389770316193\n",
            "g_loss:[0.37823590636253357, 0.3664691150188446, 0.005883390549570322]\n",
            "Batch:24\n",
            "d_loss_real:0.8180002570152283\n",
            "d_loss_fake:0.0001105223927879706\n",
            "d_loss_wrong:0.6434609293937683\n",
            "d_loss:0.5698929914542532\n",
            "g_loss:[0.39629480242729187, 0.382263720035553, 0.007015543058514595]\n",
            "Batch:25\n",
            "d_loss_real:0.8671262264251709\n",
            "d_loss_fake:7.021342753432691e-05\n",
            "d_loss_wrong:0.7013763189315796\n",
            "d_loss:0.6089247463023639\n",
            "g_loss:[0.37261325120925903, 0.3620558977127075, 0.005278671160340309]\n",
            "Batch:26\n",
            "d_loss_real:0.8261462450027466\n",
            "d_loss_fake:0.00011400434595998377\n",
            "d_loss_wrong:0.6659837365150452\n",
            "d_loss:0.5795975577166246\n",
            "g_loss:[0.3746165931224823, 0.3632219433784485, 0.005697318352758884]\n",
            "Batch:27\n",
            "d_loss_real:0.8886944055557251\n",
            "d_loss_fake:0.00010739939170889556\n",
            "d_loss_wrong:0.7058120965957642\n",
            "d_loss:0.6208270767747308\n",
            "g_loss:[0.3657063841819763, 0.35453128814697266, 0.005587546154856682]\n",
            "Batch:28\n",
            "d_loss_real:0.8127338886260986\n",
            "d_loss_fake:0.00015741284005343914\n",
            "d_loss_wrong:0.6242937445640564\n",
            "d_loss:0.5624797336640768\n",
            "g_loss:[0.35935717821121216, 0.3490452170372009, 0.005155986174941063]\n",
            "Batch:29\n",
            "d_loss_real:0.8555388450622559\n",
            "d_loss_fake:0.00022781803272664547\n",
            "d_loss_wrong:0.6444453597068787\n",
            "d_loss:0.5889377169660293\n",
            "g_loss:[0.35438060760498047, 0.3440423011779785, 0.0051691560074687]\n",
            "Batch:30\n",
            "d_loss_real:0.8549739718437195\n",
            "d_loss_fake:0.0002983914746437222\n",
            "d_loss_wrong:0.69349604845047\n",
            "d_loss:0.6009355959031382\n",
            "g_loss:[0.35242050886154175, 0.34251803159713745, 0.004951233044266701]\n",
            "Batch:31\n",
            "d_loss_real:0.8245062828063965\n",
            "d_loss_fake:0.00034595467150211334\n",
            "d_loss_wrong:0.6637428998947144\n",
            "d_loss:0.5782753550447524\n",
            "g_loss:[0.35085329413414, 0.3404461741447449, 0.005203559063374996]\n",
            "Batch:32\n",
            "d_loss_real:0.8366320133209229\n",
            "d_loss_fake:0.0002649606321938336\n",
            "d_loss_wrong:0.6296008825302124\n",
            "d_loss:0.575782467451063\n",
            "g_loss:[0.3534243702888489, 0.34361153841018677, 0.00490640988573432]\n",
            "Batch:33\n",
            "d_loss_real:0.8379273414611816\n",
            "d_loss_fake:0.006812617182731628\n",
            "d_loss_wrong:0.6431301236152649\n",
            "d_loss:0.58144935593009\n",
            "g_loss:[0.38077259063720703, 0.3707115352153778, 0.005030521657317877]\n",
            "Batch:34\n",
            "d_loss_real:0.8410614132881165\n",
            "d_loss_fake:0.00030427967431023717\n",
            "d_loss_wrong:0.6302719712257385\n",
            "d_loss:0.5781747693690704\n",
            "g_loss:[0.37657585740089417, 0.36584240198135376, 0.00536672817543149]\n",
            "Batch:35\n",
            "d_loss_real:0.866011381149292\n",
            "d_loss_fake:4.262257061782293e-05\n",
            "d_loss_wrong:0.6737502217292786\n",
            "d_loss:0.6014539016496201\n",
            "g_loss:[0.3617156147956848, 0.3531591296195984, 0.004278236068785191]\n",
            "Batch:36\n",
            "d_loss_real:0.8231833577156067\n",
            "d_loss_fake:4.712747613666579e-05\n",
            "d_loss_wrong:0.6519394516944885\n",
            "d_loss:0.5745883236504596\n",
            "g_loss:[0.3610607981681824, 0.35164695978164673, 0.004706921987235546]\n",
            "Batch:37\n",
            "d_loss_real:0.8359834551811218\n",
            "d_loss_fake:5.6216806115116924e-05\n",
            "d_loss_wrong:0.6833891868591309\n",
            "d_loss:0.5888530785068724\n",
            "g_loss:[0.3600982129573822, 0.3503448963165283, 0.004876661580055952]\n",
            "Batch:38\n",
            "d_loss_real:0.8556291460990906\n",
            "d_loss_fake:7.456580351572484e-05\n",
            "d_loss_wrong:0.6727975606918335\n",
            "d_loss:0.5960326046733826\n",
            "g_loss:[0.3825176954269409, 0.3733333349227905, 0.00459218118339777]\n",
            "Batch:39\n",
            "d_loss_real:0.8351354598999023\n",
            "d_loss_fake:0.00017643133469391614\n",
            "d_loss_wrong:0.6604594588279724\n",
            "d_loss:0.5827267024906178\n",
            "g_loss:[0.49860984086990356, 0.4897308647632599, 0.004439485725015402]\n",
            "Batch:40\n",
            "d_loss_real:0.8544653654098511\n",
            "d_loss_fake:0.0007515771430917084\n",
            "d_loss_wrong:0.7543957233428955\n",
            "d_loss:0.6160195078264223\n",
            "g_loss:[0.37945353984832764, 0.36656129360198975, 0.006446127779781818]\n",
            "Batch:41\n",
            "d_loss_real:0.8474479913711548\n",
            "d_loss_fake:0.00027348496951162815\n",
            "d_loss_wrong:0.6537660956382751\n",
            "d_loss:0.5872338908375241\n",
            "g_loss:[0.37021371722221375, 0.355413019657135, 0.007400352042168379]\n",
            "Batch:42\n",
            "d_loss_real:0.8891812562942505\n",
            "d_loss_fake:0.00040079434984363616\n",
            "d_loss_wrong:0.6562355756759644\n",
            "d_loss:0.6087497206535772\n",
            "g_loss:[0.3607361316680908, 0.34703099727630615, 0.006852567661553621]\n",
            "Batch:43\n",
            "d_loss_real:0.8075082898139954\n",
            "d_loss_fake:0.0005013931659050286\n",
            "d_loss_wrong:0.6413100957870483\n",
            "d_loss:0.564207017145236\n",
            "g_loss:[0.4144658148288727, 0.4031137228012085, 0.005676051136106253]\n",
            "Batch:44\n",
            "d_loss_real:0.8473241329193115\n",
            "d_loss_fake:0.00026527830050326884\n",
            "d_loss_wrong:0.6603510975837708\n",
            "d_loss:0.5888161604307243\n",
            "g_loss:[0.39598923921585083, 0.385343074798584, 0.005323084071278572]\n",
            "Batch:45\n",
            "d_loss_real:0.8014787435531616\n",
            "d_loss_fake:0.0002498170651961118\n",
            "d_loss_wrong:0.6260068416595459\n",
            "d_loss:0.5573035364577663\n",
            "g_loss:[0.37130653858184814, 0.36110448837280273, 0.0051010241732001305]\n",
            "Batch:46\n",
            "d_loss_real:0.846653401851654\n",
            "d_loss_fake:0.000353144045220688\n",
            "d_loss_wrong:0.6524383425712585\n",
            "d_loss:0.5865245725799468\n",
            "g_loss:[0.3837163746356964, 0.3736998438835144, 0.005008269567042589]\n",
            "Batch:47\n",
            "d_loss_real:0.8459978103637695\n",
            "d_loss_fake:0.0035003372468054295\n",
            "d_loss_wrong:0.6642814874649048\n",
            "d_loss:0.5899443613598123\n",
            "g_loss:[0.36793434619903564, 0.3583241105079651, 0.004805117845535278]\n",
            "Batch:48\n",
            "d_loss_real:0.8395899534225464\n",
            "d_loss_fake:4.6872039092704654e-05\n",
            "d_loss_wrong:0.636390745639801\n",
            "d_loss:0.5789043811309966\n",
            "g_loss:[0.3596286475658417, 0.35007891058921814, 0.004774861503392458]\n",
            "Batch:49\n",
            "d_loss_real:0.8226664066314697\n",
            "d_loss_fake:0.0003908718645107001\n",
            "d_loss_wrong:0.6299926042556763\n",
            "d_loss:0.5689290723457816\n",
            "g_loss:[0.39198291301727295, 0.3828561305999756, 0.004563389346003532]\n",
            "Batch:50\n",
            "d_loss_real:0.8325806856155396\n",
            "d_loss_fake:5.453950507217087e-05\n",
            "d_loss_wrong:0.644665539264679\n",
            "d_loss:0.5774703625002076\n",
            "g_loss:[0.356953889131546, 0.3467473089694977, 0.005103288684040308]\n",
            "Batch:51\n",
            "d_loss_real:0.8291260600090027\n",
            "d_loss_fake:9.416788088856265e-05\n",
            "d_loss_wrong:0.6514174938201904\n",
            "d_loss:0.5774409454297711\n",
            "g_loss:[0.354693740606308, 0.3434711694717407, 0.005611291620880365]\n",
            "Batch:52\n",
            "d_loss_real:0.8457481861114502\n",
            "d_loss_fake:8.010202145669609e-05\n",
            "d_loss_wrong:0.6728265881538391\n",
            "d_loss:0.591100765599549\n",
            "g_loss:[0.3541557192802429, 0.3435574769973755, 0.005299120210111141]\n",
            "Batch:53\n",
            "d_loss_real:0.83391273021698\n",
            "d_loss_fake:0.0001960357476491481\n",
            "d_loss_wrong:0.6514384150505066\n",
            "d_loss:0.5798649778080289\n",
            "g_loss:[0.38045284152030945, 0.371756911277771, 0.004347962327301502]\n",
            "Batch:54\n",
            "d_loss_real:0.8319796323776245\n",
            "d_loss_fake:0.00018115500279236585\n",
            "d_loss_wrong:0.6737525463104248\n",
            "d_loss:0.5844732415171165\n",
            "g_loss:[0.39329269528388977, 0.3859930634498596, 0.0036498159170150757]\n",
            "Batch:55\n",
            "d_loss_real:0.8190510869026184\n",
            "d_loss_fake:0.00043330827611498535\n",
            "d_loss_wrong:0.650923490524292\n",
            "d_loss:0.572364743151411\n",
            "g_loss:[0.36020833253860474, 0.3513807952404022, 0.00441376119852066]\n",
            "Batch:56\n",
            "d_loss_real:0.8581626415252686\n",
            "d_loss_fake:9.930085798259825e-05\n",
            "d_loss_wrong:0.6979200839996338\n",
            "d_loss:0.6035861669770384\n",
            "g_loss:[0.3746469020843506, 0.36511003971099854, 0.004768436774611473]\n",
            "Batch:57\n",
            "d_loss_real:0.8345190286636353\n",
            "d_loss_fake:0.00015176950546447188\n",
            "d_loss_wrong:0.6472619771957397\n",
            "d_loss:0.5791129510071187\n",
            "g_loss:[0.37364208698272705, 0.3644564747810364, 0.004592809826135635]\n",
            "Batch:58\n",
            "d_loss_real:0.8214943408966064\n",
            "d_loss_fake:0.0006109644309617579\n",
            "d_loss_wrong:0.6400686502456665\n",
            "d_loss:0.5709170741174603\n",
            "g_loss:[0.41046491265296936, 0.4015720784664154, 0.00444641150534153]\n",
            "Batch:59\n",
            "d_loss_real:0.8607797622680664\n",
            "d_loss_fake:0.00024767842842265964\n",
            "d_loss_wrong:0.668160617351532\n",
            "d_loss:0.5974919550790219\n",
            "g_loss:[0.3713824450969696, 0.3622077405452728, 0.004587351344525814]\n",
            "Batch:60\n",
            "d_loss_real:0.8442485332489014\n",
            "d_loss_fake:0.0004021760541945696\n",
            "d_loss_wrong:0.6805897355079651\n",
            "d_loss:0.5923722445149906\n",
            "g_loss:[0.36459672451019287, 0.354470819234848, 0.005062947049736977]\n",
            "Batch:61\n",
            "d_loss_real:0.8385322690010071\n",
            "d_loss_fake:0.00028206000570207834\n",
            "d_loss_wrong:0.6620544791221619\n",
            "d_loss:0.5848502692824695\n",
            "g_loss:[0.6742236018180847, 0.6633672714233398, 0.005428161937743425]\n",
            "Batch:62\n",
            "d_loss_real:0.846127450466156\n",
            "d_loss_fake:0.0029331797268241644\n",
            "d_loss_wrong:0.6491734981536865\n",
            "d_loss:0.5860903947032057\n",
            "g_loss:[0.38343167304992676, 0.3669794201850891, 0.00822613388299942]\n",
            "Batch:63\n",
            "d_loss_real:0.8425091505050659\n",
            "d_loss_fake:0.00010839306196430698\n",
            "d_loss_wrong:0.6512728929519653\n",
            "d_loss:0.5840998967560154\n",
            "g_loss:[0.3752896189689636, 0.3590767979621887, 0.008106410503387451]\n",
            "Batch:64\n",
            "d_loss_real:0.8250436186790466\n",
            "d_loss_fake:0.0001827712112572044\n",
            "d_loss_wrong:0.6388692855834961\n",
            "d_loss:0.5722848235382116\n",
            "g_loss:[0.37450435757637024, 0.3575524687767029, 0.00847594439983368]\n",
            "Batch:65\n",
            "d_loss_real:0.8913624286651611\n",
            "d_loss_fake:0.00020343990763649344\n",
            "d_loss_wrong:0.6998684406280518\n",
            "d_loss:0.6206991844665026\n",
            "g_loss:[0.37473151087760925, 0.353780597448349, 0.010475457645952702]\n",
            "Batch:66\n",
            "d_loss_real:0.8024993538856506\n",
            "d_loss_fake:0.00023057215730659664\n",
            "d_loss_wrong:0.6543176770210266\n",
            "d_loss:0.5648867392374086\n",
            "g_loss:[0.669981062412262, 0.6521289348602295, 0.008926055394113064]\n",
            "Batch:67\n",
            "d_loss_real:0.8679782152175903\n",
            "d_loss_fake:0.0001943313836818561\n",
            "d_loss_wrong:0.6294445395469666\n",
            "d_loss:0.5913988253414573\n",
            "g_loss:[0.3825169801712036, 0.3617364764213562, 0.010390248149633408]\n",
            "Batch:68\n",
            "d_loss_real:0.8467398285865784\n",
            "d_loss_fake:9.84436774160713e-05\n",
            "d_loss_wrong:0.6850957870483398\n",
            "d_loss:0.5946684719747282\n",
            "g_loss:[0.39957091212272644, 0.3811192214488983, 0.009225845336914062]\n",
            "Batch:69\n",
            "d_loss_real:0.8514277338981628\n",
            "d_loss_fake:0.0002942400751635432\n",
            "d_loss_wrong:0.6852990984916687\n",
            "d_loss:0.5971122015907895\n",
            "g_loss:[0.37236303091049194, 0.3503234386444092, 0.01101978961378336]\n",
            "Batch:70\n",
            "d_loss_real:0.8322089910507202\n",
            "d_loss_fake:0.0004824940988328308\n",
            "d_loss_wrong:0.6779828667640686\n",
            "d_loss:0.5857208357410855\n",
            "g_loss:[0.3822667598724365, 0.36327821016311646, 0.009494269266724586]\n",
            "Batch:71\n",
            "d_loss_real:0.8229753971099854\n",
            "d_loss_fake:0.00036154958070255816\n",
            "d_loss_wrong:0.6540103554725647\n",
            "d_loss:0.5750806748183095\n",
            "g_loss:[0.3671446740627289, 0.34700262546539307, 0.010071022436022758]\n",
            "Batch:72\n",
            "d_loss_real:0.8466125130653381\n",
            "d_loss_fake:0.00548984669148922\n",
            "d_loss_wrong:0.6612101197242737\n",
            "d_loss:0.5899812481366098\n",
            "g_loss:[0.44883307814598083, 0.4275655150413513, 0.010633784346282482]\n",
            "Batch:73\n",
            "d_loss_real:0.839058518409729\n",
            "d_loss_fake:8.378363418160006e-05\n",
            "d_loss_wrong:0.658396303653717\n",
            "d_loss:0.5841492810268392\n",
            "g_loss:[0.4274235963821411, 0.40518614649772644, 0.011118724942207336]\n",
            "Batch:74\n",
            "d_loss_real:0.8706632852554321\n",
            "d_loss_fake:0.0003254236653447151\n",
            "d_loss_wrong:0.6890746355056763\n",
            "d_loss:0.6076816574204713\n",
            "g_loss:[0.40348583459854126, 0.38208723068237305, 0.010699300095438957]\n",
            "Batch:75\n",
            "d_loss_real:0.8488508462905884\n",
            "d_loss_fake:0.000775644090026617\n",
            "d_loss_wrong:0.6555909514427185\n",
            "d_loss:0.5885170720284805\n",
            "g_loss:[0.42775958776474, 0.4091336727142334, 0.009312959387898445]\n",
            "Batch:76\n",
            "d_loss_real:0.8428201675415039\n",
            "d_loss_fake:0.00028999109053984284\n",
            "d_loss_wrong:0.6534422039985657\n",
            "d_loss:0.5848431325430283\n",
            "g_loss:[0.3987125754356384, 0.3806758224964142, 0.009018375538289547]\n",
            "Batch:77\n",
            "d_loss_real:0.835992693901062\n",
            "d_loss_fake:0.00010841309267561883\n",
            "d_loss_wrong:0.658044695854187\n",
            "d_loss:0.5825346241872467\n",
            "g_loss:[0.38400277495384216, 0.36648377776145935, 0.008759495802223682]\n",
            "Batch:78\n",
            "d_loss_real:0.8329424262046814\n",
            "d_loss_fake:0.00011523650027811527\n",
            "d_loss_wrong:0.6575172543525696\n",
            "d_loss:0.5808793358155526\n",
            "g_loss:[0.382720410823822, 0.3652713894844055, 0.008724503219127655]\n",
            "Batch:79\n",
            "d_loss_real:0.8392163515090942\n",
            "d_loss_fake:6.89452062943019e-05\n",
            "d_loss_wrong:0.6519911289215088\n",
            "d_loss:0.5826231942864979\n",
            "g_loss:[0.3656987249851227, 0.35139045119285583, 0.0071541303768754005]\n",
            "Batch:80\n",
            "d_loss_real:0.8239962458610535\n",
            "d_loss_fake:3.904447294189595e-05\n",
            "d_loss_wrong:0.647821307182312\n",
            "d_loss:0.5739632108443402\n",
            "g_loss:[0.3604466915130615, 0.34675073623657227, 0.006847984157502651]\n",
            "Batch:81\n",
            "d_loss_real:0.8348966836929321\n",
            "d_loss_fake:0.00023464846890419722\n",
            "d_loss_wrong:0.6257390379905701\n",
            "d_loss:0.5739417634613346\n",
            "g_loss:[0.36643359065055847, 0.3533990979194641, 0.006517243571579456]\n",
            "Batch:82\n",
            "d_loss_real:0.8894187211990356\n",
            "d_loss_fake:0.0007244135485962033\n",
            "d_loss_wrong:0.6601887345314026\n",
            "d_loss:0.6099376476195175\n",
            "g_loss:[0.37959474325180054, 0.36643844842910767, 0.006578140426427126]\n",
            "Batch:83\n",
            "d_loss_real:0.7891572713851929\n",
            "d_loss_fake:8.985762542579323e-05\n",
            "d_loss_wrong:0.6393190622329712\n",
            "d_loss:0.5544308656571957\n",
            "g_loss:[0.8292332887649536, 0.8166092038154602, 0.006312031298875809]\n",
            "Batch:84\n",
            "d_loss_real:0.8453819751739502\n",
            "d_loss_fake:0.00019666322623379529\n",
            "d_loss_wrong:0.6612677574157715\n",
            "d_loss:0.5880570927474764\n",
            "g_loss:[0.4167831838130951, 0.40362825989723206, 0.006577460560947657]\n",
            "Batch:85\n",
            "d_loss_real:0.8270328044891357\n",
            "d_loss_fake:4.78615183965303e-05\n",
            "d_loss_wrong:0.66269451379776\n",
            "d_loss:0.579201996073607\n",
            "g_loss:[0.4143708050251007, 0.4022747874259949, 0.006048009730875492]\n",
            "Batch:86\n",
            "d_loss_real:0.8248932361602783\n",
            "d_loss_fake:0.00012087389768566936\n",
            "d_loss_wrong:0.6532980799674988\n",
            "d_loss:0.5758013565464353\n",
            "g_loss:[0.3797179162502289, 0.36801064014434814, 0.005853633396327496]\n",
            "Batch:87\n",
            "d_loss_real:0.8258562684059143\n",
            "d_loss_fake:0.00022745985188521445\n",
            "d_loss_wrong:0.6473551988601685\n",
            "d_loss:0.5748237988809706\n",
            "g_loss:[0.49540063738822937, 0.4842691421508789, 0.005565742962062359]\n",
            "Batch:88\n",
            "d_loss_real:0.8434956073760986\n",
            "d_loss_fake:7.653108332306147e-05\n",
            "d_loss_wrong:0.6735880374908447\n",
            "d_loss:0.5901639458315913\n",
            "g_loss:[0.3839830160140991, 0.37100356817245483, 0.0064897178672254086]\n",
            "Batch:89\n",
            "d_loss_real:0.8327692747116089\n",
            "d_loss_fake:0.000132594199385494\n",
            "d_loss_wrong:0.6460959315299988\n",
            "d_loss:0.5779417687881505\n",
            "g_loss:[0.36059296131134033, 0.34905755519866943, 0.005767700262367725]\n",
            "Batch:90\n",
            "d_loss_real:0.8308067917823792\n",
            "d_loss_fake:0.0002841441601049155\n",
            "d_loss_wrong:0.6657387018203735\n",
            "d_loss:0.5819091073863092\n",
            "g_loss:[0.3813605010509491, 0.369223415851593, 0.0060685425996780396]\n",
            "Batch:91\n",
            "d_loss_real:0.8388746976852417\n",
            "d_loss_fake:0.001358786947093904\n",
            "d_loss_wrong:0.6697124242782593\n",
            "d_loss:0.5872051516489591\n",
            "g_loss:[0.36071309447288513, 0.3474695086479187, 0.006621795706450939]\n",
            "Batch:92\n",
            "d_loss_real:0.8586464524269104\n",
            "d_loss_fake:0.0005720999906770885\n",
            "d_loss_wrong:0.6580040454864502\n",
            "d_loss:0.593967262582737\n",
            "g_loss:[0.5282951593399048, 0.5143402814865112, 0.00697744358330965]\n",
            "Batch:93\n",
            "d_loss_real:0.8168772459030151\n",
            "d_loss_fake:0.00011378913768567145\n",
            "d_loss_wrong:0.6441947817802429\n",
            "d_loss:0.5695157656809897\n",
            "g_loss:[0.4109818637371063, 0.39839452505111694, 0.006293668411672115]\n",
            "Batch:94\n",
            "d_loss_real:0.8366929292678833\n",
            "d_loss_fake:0.0001158032682724297\n",
            "d_loss_wrong:0.6762880682945251\n",
            "d_loss:0.587447432524641\n",
            "g_loss:[0.39553511142730713, 0.38183826208114624, 0.006848424673080444]\n",
            "Batch:95\n",
            "d_loss_real:0.85233473777771\n",
            "d_loss_fake:0.0002134311944246292\n",
            "d_loss_wrong:0.6718164086341858\n",
            "d_loss:0.5941748288460076\n",
            "g_loss:[0.3787061870098114, 0.3626393675804138, 0.008033406920731068]\n",
            "Batch:96\n",
            "d_loss_real:0.8037937879562378\n",
            "d_loss_fake:0.0001523021055618301\n",
            "d_loss_wrong:0.6676830053329468\n",
            "d_loss:0.568855720837746\n",
            "g_loss:[0.3689627945423126, 0.3537178039550781, 0.00762249156832695]\n",
            "Batch:97\n",
            "d_loss_real:0.82970130443573\n",
            "d_loss_fake:9.169895929517224e-05\n",
            "d_loss_wrong:0.6459439992904663\n",
            "d_loss:0.5763595767803054\n",
            "g_loss:[0.3827084004878998, 0.3697201609611511, 0.006494126282632351]\n",
            "Batch:98\n",
            "d_loss_real:0.8600291609764099\n",
            "d_loss_fake:0.0001374725834466517\n",
            "d_loss_wrong:0.693760097026825\n",
            "d_loss:0.6034889728907729\n",
            "g_loss:[0.35557645559310913, 0.3432241678237915, 0.0061761485412716866]\n",
            "Batch:99\n",
            "d_loss_real:0.8243962526321411\n",
            "d_loss_fake:0.00014253746485337615\n",
            "d_loss_wrong:0.641096293926239\n",
            "d_loss:0.5725078341638437\n",
            "g_loss:[0.36071011424064636, 0.3478805720806122, 0.006414769217371941]\n",
            "Batch:100\n",
            "d_loss_real:0.8279398679733276\n",
            "d_loss_fake:0.0021307680290192366\n",
            "d_loss_wrong:0.628822922706604\n",
            "d_loss:0.5717083566705696\n",
            "g_loss:[0.35474783182144165, 0.341486394405365, 0.00663071358576417]\n",
            "Batch:101\n",
            "d_loss_real:0.8729591369628906\n",
            "d_loss_fake:0.00018903892487287521\n",
            "d_loss_wrong:0.6656301021575928\n",
            "d_loss:0.6029343537520617\n",
            "g_loss:[0.35731393098831177, 0.34458205103874207, 0.006365944631397724]\n",
            "Batch:102\n",
            "d_loss_real:0.8344101905822754\n",
            "d_loss_fake:0.00017892534378916025\n",
            "d_loss_wrong:0.642119824886322\n",
            "d_loss:0.5777797828486655\n",
            "g_loss:[0.3636833131313324, 0.35278910398483276, 0.005447098985314369]\n",
            "Batch:103\n",
            "d_loss_real:0.8570629358291626\n",
            "d_loss_fake:0.00018587868544273078\n",
            "d_loss_wrong:0.6314662098884583\n",
            "d_loss:0.5864444900580565\n",
            "g_loss:[0.3830188810825348, 0.370302677154541, 0.006358103360980749]\n",
            "Batch:104\n",
            "d_loss_real:0.8282127380371094\n",
            "d_loss_fake:0.00018763364641927183\n",
            "d_loss_wrong:0.6747894287109375\n",
            "d_loss:0.5828506346078939\n",
            "g_loss:[0.3672651946544647, 0.35510843992233276, 0.006078381557017565]\n",
            "Batch:105\n",
            "d_loss_real:0.8593147993087769\n",
            "d_loss_fake:0.0001356817374471575\n",
            "d_loss_wrong:0.6621506214141846\n",
            "d_loss:0.5952289754422964\n",
            "g_loss:[0.3816809058189392, 0.3706311285495758, 0.005524883978068829]\n",
            "Batch:106\n",
            "d_loss_real:0.8167335987091064\n",
            "d_loss_fake:9.620845230529085e-05\n",
            "d_loss_wrong:0.6582387089729309\n",
            "d_loss:0.5729505287108623\n",
            "g_loss:[0.37042075395584106, 0.3593910336494446, 0.005514856427907944]\n",
            "Batch:107\n",
            "d_loss_real:0.851148247718811\n",
            "d_loss_fake:0.0002669874229468405\n",
            "d_loss_wrong:0.649712324142456\n",
            "d_loss:0.5880689517507562\n",
            "g_loss:[0.34848952293395996, 0.3389134109020233, 0.004788062535226345]\n",
            "Batch:108\n",
            "d_loss_real:0.8448261618614197\n",
            "d_loss_fake:0.0002207005163654685\n",
            "d_loss_wrong:0.6431871056556702\n",
            "d_loss:0.5832650324737187\n",
            "g_loss:[0.41627123951911926, 0.40666812658309937, 0.004801559261977673]\n",
            "Batch:109\n",
            "d_loss_real:0.8362932205200195\n",
            "d_loss_fake:0.00023508642334491014\n",
            "d_loss_wrong:0.6520864367485046\n",
            "d_loss:0.5812269910529722\n",
            "g_loss:[0.3503880500793457, 0.34117722511291504, 0.004605418536812067]\n",
            "Batch:110\n",
            "d_loss_real:0.8135388493537903\n",
            "d_loss_fake:0.00027175701688975096\n",
            "d_loss_wrong:0.6608819961547852\n",
            "d_loss:0.5720578629698139\n",
            "g_loss:[0.3421911597251892, 0.3336014747619629, 0.0042948490008711815]\n",
            "Batch:111\n",
            "d_loss_real:0.8071375489234924\n",
            "d_loss_fake:9.599352051736787e-05\n",
            "d_loss_wrong:0.6457021832466125\n",
            "d_loss:0.5650183186535287\n",
            "g_loss:[0.35491836071014404, 0.3461844027042389, 0.004366983659565449]\n",
            "Batch:112\n",
            "d_loss_real:0.816597044467926\n",
            "d_loss_fake:0.0001104469847632572\n",
            "d_loss_wrong:0.6365851163864136\n",
            "d_loss:0.5674724130767572\n",
            "g_loss:[0.7140530347824097, 0.7055604457855225, 0.004246294964104891]\n",
            "Batch:113\n",
            "d_loss_real:0.9159121513366699\n",
            "d_loss_fake:0.014001620933413506\n",
            "d_loss_wrong:0.6657090187072754\n",
            "d_loss:0.6278837355785072\n",
            "g_loss:[0.7901245355606079, 0.782090425491333, 0.004017065744847059]\n",
            "Batch:114\n",
            "d_loss_real:0.7890138030052185\n",
            "d_loss_fake:3.41625272994861e-05\n",
            "d_loss_wrong:0.6516631245613098\n",
            "d_loss:0.5574312232747616\n",
            "g_loss:[0.7475696206092834, 0.739947497844696, 0.003811049275100231]\n",
            "Batch:115\n",
            "d_loss_real:0.8228471279144287\n",
            "d_loss_fake:0.001106626819819212\n",
            "d_loss_wrong:0.6538744568824768\n",
            "d_loss:0.5751688348827884\n",
            "g_loss:[0.6755656599998474, 0.667388916015625, 0.004088368266820908]\n",
            "Batch:116\n",
            "d_loss_real:0.8301945924758911\n",
            "d_loss_fake:0.0013331964146345854\n",
            "d_loss_wrong:0.678707480430603\n",
            "d_loss:0.585107465449255\n",
            "g_loss:[0.6081912517547607, 0.5996013879776001, 0.004294936545193195]\n",
            "Batch:117\n",
            "d_loss_real:0.8489267230033875\n",
            "d_loss_fake:0.00011519020335981622\n",
            "d_loss_wrong:0.6670889258384705\n",
            "d_loss:0.5912643905121513\n",
            "g_loss:[0.5405466556549072, 0.5314064025878906, 0.004570121876895428]\n",
            "Batch:118\n",
            "d_loss_real:0.8135926127433777\n",
            "d_loss_fake:0.00035424751695245504\n",
            "d_loss_wrong:0.6618506908416748\n",
            "d_loss:0.5723475409613457\n",
            "g_loss:[0.5279380083084106, 0.5187562704086304, 0.004590854048728943]\n",
            "Batch:119\n",
            "d_loss_real:0.8221948146820068\n",
            "d_loss_fake:0.00020570095512084663\n",
            "d_loss_wrong:0.6499183177947998\n",
            "d_loss:0.5736284120284836\n",
            "g_loss:[0.532762885093689, 0.5235887765884399, 0.004587056580930948]\n",
            "Batch:120\n",
            "d_loss_real:0.8350256681442261\n",
            "d_loss_fake:0.00015660258941352367\n",
            "d_loss_wrong:0.6473011374473572\n",
            "d_loss:0.5793772690813057\n",
            "g_loss:[0.4866711497306824, 0.4775175452232361, 0.004576800856739283]\n",
            "Batch:121\n",
            "d_loss_real:0.8410967588424683\n",
            "d_loss_fake:0.0002782588708214462\n",
            "d_loss_wrong:0.6551651358604431\n",
            "d_loss:0.5844092281040503\n",
            "g_loss:[0.45066189765930176, 0.4412864148616791, 0.004687741864472628]\n",
            "Batch:122\n",
            "d_loss_real:0.8160715103149414\n",
            "d_loss_fake:0.011604011058807373\n",
            "d_loss_wrong:0.6442121267318726\n",
            "d_loss:0.5719897896051407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNzypuTCdbfd"
      },
      "source": [
        "def residual_block(input):\n",
        "    \"\"\"\n",
        "    Residual block in the generator network\n",
        "    \"\"\"\n",
        "    x = Conv2D(128 * 4, kernel_size=(3, 3), padding='same', strides=1)(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(128 * 4, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = tf.math.add(x, input)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    return x\n",
        "  \n",
        "def joint_block(inputs):\n",
        "    c = inputs[0]\n",
        "    x = inputs[1]\n",
        "\n",
        "    c = K.expand_dims(c, axis=1)\n",
        "    c = K.expand_dims(c, axis=1)\n",
        "    c = K.tile(c, [1, 16, 16, 1])\n",
        "    return K.concatenate([c, x], axis=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhSHEe_jhiLN"
      },
      "source": [
        "def build_stage2_generator():\n",
        "    \"\"\"\n",
        "    Create Stage-II generator containing the CA Augmentation Network,\n",
        "    the image encoder and the generator network\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. CA Augmentation Network\n",
        "    input_layer = Input(shape=(1024,))\n",
        "    input_lr_images = Input(shape=(64, 64, 3))\n",
        "\n",
        "    ca = Dense(256)(input_layer)\n",
        "    mean_logsigma = LeakyReLU(alpha=0.2)(ca)\n",
        "    c = Lambda(generate_c)(mean_logsigma)\n",
        "\n",
        "    # 2. Image Encoder\n",
        "    x = ZeroPadding2D(padding=(1, 1))(input_lr_images)\n",
        "    x = Conv2D(128, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = Conv2D(256, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = Conv2D(512, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # 3. Joint\n",
        "    c_code = Lambda(joint_block)([c, x])\n",
        "\n",
        "    x = ZeroPadding2D(padding=(1, 1))(c_code)\n",
        "    x = Conv2D(512, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # 4. Residual blocks\n",
        "    x = residual_block(x)\n",
        "    x = residual_block(x)\n",
        "    x = residual_block(x)\n",
        "    x = residual_block(x)\n",
        "\n",
        "    # 5. Upsampling blocks\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = Activation('tanh')(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer, input_lr_images], outputs=[x, mean_logsigma])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Abgd7hiDtD"
      },
      "source": [
        "def build_stage2_discriminator():\n",
        "    \"\"\"\n",
        "    Create Stage-II discriminator network\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(256, 256, 3))\n",
        "\n",
        "    x = Conv2D(64, (4, 4), padding='same', strides=2, input_shape=(256, 256, 3), use_bias=False)(input_layer)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(64, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\n",
        "    x2 = Conv2D(128, (1, 1), padding='same', strides=1, use_bias=False)(x)\n",
        "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
        "\n",
        "    x2 = Conv2D(128, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n",
        "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
        "\n",
        "    x2 = Conv2D(256, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n",
        "    added_x = tf.math.add(x, x2)\n",
        "    added_x = LeakyReLU(alpha=0.2)(added_x)\n",
        "\n",
        "    input_layer2 = Input(shape=(4, 4, 128))\n",
        "\n",
        "    merged_input = concatenate([added_x, input_layer2])\n",
        "\n",
        "    x3 = Conv2D(64 * 8, kernel_size=1, padding=\"same\", strides=1)(merged_input)\n",
        "    x3 = LeakyReLU(alpha=0.2)(x3)\n",
        "    x3 = Flatten()(x3)\n",
        "    x3 = Dense(1)(x3)\n",
        "    x3 = Activation('sigmoid')(x3)\n",
        "\n",
        "    stage2_dis = Model(inputs=[input_layer, input_layer2], outputs=[x3])\n",
        "    return stage2_dis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=build_stage2_discriminator()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy1bNbXPBNpe",
        "outputId": "2e86a984-d113-42b7-8ddb-1fbf709b5823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 128, 128, 64  3072        ['input_10[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 128, 128, 64  0           ['conv2d_10[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 128)  131072      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 64, 64, 128)  0           ['conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 256)  524288      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 32, 32, 256)  0           ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 128)  524288      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 16, 16, 128)  0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 8, 8, 64)     131072      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 8, 8, 64)     0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 4, 4, 256)    262144      ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 4, 4, 256)    0           ['conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 4, 4, 128)    32768       ['leaky_re_lu_12[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_13 (LeakyReLU)     (None, 4, 4, 128)    0           ['conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 4, 4, 128)    147456      ['leaky_re_lu_13[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_14 (LeakyReLU)     (None, 4, 4, 128)    0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 4, 4, 256)    294912      ['leaky_re_lu_14[0][0]']         \n",
            "                                                                                                  \n",
            " tf.math.add (TFOpLambda)       (None, 4, 4, 256)    0           ['leaky_re_lu_12[0][0]',         \n",
            "                                                                  'conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_15 (LeakyReLU)     (None, 4, 4, 256)    0           ['tf.math.add[0][0]']            \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, 4, 4, 128)]  0           []                               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 4, 4, 384)    0           ['leaky_re_lu_15[0][0]',         \n",
            "                                                                  'input_11[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 4, 4, 512)    197120      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_16 (LeakyReLU)     (None, 4, 4, 512)    0           ['conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 8192)         0           ['leaky_re_lu_16[0][0]']         \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            8193        ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1)            0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,256,385\n",
            "Trainable params: 2,256,385\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CetZlPeiNvV"
      },
      "source": [
        "def build_adversarial_model(gen_model2, dis_model, gen_model1):\n",
        "    \"\"\"\n",
        "    Create adversarial model\n",
        "    \"\"\"\n",
        "    embeddings_input_layer = Input(shape=(1024, ))\n",
        "    noise_input_layer = Input(shape=(100, ))\n",
        "    compressed_embedding_input_layer = Input(shape=(4, 4, 128))\n",
        "\n",
        "    gen_model1.trainable = False\n",
        "    dis_model.trainable = False\n",
        "\n",
        "    lr_images, mean_logsigma1 = gen_model1([embeddings_input_layer, noise_input_layer])\n",
        "    hr_images, mean_logsigma2 = gen_model2([embeddings_input_layer, lr_images])\n",
        "    valid = dis_model([hr_images, compressed_embedding_input_layer])\n",
        "\n",
        "    model = Model(inputs=[embeddings_input_layer, noise_input_layer, compressed_embedding_input_layer], outputs=[valid, mean_logsigma2])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPfWNwxmiSxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc42ea4-3f01-4991-a84a-d61504d77a01"
      },
      "source": [
        "    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "    \"\"\"\n",
        "    Load datasets\n",
        "    \"\"\"\n",
        "    X_hr_train, y_hr_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n",
        "                                                            class_info_file_path=class_info_file_path_train,\n",
        "                                                            cub_dataset_dir=cub_dataset_dir,\n",
        "                                                            embeddings_file_path=embeddings_file_path_train,\n",
        "                                                            image_size=(256, 256))\n",
        "\n",
        "    X_hr_test, y_hr_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n",
        "                                                         class_info_file_path=class_info_file_path_test,\n",
        "                                                         cub_dataset_dir=cub_dataset_dir,\n",
        "                                                         embeddings_file_path=embeddings_file_path_test,\n",
        "                                                         image_size=(256, 256))\n",
        "\n",
        "    X_lr_train, y_lr_train, _ = load_dataset(filenames_file_path=filenames_file_path_train,\n",
        "                                             class_info_file_path=class_info_file_path_train,\n",
        "                                             cub_dataset_dir=cub_dataset_dir,\n",
        "                                             embeddings_file_path=embeddings_file_path_train,\n",
        "                                             image_size=(64, 64))\n",
        "\n",
        "    X_lr_test, y_lr_test, _ = load_dataset(filenames_file_path=filenames_file_path_test,\n",
        "                                           class_info_file_path=class_info_file_path_test,\n",
        "                                           cub_dataset_dir=cub_dataset_dir,\n",
        "                                           embeddings_file_path=embeddings_file_path_test,\n",
        "                                           image_size=(64, 64))\n",
        "\n",
        "    \"\"\"\n",
        "    Build and compile models\n",
        "    \"\"\"\n",
        "    stage2_dis = build_stage2_discriminator()\n",
        "    stage2_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
        "\n",
        "    stage1_gen = build_stage1_generator()\n",
        "    stage1_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n",
        "\n",
        "    stage1_gen.load_weights(\"/content/drive/MyDrive/StackGAN_weights/stage1_gen_weight.h5\") #here clearly we are using the already trained stage_1 gen hence we do stage_1gen.trainable=flase in the function where we define the adversarial model for stage2\n",
        "\n",
        "    stage2_gen = build_stage2_generator()\n",
        "    stage2_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n",
        "\n",
        "    embedding_compressor_model = build_embedding_compressor_model()\n",
        "    embedding_compressor_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "    adversarial_model = build_adversarial_model(stage2_gen, stage2_dis, stage1_gen)\n",
        "    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1.0, 2.0],\n",
        "                              optimizer=gen_optimizer, metrics=None)\n",
        "\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
        "    tensorboard.set_model(stage2_gen)\n",
        "    tensorboard.set_model(stage2_dis)\n",
        "\n",
        "    # Generate an array containing real and fake values\n",
        "    # Apply label smoothing\n",
        "    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
        "    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"========================================\")\n",
        "        print(\"Epoch is:\", epoch)\n",
        "\n",
        "        gen_losses = []\n",
        "        dis_losses = []\n",
        "\n",
        "        # Load data and train model\n",
        "        number_of_batches = int(X_hr_train.shape[0] / batch_size)\n",
        "        print(\"Number of batches:{}\".format(number_of_batches))\n",
        "        for index in range(number_of_batches):\n",
        "            print(\"Batch:{}\".format(index+1))\n",
        "\n",
        "            # Create a noise vector\n",
        "            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "            X_hr_train_batch = X_hr_train[index * batch_size:(index + 1) * batch_size]\n",
        "            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n",
        "            X_hr_train_batch = (X_hr_train_batch - 127.5) / 127.5\n",
        "\n",
        "            # Generate fake images\n",
        "            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n",
        "            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n",
        "\n",
        "            \"\"\"\n",
        "            4. Generate compressed embeddings\n",
        "            \"\"\"\n",
        "            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n",
        "            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n",
        "            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
        "\n",
        "            \"\"\"\n",
        "            5. Train the discriminator model\n",
        "            \"\"\"\n",
        "            dis_loss_real = stage2_dis.train_on_batch([X_hr_train_batch, compressed_embedding],\n",
        "                                                      np.reshape(real_labels, (batch_size, 1)))\n",
        "            dis_loss_fake = stage2_dis.train_on_batch([hr_fake_images, compressed_embedding],\n",
        "                                                      np.reshape(fake_labels, (batch_size, 1)))\n",
        "            dis_loss_wrong = stage2_dis.train_on_batch([X_hr_train_batch[:(batch_size - 1)], compressed_embedding[1:]],\n",
        "                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n",
        "            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong,  dis_loss_fake))\n",
        "            print(\"d_loss:{}\".format(d_loss))\n",
        "\n",
        "            \"\"\"\n",
        "            Train the adversarial model\n",
        "            \"\"\"\n",
        "            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],\n",
        "                                                                [K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n",
        "\n",
        "            print(\"g_loss:{}\".format(g_loss))\n",
        "\n",
        "            dis_losses.append(d_loss)\n",
        "            gen_losses.append(g_loss)\n",
        "\n",
        "        \"\"\"\n",
        "        Save losses to Tensorboard after each epoch\n",
        "        \"\"\"\n",
        "        # write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n",
        "        # write_log(tensorboard, 'generator_loss', np.mean(gen_losses)[0], epoch)\n",
        "\n",
        "        # Generate and save images after every 2nd epoch\n",
        "        if epoch % 2 == 0:\n",
        "            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
        "            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "            embedding_batch = embeddings_test[0:batch_size]\n",
        "\n",
        "            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise2], verbose=3)\n",
        "            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n",
        "            stage2_gen.save_weights(\"/content/drive/MyDrive/StackGAN_weights/stage2_gen_weight.h5\")\n",
        "            stage2_dis.save_weights(\"/content/drive/MyDrive/StackGAN_weights/stage2_dis_weight.h5\")\n",
        "\n",
        "            # Save images\n",
        "            for i, img in enumerate(hr_fake_images[:10]):\n",
        "                save_rgb_img(img, \"results2/gen_{}_{}.png\".format(epoch, i))\n",
        "\n",
        "    # Saving the models\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings:  (8855, 10, 1024)\n",
            "Embeddings shape: (8855, 10, 1024)\n",
            "embeddings:  (2933, 10, 1024)\n",
            "Embeddings shape: (2933, 10, 1024)\n",
            "embeddings:  (8855, 10, 1024)\n",
            "Embeddings shape: (8855, 10, 1024)\n",
            "embeddings:  (2933, 10, 1024)\n",
            "Embeddings shape: (2933, 10, 1024)\n",
            "========================================\n",
            "Epoch is: 0\n",
            "Number of batches:138\n",
            "Batch:1\n",
            "d_loss:0.7092905342578888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fITp9mFHYTOi"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}